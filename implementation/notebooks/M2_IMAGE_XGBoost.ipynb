{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748a82d7-aab7-49bf-baf1-005dab61ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu detecte on va accelerer xgboost\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# je definis les chemins\n",
    "path_root = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_root, \"implementation\", \"outputs\")\n",
    "\n",
    "# je verifie si le gpu est dispo pour xgboost\n",
    "# xgboost a besoin de savoir si cuda est la\n",
    "use_gpu = False\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"gpu detecte on va accelerer xgboost\")\n",
    "        use_gpu = True\n",
    "    else:\n",
    "        print(\"pas de gpu on reste sur cpu\")\n",
    "except:\n",
    "    print(\"erreur detection gpu passage cpu\")\n",
    "\n",
    "# je cree le dossier sortie si besoin\n",
    "if not os.path.exists(path_out):\n",
    "    os.makedirs(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13065fee-0765-4e67-87b4-9f10fc8fe4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chargement des donnees converties\n",
      "donnees chargees en memoire\n",
      "(405000, 2048)\n",
      "split termine pret a entrainer\n"
     ]
    }
   ],
   "source": [
    "print(\"chargement des donnees converties\")\n",
    "\n",
    "# je tente de charger les features extraites par le reseau\n",
    "# c est ce qui donne les meilleurs resultats en ml classique\n",
    "try:\n",
    "    path_x = os.path.join(path_out, 'train_features_resnet50_augmented.npy')\n",
    "    path_y = os.path.join(path_out, 'train_labels_augmented.npy')\n",
    "    \n",
    "    if not os.path.exists(path_x):\n",
    "        # plan b si le fichier augmente n est pas la je cherche le simple\n",
    "        path_x = os.path.join(path_out, 'train_features_resnet50.npy')\n",
    "        path_y = os.path.join(path_out, 'train_labels.npy')\n",
    "\n",
    "    x_data = np.load(path_x)\n",
    "    y_data = np.load(path_y)\n",
    "    \n",
    "    print(\"donnees chargees en memoire\")\n",
    "    print(x_data.shape)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"erreur critique impossible de trouver les fichiers npy\")\n",
    "    print(\"tu dois avoir extrait les features avant de lancer xgboost\")\n",
    "    raise e\n",
    "\n",
    "# encodage des cibles\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_data)\n",
    "\n",
    "# split train val\n",
    "# je garde 20% pour verifier si on overfit pas\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_data, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(\"split termine pret a entrainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2e3d3c-3545-4325-b9cc-fdfcc7c604cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lancement optimisation xgboost\n",
      "demarrage entrainement surveille\n",
      "[0]\tvalidation_0-mlogloss:3.12367\tvalidation_1-mlogloss:3.14457\n",
      "[10]\tvalidation_0-mlogloss:2.31332\tvalidation_1-mlogloss:2.45704\n",
      "[20]\tvalidation_0-mlogloss:1.91287\tvalidation_1-mlogloss:2.12983\n",
      "[30]\tvalidation_0-mlogloss:1.64494\tvalidation_1-mlogloss:1.91686\n",
      "[40]\tvalidation_0-mlogloss:1.44806\tvalidation_1-mlogloss:1.76370\n",
      "[50]\tvalidation_0-mlogloss:1.29666\tvalidation_1-mlogloss:1.64825\n",
      "[60]\tvalidation_0-mlogloss:1.17473\tvalidation_1-mlogloss:1.55718\n",
      "[70]\tvalidation_0-mlogloss:1.07402\tvalidation_1-mlogloss:1.48375\n",
      "[80]\tvalidation_0-mlogloss:0.99035\tvalidation_1-mlogloss:1.42363\n",
      "[90]\tvalidation_0-mlogloss:0.91929\tvalidation_1-mlogloss:1.37334\n",
      "[100]\tvalidation_0-mlogloss:0.85748\tvalidation_1-mlogloss:1.33024\n",
      "[110]\tvalidation_0-mlogloss:0.80232\tvalidation_1-mlogloss:1.29228\n",
      "[120]\tvalidation_0-mlogloss:0.75441\tvalidation_1-mlogloss:1.25961\n",
      "[130]\tvalidation_0-mlogloss:0.71083\tvalidation_1-mlogloss:1.23014\n",
      "[140]\tvalidation_0-mlogloss:0.67187\tvalidation_1-mlogloss:1.20382\n",
      "[150]\tvalidation_0-mlogloss:0.63562\tvalidation_1-mlogloss:1.17936\n",
      "[160]\tvalidation_0-mlogloss:0.60228\tvalidation_1-mlogloss:1.15727\n",
      "[170]\tvalidation_0-mlogloss:0.57173\tvalidation_1-mlogloss:1.13681\n",
      "[180]\tvalidation_0-mlogloss:0.54286\tvalidation_1-mlogloss:1.11783\n",
      "[190]\tvalidation_0-mlogloss:0.51526\tvalidation_1-mlogloss:1.09969\n",
      "[200]\tvalidation_0-mlogloss:0.49050\tvalidation_1-mlogloss:1.08298\n",
      "[210]\tvalidation_0-mlogloss:0.46731\tvalidation_1-mlogloss:1.06727\n",
      "[220]\tvalidation_0-mlogloss:0.44482\tvalidation_1-mlogloss:1.05203\n",
      "[230]\tvalidation_0-mlogloss:0.42360\tvalidation_1-mlogloss:1.03743\n",
      "[240]\tvalidation_0-mlogloss:0.40398\tvalidation_1-mlogloss:1.02392\n",
      "[250]\tvalidation_0-mlogloss:0.38575\tvalidation_1-mlogloss:1.01119\n",
      "[260]\tvalidation_0-mlogloss:0.36780\tvalidation_1-mlogloss:0.99852\n",
      "[270]\tvalidation_0-mlogloss:0.35083\tvalidation_1-mlogloss:0.98645\n",
      "[280]\tvalidation_0-mlogloss:0.33464\tvalidation_1-mlogloss:0.97477\n",
      "[290]\tvalidation_0-mlogloss:0.31958\tvalidation_1-mlogloss:0.96372\n",
      "[300]\tvalidation_0-mlogloss:0.30540\tvalidation_1-mlogloss:0.95313\n",
      "[310]\tvalidation_0-mlogloss:0.29163\tvalidation_1-mlogloss:0.94265\n",
      "[320]\tvalidation_0-mlogloss:0.27844\tvalidation_1-mlogloss:0.93250\n",
      "[330]\tvalidation_0-mlogloss:0.26627\tvalidation_1-mlogloss:0.92292\n",
      "[340]\tvalidation_0-mlogloss:0.25428\tvalidation_1-mlogloss:0.91347\n",
      "[350]\tvalidation_0-mlogloss:0.24325\tvalidation_1-mlogloss:0.90449\n",
      "[360]\tvalidation_0-mlogloss:0.23263\tvalidation_1-mlogloss:0.89564\n",
      "[370]\tvalidation_0-mlogloss:0.22238\tvalidation_1-mlogloss:0.88709\n",
      "[380]\tvalidation_0-mlogloss:0.21276\tvalidation_1-mlogloss:0.87884\n",
      "[390]\tvalidation_0-mlogloss:0.20347\tvalidation_1-mlogloss:0.87084\n",
      "[400]\tvalidation_0-mlogloss:0.19449\tvalidation_1-mlogloss:0.86289\n",
      "[410]\tvalidation_0-mlogloss:0.18620\tvalidation_1-mlogloss:0.85534\n",
      "[420]\tvalidation_0-mlogloss:0.17819\tvalidation_1-mlogloss:0.84797\n",
      "[430]\tvalidation_0-mlogloss:0.17030\tvalidation_1-mlogloss:0.84064\n",
      "[440]\tvalidation_0-mlogloss:0.16288\tvalidation_1-mlogloss:0.83355\n",
      "[450]\tvalidation_0-mlogloss:0.15575\tvalidation_1-mlogloss:0.82657\n",
      "[460]\tvalidation_0-mlogloss:0.14910\tvalidation_1-mlogloss:0.81993\n",
      "[470]\tvalidation_0-mlogloss:0.14255\tvalidation_1-mlogloss:0.81334\n",
      "[480]\tvalidation_0-mlogloss:0.13639\tvalidation_1-mlogloss:0.80679\n",
      "[490]\tvalidation_0-mlogloss:0.13048\tvalidation_1-mlogloss:0.80045\n",
      "[500]\tvalidation_0-mlogloss:0.12477\tvalidation_1-mlogloss:0.79431\n",
      "[510]\tvalidation_0-mlogloss:0.11954\tvalidation_1-mlogloss:0.78844\n",
      "[520]\tvalidation_0-mlogloss:0.11445\tvalidation_1-mlogloss:0.78260\n",
      "[530]\tvalidation_0-mlogloss:0.10955\tvalidation_1-mlogloss:0.77682\n",
      "[540]\tvalidation_0-mlogloss:0.10490\tvalidation_1-mlogloss:0.77119\n",
      "[550]\tvalidation_0-mlogloss:0.10037\tvalidation_1-mlogloss:0.76555\n",
      "[560]\tvalidation_0-mlogloss:0.09626\tvalidation_1-mlogloss:0.76035\n",
      "[570]\tvalidation_0-mlogloss:0.09237\tvalidation_1-mlogloss:0.75525\n",
      "[580]\tvalidation_0-mlogloss:0.08853\tvalidation_1-mlogloss:0.75014\n",
      "[590]\tvalidation_0-mlogloss:0.08485\tvalidation_1-mlogloss:0.74512\n",
      "[600]\tvalidation_0-mlogloss:0.08138\tvalidation_1-mlogloss:0.74016\n",
      "[610]\tvalidation_0-mlogloss:0.07804\tvalidation_1-mlogloss:0.73539\n",
      "[620]\tvalidation_0-mlogloss:0.07481\tvalidation_1-mlogloss:0.73067\n",
      "[630]\tvalidation_0-mlogloss:0.07181\tvalidation_1-mlogloss:0.72616\n",
      "[640]\tvalidation_0-mlogloss:0.06894\tvalidation_1-mlogloss:0.72173\n",
      "[650]\tvalidation_0-mlogloss:0.06613\tvalidation_1-mlogloss:0.71738\n",
      "[660]\tvalidation_0-mlogloss:0.06344\tvalidation_1-mlogloss:0.71305\n",
      "[670]\tvalidation_0-mlogloss:0.06099\tvalidation_1-mlogloss:0.70888\n",
      "[680]\tvalidation_0-mlogloss:0.05856\tvalidation_1-mlogloss:0.70473\n",
      "[690]\tvalidation_0-mlogloss:0.05624\tvalidation_1-mlogloss:0.70077\n",
      "[700]\tvalidation_0-mlogloss:0.05415\tvalidation_1-mlogloss:0.69689\n",
      "[710]\tvalidation_0-mlogloss:0.05207\tvalidation_1-mlogloss:0.69294\n",
      "[720]\tvalidation_0-mlogloss:0.05004\tvalidation_1-mlogloss:0.68911\n",
      "[730]\tvalidation_0-mlogloss:0.04817\tvalidation_1-mlogloss:0.68542\n",
      "[740]\tvalidation_0-mlogloss:0.04630\tvalidation_1-mlogloss:0.68182\n",
      "[750]\tvalidation_0-mlogloss:0.04459\tvalidation_1-mlogloss:0.67834\n",
      "[760]\tvalidation_0-mlogloss:0.04294\tvalidation_1-mlogloss:0.67491\n",
      "[770]\tvalidation_0-mlogloss:0.04134\tvalidation_1-mlogloss:0.67150\n",
      "[780]\tvalidation_0-mlogloss:0.03978\tvalidation_1-mlogloss:0.66809\n",
      "[790]\tvalidation_0-mlogloss:0.03830\tvalidation_1-mlogloss:0.66476\n",
      "[800]\tvalidation_0-mlogloss:0.03691\tvalidation_1-mlogloss:0.66154\n",
      "[810]\tvalidation_0-mlogloss:0.03556\tvalidation_1-mlogloss:0.65835\n",
      "[820]\tvalidation_0-mlogloss:0.03423\tvalidation_1-mlogloss:0.65516\n",
      "[830]\tvalidation_0-mlogloss:0.03299\tvalidation_1-mlogloss:0.65212\n",
      "[840]\tvalidation_0-mlogloss:0.03179\tvalidation_1-mlogloss:0.64911\n",
      "[850]\tvalidation_0-mlogloss:0.03070\tvalidation_1-mlogloss:0.64625\n",
      "[860]\tvalidation_0-mlogloss:0.02962\tvalidation_1-mlogloss:0.64328\n",
      "[870]\tvalidation_0-mlogloss:0.02862\tvalidation_1-mlogloss:0.64059\n",
      "[880]\tvalidation_0-mlogloss:0.02758\tvalidation_1-mlogloss:0.63777\n",
      "[890]\tvalidation_0-mlogloss:0.02664\tvalidation_1-mlogloss:0.63507\n",
      "[900]\tvalidation_0-mlogloss:0.02572\tvalidation_1-mlogloss:0.63241\n",
      "[910]\tvalidation_0-mlogloss:0.02485\tvalidation_1-mlogloss:0.62990\n",
      "[920]\tvalidation_0-mlogloss:0.02403\tvalidation_1-mlogloss:0.62745\n",
      "[930]\tvalidation_0-mlogloss:0.02325\tvalidation_1-mlogloss:0.62500\n",
      "[940]\tvalidation_0-mlogloss:0.02248\tvalidation_1-mlogloss:0.62259\n",
      "[950]\tvalidation_0-mlogloss:0.02175\tvalidation_1-mlogloss:0.62020\n",
      "[960]\tvalidation_0-mlogloss:0.02102\tvalidation_1-mlogloss:0.61773\n",
      "[970]\tvalidation_0-mlogloss:0.02033\tvalidation_1-mlogloss:0.61533\n",
      "[980]\tvalidation_0-mlogloss:0.01969\tvalidation_1-mlogloss:0.61318\n",
      "[990]\tvalidation_0-mlogloss:0.01906\tvalidation_1-mlogloss:0.61098\n",
      "[1000]\tvalidation_0-mlogloss:0.01846\tvalidation_1-mlogloss:0.60879\n",
      "[1010]\tvalidation_0-mlogloss:0.01789\tvalidation_1-mlogloss:0.60668\n",
      "[1020]\tvalidation_0-mlogloss:0.01735\tvalidation_1-mlogloss:0.60459\n",
      "[1030]\tvalidation_0-mlogloss:0.01682\tvalidation_1-mlogloss:0.60249\n",
      "[1040]\tvalidation_0-mlogloss:0.01630\tvalidation_1-mlogloss:0.60044\n",
      "[1050]\tvalidation_0-mlogloss:0.01582\tvalidation_1-mlogloss:0.59846\n",
      "[1060]\tvalidation_0-mlogloss:0.01534\tvalidation_1-mlogloss:0.59651\n",
      "[1070]\tvalidation_0-mlogloss:0.01488\tvalidation_1-mlogloss:0.59465\n",
      "[1080]\tvalidation_0-mlogloss:0.01445\tvalidation_1-mlogloss:0.59273\n",
      "[1090]\tvalidation_0-mlogloss:0.01403\tvalidation_1-mlogloss:0.59089\n",
      "[1100]\tvalidation_0-mlogloss:0.01364\tvalidation_1-mlogloss:0.58914\n",
      "[1110]\tvalidation_0-mlogloss:0.01325\tvalidation_1-mlogloss:0.58739\n",
      "[1120]\tvalidation_0-mlogloss:0.01288\tvalidation_1-mlogloss:0.58567\n",
      "[1130]\tvalidation_0-mlogloss:0.01252\tvalidation_1-mlogloss:0.58397\n",
      "[1140]\tvalidation_0-mlogloss:0.01217\tvalidation_1-mlogloss:0.58226\n",
      "[1150]\tvalidation_0-mlogloss:0.01184\tvalidation_1-mlogloss:0.58061\n",
      "[1160]\tvalidation_0-mlogloss:0.01153\tvalidation_1-mlogloss:0.57909\n",
      "[1170]\tvalidation_0-mlogloss:0.01122\tvalidation_1-mlogloss:0.57751\n",
      "[1180]\tvalidation_0-mlogloss:0.01093\tvalidation_1-mlogloss:0.57596\n",
      "[1190]\tvalidation_0-mlogloss:0.01064\tvalidation_1-mlogloss:0.57437\n",
      "[1200]\tvalidation_0-mlogloss:0.01037\tvalidation_1-mlogloss:0.57286\n",
      "[1210]\tvalidation_0-mlogloss:0.01011\tvalidation_1-mlogloss:0.57141\n",
      "[1220]\tvalidation_0-mlogloss:0.00985\tvalidation_1-mlogloss:0.57004\n",
      "[1230]\tvalidation_0-mlogloss:0.00961\tvalidation_1-mlogloss:0.56859\n",
      "[1240]\tvalidation_0-mlogloss:0.00938\tvalidation_1-mlogloss:0.56717\n",
      "[1250]\tvalidation_0-mlogloss:0.00914\tvalidation_1-mlogloss:0.56580\n",
      "[1260]\tvalidation_0-mlogloss:0.00893\tvalidation_1-mlogloss:0.56451\n",
      "[1270]\tvalidation_0-mlogloss:0.00871\tvalidation_1-mlogloss:0.56315\n",
      "[1280]\tvalidation_0-mlogloss:0.00849\tvalidation_1-mlogloss:0.56178\n",
      "[1290]\tvalidation_0-mlogloss:0.00828\tvalidation_1-mlogloss:0.56050\n",
      "[1300]\tvalidation_0-mlogloss:0.00809\tvalidation_1-mlogloss:0.55927\n",
      "[1310]\tvalidation_0-mlogloss:0.00790\tvalidation_1-mlogloss:0.55805\n",
      "[1320]\tvalidation_0-mlogloss:0.00772\tvalidation_1-mlogloss:0.55687\n",
      "[1330]\tvalidation_0-mlogloss:0.00755\tvalidation_1-mlogloss:0.55568\n",
      "[1340]\tvalidation_0-mlogloss:0.00738\tvalidation_1-mlogloss:0.55445\n",
      "[1350]\tvalidation_0-mlogloss:0.00721\tvalidation_1-mlogloss:0.55335\n",
      "[1360]\tvalidation_0-mlogloss:0.00705\tvalidation_1-mlogloss:0.55218\n",
      "[1370]\tvalidation_0-mlogloss:0.00689\tvalidation_1-mlogloss:0.55108\n",
      "[1380]\tvalidation_0-mlogloss:0.00675\tvalidation_1-mlogloss:0.54996\n",
      "[1390]\tvalidation_0-mlogloss:0.00660\tvalidation_1-mlogloss:0.54887\n",
      "[1400]\tvalidation_0-mlogloss:0.00647\tvalidation_1-mlogloss:0.54783\n",
      "[1410]\tvalidation_0-mlogloss:0.00633\tvalidation_1-mlogloss:0.54680\n",
      "[1420]\tvalidation_0-mlogloss:0.00620\tvalidation_1-mlogloss:0.54579\n",
      "[1430]\tvalidation_0-mlogloss:0.00607\tvalidation_1-mlogloss:0.54479\n",
      "[1440]\tvalidation_0-mlogloss:0.00594\tvalidation_1-mlogloss:0.54379\n",
      "[1450]\tvalidation_0-mlogloss:0.00582\tvalidation_1-mlogloss:0.54285\n",
      "[1460]\tvalidation_0-mlogloss:0.00571\tvalidation_1-mlogloss:0.54191\n",
      "[1470]\tvalidation_0-mlogloss:0.00560\tvalidation_1-mlogloss:0.54100\n",
      "[1480]\tvalidation_0-mlogloss:0.00549\tvalidation_1-mlogloss:0.54012\n",
      "[1490]\tvalidation_0-mlogloss:0.00538\tvalidation_1-mlogloss:0.53921\n",
      "[1500]\tvalidation_0-mlogloss:0.00528\tvalidation_1-mlogloss:0.53833\n",
      "[1510]\tvalidation_0-mlogloss:0.00517\tvalidation_1-mlogloss:0.53738\n",
      "[1520]\tvalidation_0-mlogloss:0.00508\tvalidation_1-mlogloss:0.53651\n",
      "[1530]\tvalidation_0-mlogloss:0.00498\tvalidation_1-mlogloss:0.53559\n",
      "[1540]\tvalidation_0-mlogloss:0.00489\tvalidation_1-mlogloss:0.53479\n",
      "[1550]\tvalidation_0-mlogloss:0.00480\tvalidation_1-mlogloss:0.53394\n",
      "[1560]\tvalidation_0-mlogloss:0.00471\tvalidation_1-mlogloss:0.53309\n",
      "[1570]\tvalidation_0-mlogloss:0.00463\tvalidation_1-mlogloss:0.53231\n",
      "[1580]\tvalidation_0-mlogloss:0.00454\tvalidation_1-mlogloss:0.53149\n",
      "[1590]\tvalidation_0-mlogloss:0.00446\tvalidation_1-mlogloss:0.53065\n",
      "[1600]\tvalidation_0-mlogloss:0.00438\tvalidation_1-mlogloss:0.52992\n",
      "[1610]\tvalidation_0-mlogloss:0.00431\tvalidation_1-mlogloss:0.52911\n",
      "[1620]\tvalidation_0-mlogloss:0.00423\tvalidation_1-mlogloss:0.52840\n",
      "[1630]\tvalidation_0-mlogloss:0.00416\tvalidation_1-mlogloss:0.52761\n",
      "[1640]\tvalidation_0-mlogloss:0.00409\tvalidation_1-mlogloss:0.52690\n",
      "[1650]\tvalidation_0-mlogloss:0.00402\tvalidation_1-mlogloss:0.52623\n",
      "[1660]\tvalidation_0-mlogloss:0.00396\tvalidation_1-mlogloss:0.52554\n",
      "[1670]\tvalidation_0-mlogloss:0.00389\tvalidation_1-mlogloss:0.52487\n",
      "[1680]\tvalidation_0-mlogloss:0.00383\tvalidation_1-mlogloss:0.52420\n",
      "[1690]\tvalidation_0-mlogloss:0.00376\tvalidation_1-mlogloss:0.52349\n",
      "[1700]\tvalidation_0-mlogloss:0.00370\tvalidation_1-mlogloss:0.52284\n",
      "[1710]\tvalidation_0-mlogloss:0.00365\tvalidation_1-mlogloss:0.52221\n",
      "[1720]\tvalidation_0-mlogloss:0.00359\tvalidation_1-mlogloss:0.52155\n",
      "[1730]\tvalidation_0-mlogloss:0.00353\tvalidation_1-mlogloss:0.52095\n",
      "[1740]\tvalidation_0-mlogloss:0.00348\tvalidation_1-mlogloss:0.52032\n",
      "[1750]\tvalidation_0-mlogloss:0.00343\tvalidation_1-mlogloss:0.51964\n",
      "[1760]\tvalidation_0-mlogloss:0.00337\tvalidation_1-mlogloss:0.51902\n",
      "[1770]\tvalidation_0-mlogloss:0.00332\tvalidation_1-mlogloss:0.51843\n",
      "[1780]\tvalidation_0-mlogloss:0.00327\tvalidation_1-mlogloss:0.51782\n",
      "[1790]\tvalidation_0-mlogloss:0.00323\tvalidation_1-mlogloss:0.51721\n",
      "[1800]\tvalidation_0-mlogloss:0.00318\tvalidation_1-mlogloss:0.51665\n",
      "[1810]\tvalidation_0-mlogloss:0.00313\tvalidation_1-mlogloss:0.51609\n",
      "[1820]\tvalidation_0-mlogloss:0.00309\tvalidation_1-mlogloss:0.51556\n",
      "[1830]\tvalidation_0-mlogloss:0.00305\tvalidation_1-mlogloss:0.51505\n",
      "[1840]\tvalidation_0-mlogloss:0.00300\tvalidation_1-mlogloss:0.51449\n",
      "[1850]\tvalidation_0-mlogloss:0.00296\tvalidation_1-mlogloss:0.51396\n",
      "[1860]\tvalidation_0-mlogloss:0.00292\tvalidation_1-mlogloss:0.51339\n",
      "[1870]\tvalidation_0-mlogloss:0.00288\tvalidation_1-mlogloss:0.51292\n",
      "[1880]\tvalidation_0-mlogloss:0.00284\tvalidation_1-mlogloss:0.51244\n",
      "[1890]\tvalidation_0-mlogloss:0.00280\tvalidation_1-mlogloss:0.51188\n",
      "[1900]\tvalidation_0-mlogloss:0.00276\tvalidation_1-mlogloss:0.51140\n",
      "[1910]\tvalidation_0-mlogloss:0.00273\tvalidation_1-mlogloss:0.51082\n",
      "[1920]\tvalidation_0-mlogloss:0.00269\tvalidation_1-mlogloss:0.51035\n",
      "[1930]\tvalidation_0-mlogloss:0.00265\tvalidation_1-mlogloss:0.50987\n",
      "[1940]\tvalidation_0-mlogloss:0.00262\tvalidation_1-mlogloss:0.50935\n",
      "[1950]\tvalidation_0-mlogloss:0.00259\tvalidation_1-mlogloss:0.50881\n",
      "[1960]\tvalidation_0-mlogloss:0.00255\tvalidation_1-mlogloss:0.50837\n",
      "[1970]\tvalidation_0-mlogloss:0.00252\tvalidation_1-mlogloss:0.50789\n",
      "[1980]\tvalidation_0-mlogloss:0.00249\tvalidation_1-mlogloss:0.50746\n",
      "[1990]\tvalidation_0-mlogloss:0.00246\tvalidation_1-mlogloss:0.50701\n",
      "[2000]\tvalidation_0-mlogloss:0.00243\tvalidation_1-mlogloss:0.50656\n",
      "[2010]\tvalidation_0-mlogloss:0.00240\tvalidation_1-mlogloss:0.50611\n",
      "[2020]\tvalidation_0-mlogloss:0.00237\tvalidation_1-mlogloss:0.50571\n",
      "[2030]\tvalidation_0-mlogloss:0.00234\tvalidation_1-mlogloss:0.50523\n",
      "[2040]\tvalidation_0-mlogloss:0.00231\tvalidation_1-mlogloss:0.50479\n",
      "[2050]\tvalidation_0-mlogloss:0.00228\tvalidation_1-mlogloss:0.50437\n",
      "[2060]\tvalidation_0-mlogloss:0.00226\tvalidation_1-mlogloss:0.50394\n",
      "[2070]\tvalidation_0-mlogloss:0.00223\tvalidation_1-mlogloss:0.50356\n",
      "[2080]\tvalidation_0-mlogloss:0.00221\tvalidation_1-mlogloss:0.50315\n",
      "[2090]\tvalidation_0-mlogloss:0.00218\tvalidation_1-mlogloss:0.50273\n",
      "[2100]\tvalidation_0-mlogloss:0.00216\tvalidation_1-mlogloss:0.50232\n",
      "[2110]\tvalidation_0-mlogloss:0.00213\tvalidation_1-mlogloss:0.50192\n",
      "[2120]\tvalidation_0-mlogloss:0.00211\tvalidation_1-mlogloss:0.50156\n",
      "[2130]\tvalidation_0-mlogloss:0.00209\tvalidation_1-mlogloss:0.50119\n",
      "[2140]\tvalidation_0-mlogloss:0.00206\tvalidation_1-mlogloss:0.50082\n",
      "[2150]\tvalidation_0-mlogloss:0.00204\tvalidation_1-mlogloss:0.50049\n",
      "[2160]\tvalidation_0-mlogloss:0.00202\tvalidation_1-mlogloss:0.50018\n",
      "[2170]\tvalidation_0-mlogloss:0.00200\tvalidation_1-mlogloss:0.49986\n",
      "[2180]\tvalidation_0-mlogloss:0.00198\tvalidation_1-mlogloss:0.49949\n",
      "[2190]\tvalidation_0-mlogloss:0.00196\tvalidation_1-mlogloss:0.49913\n",
      "[2200]\tvalidation_0-mlogloss:0.00194\tvalidation_1-mlogloss:0.49878\n",
      "[2210]\tvalidation_0-mlogloss:0.00192\tvalidation_1-mlogloss:0.49844\n",
      "[2220]\tvalidation_0-mlogloss:0.00190\tvalidation_1-mlogloss:0.49810\n",
      "[2230]\tvalidation_0-mlogloss:0.00188\tvalidation_1-mlogloss:0.49774\n",
      "[2240]\tvalidation_0-mlogloss:0.00186\tvalidation_1-mlogloss:0.49741\n",
      "[2250]\tvalidation_0-mlogloss:0.00184\tvalidation_1-mlogloss:0.49713\n",
      "[2260]\tvalidation_0-mlogloss:0.00182\tvalidation_1-mlogloss:0.49682\n",
      "[2270]\tvalidation_0-mlogloss:0.00180\tvalidation_1-mlogloss:0.49654\n",
      "[2280]\tvalidation_0-mlogloss:0.00179\tvalidation_1-mlogloss:0.49624\n",
      "[2290]\tvalidation_0-mlogloss:0.00177\tvalidation_1-mlogloss:0.49595\n",
      "[2300]\tvalidation_0-mlogloss:0.00175\tvalidation_1-mlogloss:0.49562\n",
      "[2310]\tvalidation_0-mlogloss:0.00173\tvalidation_1-mlogloss:0.49531\n",
      "[2320]\tvalidation_0-mlogloss:0.00172\tvalidation_1-mlogloss:0.49501\n",
      "[2330]\tvalidation_0-mlogloss:0.00170\tvalidation_1-mlogloss:0.49472\n",
      "[2340]\tvalidation_0-mlogloss:0.00169\tvalidation_1-mlogloss:0.49444\n",
      "[2350]\tvalidation_0-mlogloss:0.00167\tvalidation_1-mlogloss:0.49415\n",
      "[2360]\tvalidation_0-mlogloss:0.00166\tvalidation_1-mlogloss:0.49385\n",
      "[2370]\tvalidation_0-mlogloss:0.00164\tvalidation_1-mlogloss:0.49358\n",
      "[2380]\tvalidation_0-mlogloss:0.00163\tvalidation_1-mlogloss:0.49330\n",
      "[2390]\tvalidation_0-mlogloss:0.00161\tvalidation_1-mlogloss:0.49299\n",
      "[2400]\tvalidation_0-mlogloss:0.00160\tvalidation_1-mlogloss:0.49275\n",
      "[2410]\tvalidation_0-mlogloss:0.00158\tvalidation_1-mlogloss:0.49249\n",
      "[2420]\tvalidation_0-mlogloss:0.00157\tvalidation_1-mlogloss:0.49224\n",
      "[2430]\tvalidation_0-mlogloss:0.00155\tvalidation_1-mlogloss:0.49196\n",
      "[2440]\tvalidation_0-mlogloss:0.00154\tvalidation_1-mlogloss:0.49167\n",
      "[2450]\tvalidation_0-mlogloss:0.00153\tvalidation_1-mlogloss:0.49144\n",
      "[2460]\tvalidation_0-mlogloss:0.00152\tvalidation_1-mlogloss:0.49122\n",
      "[2470]\tvalidation_0-mlogloss:0.00150\tvalidation_1-mlogloss:0.49093\n",
      "[2480]\tvalidation_0-mlogloss:0.00149\tvalidation_1-mlogloss:0.49071\n",
      "[2490]\tvalidation_0-mlogloss:0.00148\tvalidation_1-mlogloss:0.49049\n",
      "[2500]\tvalidation_0-mlogloss:0.00147\tvalidation_1-mlogloss:0.49028\n",
      "[2510]\tvalidation_0-mlogloss:0.00145\tvalidation_1-mlogloss:0.49004\n",
      "[2520]\tvalidation_0-mlogloss:0.00144\tvalidation_1-mlogloss:0.48977\n",
      "[2530]\tvalidation_0-mlogloss:0.00143\tvalidation_1-mlogloss:0.48957\n",
      "[2540]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.48932\n",
      "[2550]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.48907\n",
      "[2560]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.48885\n",
      "[2570]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.48861\n",
      "[2580]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.48839\n",
      "[2590]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.48819\n",
      "[2600]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.48795\n",
      "[2610]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.48770\n",
      "[2620]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.48747\n",
      "[2630]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.48722\n",
      "[2640]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.48704\n",
      "[2650]\tvalidation_0-mlogloss:0.00130\tvalidation_1-mlogloss:0.48682\n",
      "[2660]\tvalidation_0-mlogloss:0.00129\tvalidation_1-mlogloss:0.48662\n",
      "[2670]\tvalidation_0-mlogloss:0.00129\tvalidation_1-mlogloss:0.48639\n",
      "[2680]\tvalidation_0-mlogloss:0.00128\tvalidation_1-mlogloss:0.48620\n",
      "[2690]\tvalidation_0-mlogloss:0.00127\tvalidation_1-mlogloss:0.48599\n",
      "[2700]\tvalidation_0-mlogloss:0.00126\tvalidation_1-mlogloss:0.48579\n",
      "[2710]\tvalidation_0-mlogloss:0.00125\tvalidation_1-mlogloss:0.48560\n",
      "[2720]\tvalidation_0-mlogloss:0.00124\tvalidation_1-mlogloss:0.48543\n",
      "[2730]\tvalidation_0-mlogloss:0.00123\tvalidation_1-mlogloss:0.48522\n",
      "[2740]\tvalidation_0-mlogloss:0.00122\tvalidation_1-mlogloss:0.48501\n",
      "[2750]\tvalidation_0-mlogloss:0.00121\tvalidation_1-mlogloss:0.48484\n",
      "[2760]\tvalidation_0-mlogloss:0.00121\tvalidation_1-mlogloss:0.48463\n",
      "[2770]\tvalidation_0-mlogloss:0.00120\tvalidation_1-mlogloss:0.48442\n",
      "[2780]\tvalidation_0-mlogloss:0.00119\tvalidation_1-mlogloss:0.48425\n",
      "[2790]\tvalidation_0-mlogloss:0.00118\tvalidation_1-mlogloss:0.48406\n",
      "[2800]\tvalidation_0-mlogloss:0.00117\tvalidation_1-mlogloss:0.48386\n",
      "[2810]\tvalidation_0-mlogloss:0.00117\tvalidation_1-mlogloss:0.48370\n",
      "[2820]\tvalidation_0-mlogloss:0.00116\tvalidation_1-mlogloss:0.48354\n",
      "[2830]\tvalidation_0-mlogloss:0.00115\tvalidation_1-mlogloss:0.48337\n",
      "[2840]\tvalidation_0-mlogloss:0.00114\tvalidation_1-mlogloss:0.48315\n",
      "[2850]\tvalidation_0-mlogloss:0.00114\tvalidation_1-mlogloss:0.48297\n",
      "[2860]\tvalidation_0-mlogloss:0.00113\tvalidation_1-mlogloss:0.48281\n",
      "[2870]\tvalidation_0-mlogloss:0.00112\tvalidation_1-mlogloss:0.48264\n",
      "[2880]\tvalidation_0-mlogloss:0.00111\tvalidation_1-mlogloss:0.48246\n",
      "[2890]\tvalidation_0-mlogloss:0.00111\tvalidation_1-mlogloss:0.48228\n",
      "[2900]\tvalidation_0-mlogloss:0.00110\tvalidation_1-mlogloss:0.48212\n",
      "[2910]\tvalidation_0-mlogloss:0.00109\tvalidation_1-mlogloss:0.48195\n",
      "[2920]\tvalidation_0-mlogloss:0.00109\tvalidation_1-mlogloss:0.48176\n",
      "[2930]\tvalidation_0-mlogloss:0.00108\tvalidation_1-mlogloss:0.48161\n",
      "[2940]\tvalidation_0-mlogloss:0.00107\tvalidation_1-mlogloss:0.48146\n",
      "[2950]\tvalidation_0-mlogloss:0.00107\tvalidation_1-mlogloss:0.48133\n",
      "[2960]\tvalidation_0-mlogloss:0.00106\tvalidation_1-mlogloss:0.48117\n",
      "[2970]\tvalidation_0-mlogloss:0.00106\tvalidation_1-mlogloss:0.48102\n",
      "[2980]\tvalidation_0-mlogloss:0.00105\tvalidation_1-mlogloss:0.48087\n",
      "[2990]\tvalidation_0-mlogloss:0.00104\tvalidation_1-mlogloss:0.48069\n",
      "[2999]\tvalidation_0-mlogloss:0.00104\tvalidation_1-mlogloss:0.48054\n",
      "entrainement gpu termine\n",
      "temps total 8437.7 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"lancement optimisation xgboost\")\n",
    "\n",
    "# config du modele champion\n",
    "# je pousse les parametres pour exploiter ta machine\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(le.classes_),\n",
    "    'n_estimators': 3000, # on vise haut l arret auto coupera avant\n",
    "    'max_depth': 8, # profondeur pour capter les nuances\n",
    "    'learning_rate': 0.05, # vitesse lente pour precision\n",
    "    'subsample': 0.8, # evite overfit\n",
    "    'colsample_bytree': 0.8,\n",
    "    'early_stopping_rounds': 50, # securite anti overfit\n",
    "    'eval_metric': 'mlogloss'\n",
    "}\n",
    "\n",
    "# gestion hardware\n",
    "if use_gpu:\n",
    "    params['tree_method'] = 'hist'\n",
    "    params['device'] = 'cuda'\n",
    "else:\n",
    "    params['tree_method'] = 'hist'\n",
    "    params['device'] = 'cpu'\n",
    "    params['n_jobs'] = -1\n",
    "\n",
    "model = xgb.XGBClassifier(**params)\n",
    "\n",
    "t_start = time.time()\n",
    "print(\"demarrage entrainement surveille\")\n",
    "\n",
    "try:\n",
    "    # je lance l apprentissage\n",
    "    # le verbose affiche le score regulierement\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "        verbose=10\n",
    "    )\n",
    "    print(\"entrainement gpu termine\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"echec gpu detection saturation memoire\")\n",
    "    print(\"bascule automatique sur cpu ram 128go\")\n",
    "    \n",
    "    # nettoyage avant reprise\n",
    "    if 'model' in globals(): del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # reconfig cpu forcee\n",
    "    params['device'] = 'cpu'\n",
    "    params['n_jobs'] = -1\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "        verbose=10\n",
    "    )\n",
    "    print(\"entrainement cpu termine\")\n",
    "\n",
    "duration = time.time() - t_start\n",
    "print(f\"temps total {duration:.1f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88aef700-1c2b-4874-b3d7-cd8d816bcf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyse des performances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [07:35:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score f1 final obtenu 0.8532\n",
      "rapport par classe\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      3000\n",
      "           1       0.78      0.78      0.78      3000\n",
      "           2       0.89      0.89      0.89      3000\n",
      "           3       0.93      0.98      0.95      3000\n",
      "           4       0.84      0.86      0.85      3000\n",
      "           5       0.93      0.93      0.93      3000\n",
      "           6       0.95      0.96      0.95      3000\n",
      "           7       0.76      0.62      0.68      3000\n",
      "           8       0.81      0.77      0.79      3000\n",
      "           9       0.78      0.85      0.82      3000\n",
      "          10       0.96      0.99      0.97      3000\n",
      "          11       0.86      0.87      0.86      3000\n",
      "          12       0.84      0.80      0.82      3000\n",
      "          13       0.83      0.73      0.78      3000\n",
      "          14       0.88      0.89      0.88      3000\n",
      "          15       0.93      0.99      0.96      3000\n",
      "          16       0.74      0.75      0.75      3000\n",
      "          17       0.96      0.98      0.97      3000\n",
      "          18       0.81      0.78      0.80      3000\n",
      "          19       0.77      0.74      0.76      3000\n",
      "          20       0.86      0.89      0.88      3000\n",
      "          21       0.86      0.79      0.82      3000\n",
      "          22       0.86      0.84      0.85      3000\n",
      "          23       0.87      0.85      0.86      3000\n",
      "          24       0.85      0.88      0.87      3000\n",
      "          25       0.85      0.89      0.87      3000\n",
      "          26       0.87      0.98      0.92      3000\n",
      "\n",
      "    accuracy                           0.85     81000\n",
      "   macro avg       0.85      0.85      0.85     81000\n",
      "weighted avg       0.85      0.85      0.85     81000\n",
      "\n",
      "modele sauvegarde sous C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\best_xgboost_gpu_model.json\n",
      "fichier csv detaille genere\n"
     ]
    }
   ],
   "source": [
    "print(\"analyse des performances\")\n",
    "\n",
    "# predictions\n",
    "preds = model.predict(x_val)\n",
    "score = f1_score(y_val, preds, average='weighted')\n",
    "\n",
    "print(f\"score f1 final obtenu {score:.4f}\")\n",
    "\n",
    "# rapport detaille\n",
    "print(\"rapport par classe\")\n",
    "print(classification_report(y_val, preds))\n",
    "\n",
    "# sauvegarde intelligente\n",
    "# je ne sauvegarde que si le modele est valide\n",
    "save_path = os.path.join(path_out, \"best_xgboost_gpu_model.json\")\n",
    "model.save_model(save_path)\n",
    "print(f\"modele sauvegarde sous {save_path}\")\n",
    "\n",
    "# generation csv pour comparaison\n",
    "results = pd.DataFrame({\n",
    "    'y_true': le.inverse_transform(y_val),\n",
    "    'y_pred': le.inverse_transform(preds)\n",
    "})\n",
    "csv_path = os.path.join(path_out, \"resultats_xgboost_detail.csv\")\n",
    "results.to_csv(csv_path, index=False)\n",
    "print(\"fichier csv detaille genere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f9ba5-5020-41fa-af6d-48f3ab51a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"analyse des performances\")\n",
    "\n",
    "# predictions\n",
    "preds = model.predict(x_val)\n",
    "score = f1_score(y_val, preds, average='weighted')\n",
    "\n",
    "print(f\"score f1 final obtenu {score:.4f}\")\n",
    "\n",
    "# rapport detaille\n",
    "print(\"rapport par classe\")\n",
    "print(classification_report(y_val, preds))\n",
    "\n",
    "# sauvegarde intelligente\n",
    "# je ne sauvegarde que si le modele est valide\n",
    "save_path = os.path.join(path_out, \"best_xgboost_gpu_model.json\")\n",
    "model.save_model(save_path)\n",
    "print(f\"modele sauvegarde sous {save_path}\")\n",
    "\n",
    "# generation csv pour comparaison\n",
    "results = pd.DataFrame({\n",
    "    'y_true': le.inverse_transform(y_val),\n",
    "    'y_pred': le.inverse_transform(preds)\n",
    "})\n",
    "csv_path = os.path.join(path_out, \"resultats_xgboost_detail.csv\")\n",
    "results.to_csv(csv_path, index=False)\n",
    "print(\"fichier csv detaille genere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ceaabe6-6028-40cc-bd15-0b64a3cc86e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> generation de l'encodeur manquant pour m2 <<<\n",
      "succes ! fichier généré ici : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\M2_IMAGE_XGBoost_Encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\">>> generation de l'encodeur manquant pour m2 <<<\")\n",
    "\n",
    "# chemins\n",
    "base_dir = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "output_dir = os.path.join(base_dir, \"implementation\", \"outputs\")\n",
    "\n",
    "# on recharge juste les y pour refaire l'encodeur à l'identique\n",
    "path_y = os.path.join(base_dir, \"data\", \"raw\", \"Y_train_CVw08PX.csv\")\n",
    "\n",
    "if os.path.exists(path_y):\n",
    "    # lecture\n",
    "    y = pd.read_csv(path_y)\n",
    "    \n",
    "    # correction nom colonne si besoin\n",
    "    if 'prdtypecode' not in y.columns: \n",
    "        y = y.rename(columns={y.columns[1]: 'prdtypecode'})\n",
    "        \n",
    "    # creation encodeur\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y['prdtypecode'])\n",
    "    \n",
    "    # sauvegarde immediate avec le bon nom m2\n",
    "    save_path = os.path.join(output_dir, \"M2_IMAGE_XGBoost_Encoder.pkl\")\n",
    "    joblib.dump(le, save_path)\n",
    "    \n",
    "    print(f\"succes ! fichier généré ici : {save_path}\")\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"erreur : fichier y_train introuvable. verifie tes dossiers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba9fd96-85e4-462a-b0e5-a626cbaa4e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> operation sauvetage m2 : re-alignement total <<<\n",
      "scan des images...\n",
      "encodeur m2 mis a jour.\n",
      "chargement resnet50...\n",
      "extraction des features pour tout le dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extraction: 100%|██████████| 1327/1327 [10:49<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features extraites : (84916, 2048)\n",
      "entrainement du nouveau xgboost...\n",
      "[0]\tvalidation_0-mlogloss:3.11062\n",
      "[100]\tvalidation_0-mlogloss:1.46294\n",
      "[200]\tvalidation_0-mlogloss:1.33674\n",
      "[300]\tvalidation_0-mlogloss:1.29742\n",
      "[400]\tvalidation_0-mlogloss:1.28092\n",
      "[500]\tvalidation_0-mlogloss:1.27525\n",
      "[572]\tvalidation_0-mlogloss:1.27521\n",
      ">>> M2 REPARÉ ET SAUVEGARDÉ ICI : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\M2_IMAGE_Classic_XGBoost.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [18:47:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score de validation du nouveau m2 : 0.6267\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "print(\">>> operation sauvetage m2 : re-alignement total <<<\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_data, \"implementation\", \"outputs\")\n",
    "batch_size = 64\n",
    "\n",
    "# 1. repérage des images (le radar infaillible)\n",
    "print(\"scan des images...\")\n",
    "real_path_img = None\n",
    "candidates = [\n",
    "    os.path.join(path_data, \"data\", \"raw\", \"images\", \"images\", \"image_train\"),\n",
    "    r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "]\n",
    "for p in candidates:\n",
    "    if os.path.exists(p) and len(os.listdir(p)) > 100:\n",
    "        real_path_img = p; break\n",
    "\n",
    "if not real_path_img: raise FileNotFoundError(\"dossier images introuvable\")\n",
    "\n",
    "# 2. preparation dataframe\n",
    "df = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"X_train_update.csv\"))\n",
    "y = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"Y_train_CVw08PX.csv\"))\n",
    "if 'prdtypecode' not in y.columns: y = y.rename(columns={y.columns[1]: 'prdtypecode'})\n",
    "df = df.merge(y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda r: os.path.join(real_path_img, f\"image_{r['imageid']}_product_{r['productid']}.jpg\"), axis=1)\n",
    "# filtre securite\n",
    "df = df[df['path'].apply(os.path.exists)]\n",
    "\n",
    "# 3. encodage labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['prdtypecode'])\n",
    "# on sauvegarde cet encodeur, c'est la reference absolue\n",
    "joblib.dump(le, os.path.join(path_out, \"M2_IMAGE_XGBoost_Encoder.pkl\"))\n",
    "print(\"encodeur m2 mis a jour.\")\n",
    "\n",
    "# 4. extracteur resnet (standard pytorch)\n",
    "print(\"chargement resnet50...\")\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "# on coupe la tete pour garder les 2048 features\n",
    "extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "extractor.to(device).eval()\n",
    "\n",
    "# 5. extraction features (c'est la partie un peu longue, ~10min)\n",
    "print(\"extraction des features pour tout le dataset...\")\n",
    "\n",
    "class FeatDS(Dataset):\n",
    "    def __init__(self, paths): self.paths = paths\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            img = cv2.imread(self.paths[i]); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img = img / 255.0\n",
    "            img = (img - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "            return torch.tensor(img.transpose(2,0,1), dtype=torch.float32)\n",
    "        except: return torch.zeros((3, 224, 224))\n",
    "\n",
    "ds = FeatDS(df['path'].values)\n",
    "loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "features_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader, desc=\"extraction\"):\n",
    "        batch = batch.to(device)\n",
    "        # squeeze pour virer les dimensions 1x1 inutiles\n",
    "        f = extractor(batch).squeeze(-1).squeeze(-1)\n",
    "        features_list.append(f.cpu().numpy())\n",
    "\n",
    "X_features = np.concatenate(features_list)\n",
    "print(f\"features extraites : {X_features.shape}\")\n",
    "\n",
    "# 6. entrainement xgboost express\n",
    "print(\"entrainement du nouveau xgboost...\")\n",
    "# split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_features, y_encoded, test_size=0.15, stratify=y_encoded, random_state=42)\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(le.classes_),\n",
    "    n_estimators=1000,     # suffisant pour etre bon\n",
    "    max_depth=6,           # standard\n",
    "    learning_rate=0.05,\n",
    "    tree_method='hist',    # acceleration gpu si dispo\n",
    "    device='cuda',\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "model_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# 7. sauvegarde du sauveur\n",
    "path_model = os.path.join(path_out, \"M2_IMAGE_Classic_XGBoost.json\")\n",
    "model_xgb.save_model(path_model)\n",
    "print(f\">>> M2 REPARÉ ET SAUVEGARDÉ ICI : {path_model}\")\n",
    "\n",
    "# petit check score\n",
    "acc = accuracy_score(y_val, model_xgb.predict(X_val))\n",
    "print(f\"score de validation du nouveau m2 : {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c377a2-9577-4b3e-82de-41a24c2d8161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on le re entraine avec nos spécificité \n"
     ]
    }
   ],
   "source": [
    "print(\"on le re entraine avec nos spécificité \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70434aa-fdcc-4aaf-b871-25dde9e12c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> etape 1 : generation des features obligatoires <<<\n",
      "je cherche les images...\n",
      "chargement extracteur...\n",
      "extraction features en cours (patience)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extract: 100%|██████████| 1327/1327 [09:40<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features pretes : (84916, 2048)\n",
      "\n",
      ">>> etape 2 : banc d essai vitesse xgboost <<<\n",
      "\n",
      "--- test config : RAPIDE (Depth 6) ---\n",
      "temps 10 arbres : 7.29s\n",
      "estim 5000 arbres : ~1.01 h\n",
      "ok valide\n",
      "\n",
      "--- test config : MOYEN (Depth 8) ---\n",
      "temps 10 arbres : 12.43s\n",
      "estim 5000 arbres : ~1.73 h\n",
      "ok valide\n",
      "\n",
      "--- test config : TITAN (Depth 10) ---\n",
      "temps 10 arbres : 16.77s\n",
      "estim 5000 arbres : ~2.33 h\n",
      "ok valide\n",
      "------------------------------\n",
      "recommandation : TITAN (Depth 10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\">>> etape 1 : generation des features obligatoires <<<\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "\n",
    "# 1. radar a images\n",
    "print(\"je cherche les images...\")\n",
    "real_path_img = None\n",
    "cands = [\n",
    "    os.path.join(path_data, \"data\", \"raw\", \"images\", \"images\", \"image_train\"),\n",
    "    r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "]\n",
    "for p in cands:\n",
    "    if os.path.exists(p) and len(os.listdir(p)) > 100: real_path_img = p; break\n",
    "\n",
    "if not real_path_img: raise FileNotFoundError(\"pas d images trouvees\")\n",
    "\n",
    "# 2. dataframe\n",
    "df = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"X_train_update.csv\"))\n",
    "y = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"Y_train_CVw08PX.csv\"))\n",
    "if 'prdtypecode' not in y.columns: y = y.rename(columns={y.columns[1]: 'prdtypecode'})\n",
    "df = df.merge(y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda r: os.path.join(real_path_img, f\"image_{r['imageid']}_product_{r['productid']}.jpg\"), axis=1)\n",
    "df = df[df['path'].apply(os.path.exists)] # secu\n",
    "\n",
    "# encodage\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['prdtypecode'])\n",
    "\n",
    "# 3. extracteur resnet\n",
    "print(\"chargement extracteur...\")\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "extractor = nn.Sequential(*list(resnet.children())[:-1]) # on vire la fin\n",
    "extractor.to(device).eval()\n",
    "\n",
    "# 4. boucle extraction\n",
    "print(\"extraction features en cours (patience)...\")\n",
    "class FeatDS(Dataset):\n",
    "    def __init__(self, p): self.p = p\n",
    "    def __len__(self): return len(self.p)\n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            im = cv2.imread(self.p[i]); im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            im = cv2.resize(im, (224, 224))\n",
    "            im = im / 255.0\n",
    "            im = (im - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "            return torch.tensor(im.transpose(2,0,1), dtype=torch.float32)\n",
    "        except: return torch.zeros((3,224,224))\n",
    "\n",
    "loader = DataLoader(FeatDS(df['path'].values), batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "feats = []\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(loader, desc=\"extract\"):\n",
    "        b = b.to(device)\n",
    "        f = extractor(b).squeeze(-1).squeeze(-1)\n",
    "        feats.append(f.cpu().numpy())\n",
    "\n",
    "X_features = np.concatenate(feats)\n",
    "print(f\"features pretes : {X_features.shape}\")\n",
    "\n",
    "print(\"\\n>>> etape 2 : banc d essai vitesse xgboost <<<\")\n",
    "\n",
    "# split test rapide\n",
    "X_sub, _, y_sub, _ = train_test_split(X_features, y_encoded, train_size=0.2, random_state=42)\n",
    "\n",
    "configs = [\n",
    "    {\"name\": \"RAPIDE (Depth 6)\", \"depth\": 6, \"lr\": 0.05},\n",
    "    {\"name\": \"MOYEN (Depth 8)\", \"depth\": 8, \"lr\": 0.03},\n",
    "    {\"name\": \"TITAN (Depth 10)\", \"depth\": 10, \"lr\": 0.01},\n",
    "]\n",
    "\n",
    "best_conf = None\n",
    "\n",
    "for c in configs:\n",
    "    print(f\"\\n--- test config : {c['name']} ---\")\n",
    "    \n",
    "    mod = xgb.XGBClassifier(\n",
    "        objective='multi:softmax', \n",
    "        num_class=len(le.classes_),\n",
    "        n_estimators=10, \n",
    "        max_depth=c['depth'],\n",
    "        learning_rate=c['lr'],\n",
    "        tree_method='hist',\n",
    "        device='cuda',\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8\n",
    "    )\n",
    "    \n",
    "    t0 = time.time()\n",
    "    mod.fit(X_sub, y_sub, verbose=False)\n",
    "    dt = time.time() - t0\n",
    "    \n",
    "    t_tree = dt / 10\n",
    "    est_h = (t_tree * 5000) / 3600\n",
    "    \n",
    "    print(f\"temps 10 arbres : {dt:.2f}s\")\n",
    "    print(f\"estim 5000 arbres : ~{est_h:.2f} h\")\n",
    "    \n",
    "    if est_h < 2.5: # tolerance 2h30\n",
    "        print(\"ok valide\")\n",
    "        best_conf = c\n",
    "    else:\n",
    "        print(\"trop lent\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "if best_conf:\n",
    "    print(f\"recommandation : {best_conf['name']}\")\n",
    "else:\n",
    "    print(\"tout est trop lent, reste sur depth 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb354a5-db0c-4381-a25e-ae1cc42b6e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> lancement titan depth 10 (validé par test) <<<\n",
      "features ok : (84916, 2048)\n",
      "split train val...\n",
      "config depth 10 activee...\n",
      "demarrage (environ 2h30)...\n",
      "[0]\tvalidation_0-mlogloss:3.24352\n",
      "[10]\tvalidation_0-mlogloss:2.96486\n",
      "[20]\tvalidation_0-mlogloss:2.77645\n",
      "[30]\tvalidation_0-mlogloss:2.63168\n",
      "[40]\tvalidation_0-mlogloss:2.51359\n",
      "[50]\tvalidation_0-mlogloss:2.41472\n",
      "[60]\tvalidation_0-mlogloss:2.32949\n",
      "[70]\tvalidation_0-mlogloss:2.25483\n",
      "[80]\tvalidation_0-mlogloss:2.18865\n",
      "[90]\tvalidation_0-mlogloss:2.12914\n",
      "[100]\tvalidation_0-mlogloss:2.07503\n",
      "[110]\tvalidation_0-mlogloss:2.02639\n",
      "[120]\tvalidation_0-mlogloss:1.98197\n",
      "[130]\tvalidation_0-mlogloss:1.94093\n",
      "[140]\tvalidation_0-mlogloss:1.90310\n",
      "[150]\tvalidation_0-mlogloss:1.86784\n",
      "[160]\tvalidation_0-mlogloss:1.83531\n",
      "[170]\tvalidation_0-mlogloss:1.80492\n",
      "[180]\tvalidation_0-mlogloss:1.77670\n",
      "[190]\tvalidation_0-mlogloss:1.75038\n",
      "[200]\tvalidation_0-mlogloss:1.72573\n",
      "[210]\tvalidation_0-mlogloss:1.70271\n",
      "[220]\tvalidation_0-mlogloss:1.68098\n",
      "[230]\tvalidation_0-mlogloss:1.66064\n",
      "[240]\tvalidation_0-mlogloss:1.64140\n",
      "[250]\tvalidation_0-mlogloss:1.62311\n",
      "[260]\tvalidation_0-mlogloss:1.60607\n",
      "[270]\tvalidation_0-mlogloss:1.58988\n",
      "[280]\tvalidation_0-mlogloss:1.57452\n",
      "[290]\tvalidation_0-mlogloss:1.56012\n",
      "[300]\tvalidation_0-mlogloss:1.54648\n",
      "[310]\tvalidation_0-mlogloss:1.53348\n",
      "[320]\tvalidation_0-mlogloss:1.52136\n",
      "[330]\tvalidation_0-mlogloss:1.50986\n",
      "[340]\tvalidation_0-mlogloss:1.49895\n",
      "[350]\tvalidation_0-mlogloss:1.48848\n",
      "[360]\tvalidation_0-mlogloss:1.47862\n",
      "[370]\tvalidation_0-mlogloss:1.46931\n",
      "[380]\tvalidation_0-mlogloss:1.46040\n",
      "[390]\tvalidation_0-mlogloss:1.45198\n",
      "[400]\tvalidation_0-mlogloss:1.44397\n",
      "[410]\tvalidation_0-mlogloss:1.43631\n",
      "[420]\tvalidation_0-mlogloss:1.42895\n",
      "[430]\tvalidation_0-mlogloss:1.42200\n",
      "[440]\tvalidation_0-mlogloss:1.41542\n",
      "[450]\tvalidation_0-mlogloss:1.40910\n",
      "[460]\tvalidation_0-mlogloss:1.40319\n",
      "[470]\tvalidation_0-mlogloss:1.39741\n",
      "[480]\tvalidation_0-mlogloss:1.39200\n",
      "[490]\tvalidation_0-mlogloss:1.38668\n",
      "[500]\tvalidation_0-mlogloss:1.38158\n",
      "[510]\tvalidation_0-mlogloss:1.37674\n",
      "[520]\tvalidation_0-mlogloss:1.37208\n",
      "[530]\tvalidation_0-mlogloss:1.36774\n",
      "[540]\tvalidation_0-mlogloss:1.36357\n",
      "[550]\tvalidation_0-mlogloss:1.35949\n",
      "[560]\tvalidation_0-mlogloss:1.35569\n",
      "[570]\tvalidation_0-mlogloss:1.35192\n",
      "[580]\tvalidation_0-mlogloss:1.34839\n",
      "[590]\tvalidation_0-mlogloss:1.34503\n",
      "[600]\tvalidation_0-mlogloss:1.34178\n",
      "[610]\tvalidation_0-mlogloss:1.33852\n",
      "[620]\tvalidation_0-mlogloss:1.33550\n",
      "[630]\tvalidation_0-mlogloss:1.33266\n",
      "[640]\tvalidation_0-mlogloss:1.32986\n",
      "[650]\tvalidation_0-mlogloss:1.32729\n",
      "[660]\tvalidation_0-mlogloss:1.32488\n",
      "[670]\tvalidation_0-mlogloss:1.32239\n",
      "[680]\tvalidation_0-mlogloss:1.32002\n",
      "[690]\tvalidation_0-mlogloss:1.31775\n",
      "[700]\tvalidation_0-mlogloss:1.31564\n",
      "[710]\tvalidation_0-mlogloss:1.31354\n",
      "[720]\tvalidation_0-mlogloss:1.31156\n",
      "[730]\tvalidation_0-mlogloss:1.30958\n",
      "[740]\tvalidation_0-mlogloss:1.30771\n",
      "[750]\tvalidation_0-mlogloss:1.30592\n",
      "[760]\tvalidation_0-mlogloss:1.30410\n",
      "[770]\tvalidation_0-mlogloss:1.30242\n",
      "[780]\tvalidation_0-mlogloss:1.30080\n",
      "[790]\tvalidation_0-mlogloss:1.29923\n",
      "[800]\tvalidation_0-mlogloss:1.29769\n",
      "[810]\tvalidation_0-mlogloss:1.29618\n",
      "[820]\tvalidation_0-mlogloss:1.29463\n",
      "[830]\tvalidation_0-mlogloss:1.29324\n",
      "[840]\tvalidation_0-mlogloss:1.29188\n",
      "[850]\tvalidation_0-mlogloss:1.29052\n",
      "[860]\tvalidation_0-mlogloss:1.28922\n",
      "[870]\tvalidation_0-mlogloss:1.28799\n",
      "[880]\tvalidation_0-mlogloss:1.28679\n",
      "[890]\tvalidation_0-mlogloss:1.28567\n",
      "[900]\tvalidation_0-mlogloss:1.28449\n",
      "[910]\tvalidation_0-mlogloss:1.28338\n",
      "[920]\tvalidation_0-mlogloss:1.28230\n",
      "[930]\tvalidation_0-mlogloss:1.28134\n",
      "[940]\tvalidation_0-mlogloss:1.28030\n",
      "[950]\tvalidation_0-mlogloss:1.27937\n",
      "[960]\tvalidation_0-mlogloss:1.27852\n",
      "[970]\tvalidation_0-mlogloss:1.27759\n",
      "[980]\tvalidation_0-mlogloss:1.27680\n",
      "[990]\tvalidation_0-mlogloss:1.27607\n",
      "[1000]\tvalidation_0-mlogloss:1.27533\n",
      "[1010]\tvalidation_0-mlogloss:1.27457\n",
      "[1020]\tvalidation_0-mlogloss:1.27376\n",
      "[1030]\tvalidation_0-mlogloss:1.27296\n",
      "[1040]\tvalidation_0-mlogloss:1.27223\n",
      "[1050]\tvalidation_0-mlogloss:1.27163\n",
      "[1060]\tvalidation_0-mlogloss:1.27096\n",
      "[1070]\tvalidation_0-mlogloss:1.27029\n",
      "[1080]\tvalidation_0-mlogloss:1.26966\n",
      "[1090]\tvalidation_0-mlogloss:1.26896\n",
      "[1100]\tvalidation_0-mlogloss:1.26847\n",
      "[1110]\tvalidation_0-mlogloss:1.26780\n",
      "[1120]\tvalidation_0-mlogloss:1.26722\n",
      "[1130]\tvalidation_0-mlogloss:1.26668\n",
      "[1140]\tvalidation_0-mlogloss:1.26621\n",
      "[1150]\tvalidation_0-mlogloss:1.26572\n",
      "[1160]\tvalidation_0-mlogloss:1.26526\n",
      "[1170]\tvalidation_0-mlogloss:1.26481\n",
      "[1180]\tvalidation_0-mlogloss:1.26432\n",
      "[1190]\tvalidation_0-mlogloss:1.26380\n",
      "[1200]\tvalidation_0-mlogloss:1.26352\n",
      "[1210]\tvalidation_0-mlogloss:1.26305\n",
      "[1220]\tvalidation_0-mlogloss:1.26269\n",
      "[1230]\tvalidation_0-mlogloss:1.26228\n",
      "[1240]\tvalidation_0-mlogloss:1.26191\n",
      "[1250]\tvalidation_0-mlogloss:1.26149\n",
      "[1260]\tvalidation_0-mlogloss:1.26109\n",
      "[1270]\tvalidation_0-mlogloss:1.26074\n",
      "[1280]\tvalidation_0-mlogloss:1.26039\n",
      "[1290]\tvalidation_0-mlogloss:1.26001\n",
      "[1300]\tvalidation_0-mlogloss:1.25966\n",
      "[1310]\tvalidation_0-mlogloss:1.25937\n",
      "[1320]\tvalidation_0-mlogloss:1.25909\n",
      "[1330]\tvalidation_0-mlogloss:1.25878\n",
      "[1340]\tvalidation_0-mlogloss:1.25846\n",
      "[1350]\tvalidation_0-mlogloss:1.25814\n",
      "[1360]\tvalidation_0-mlogloss:1.25789\n",
      "[1370]\tvalidation_0-mlogloss:1.25757\n",
      "[1380]\tvalidation_0-mlogloss:1.25729\n",
      "[1390]\tvalidation_0-mlogloss:1.25701\n",
      "[1400]\tvalidation_0-mlogloss:1.25676\n",
      "[1410]\tvalidation_0-mlogloss:1.25653\n",
      "[1420]\tvalidation_0-mlogloss:1.25631\n",
      "[1430]\tvalidation_0-mlogloss:1.25608\n",
      "[1440]\tvalidation_0-mlogloss:1.25582\n",
      "[1450]\tvalidation_0-mlogloss:1.25555\n",
      "[1460]\tvalidation_0-mlogloss:1.25535\n",
      "[1470]\tvalidation_0-mlogloss:1.25510\n",
      "[1480]\tvalidation_0-mlogloss:1.25494\n",
      "[1490]\tvalidation_0-mlogloss:1.25478\n",
      "[1500]\tvalidation_0-mlogloss:1.25459\n",
      "[1510]\tvalidation_0-mlogloss:1.25442\n",
      "[1520]\tvalidation_0-mlogloss:1.25422\n",
      "[1530]\tvalidation_0-mlogloss:1.25406\n",
      "[1540]\tvalidation_0-mlogloss:1.25386\n",
      "[1550]\tvalidation_0-mlogloss:1.25373\n",
      "[1560]\tvalidation_0-mlogloss:1.25360\n",
      "[1570]\tvalidation_0-mlogloss:1.25335\n",
      "[1580]\tvalidation_0-mlogloss:1.25320\n",
      "[1590]\tvalidation_0-mlogloss:1.25301\n",
      "[1600]\tvalidation_0-mlogloss:1.25286\n",
      "[1610]\tvalidation_0-mlogloss:1.25276\n",
      "[1620]\tvalidation_0-mlogloss:1.25265\n",
      "[1630]\tvalidation_0-mlogloss:1.25252\n",
      "[1640]\tvalidation_0-mlogloss:1.25240\n",
      "[1650]\tvalidation_0-mlogloss:1.25222\n",
      "[1660]\tvalidation_0-mlogloss:1.25207\n",
      "[1670]\tvalidation_0-mlogloss:1.25196\n",
      "[1680]\tvalidation_0-mlogloss:1.25182\n",
      "[1690]\tvalidation_0-mlogloss:1.25171\n",
      "[1700]\tvalidation_0-mlogloss:1.25162\n",
      "[1710]\tvalidation_0-mlogloss:1.25155\n",
      "[1720]\tvalidation_0-mlogloss:1.25145\n",
      "[1730]\tvalidation_0-mlogloss:1.25137\n",
      "[1740]\tvalidation_0-mlogloss:1.25126\n",
      "[1750]\tvalidation_0-mlogloss:1.25118\n",
      "[1760]\tvalidation_0-mlogloss:1.25109\n",
      "[1770]\tvalidation_0-mlogloss:1.25100\n",
      "[1780]\tvalidation_0-mlogloss:1.25089\n",
      "[1790]\tvalidation_0-mlogloss:1.25082\n",
      "[1800]\tvalidation_0-mlogloss:1.25076\n",
      "[1810]\tvalidation_0-mlogloss:1.25072\n",
      "[1820]\tvalidation_0-mlogloss:1.25063\n",
      "[1830]\tvalidation_0-mlogloss:1.25057\n",
      "[1840]\tvalidation_0-mlogloss:1.25049\n",
      "[1850]\tvalidation_0-mlogloss:1.25041\n",
      "[1860]\tvalidation_0-mlogloss:1.25032\n",
      "[1870]\tvalidation_0-mlogloss:1.25026\n",
      "[1880]\tvalidation_0-mlogloss:1.25021\n",
      "[1890]\tvalidation_0-mlogloss:1.25015\n",
      "[1900]\tvalidation_0-mlogloss:1.25007\n",
      "[1910]\tvalidation_0-mlogloss:1.24999\n",
      "[1920]\tvalidation_0-mlogloss:1.24991\n",
      "[1930]\tvalidation_0-mlogloss:1.24986\n",
      "[1940]\tvalidation_0-mlogloss:1.24981\n",
      "[1950]\tvalidation_0-mlogloss:1.24976\n",
      "[1960]\tvalidation_0-mlogloss:1.24972\n",
      "[1970]\tvalidation_0-mlogloss:1.24968\n",
      "[1980]\tvalidation_0-mlogloss:1.24967\n",
      "[1990]\tvalidation_0-mlogloss:1.24968\n",
      "[2000]\tvalidation_0-mlogloss:1.24964\n",
      "[2010]\tvalidation_0-mlogloss:1.24957\n",
      "[2020]\tvalidation_0-mlogloss:1.24955\n",
      "[2030]\tvalidation_0-mlogloss:1.24951\n",
      "[2040]\tvalidation_0-mlogloss:1.24948\n",
      "[2050]\tvalidation_0-mlogloss:1.24945\n",
      "[2060]\tvalidation_0-mlogloss:1.24944\n",
      "[2070]\tvalidation_0-mlogloss:1.24946\n",
      "[2080]\tvalidation_0-mlogloss:1.24943\n",
      "[2090]\tvalidation_0-mlogloss:1.24941\n",
      "[2100]\tvalidation_0-mlogloss:1.24937\n",
      "[2110]\tvalidation_0-mlogloss:1.24935\n",
      "[2120]\tvalidation_0-mlogloss:1.24934\n",
      "[2130]\tvalidation_0-mlogloss:1.24932\n",
      "[2140]\tvalidation_0-mlogloss:1.24933\n",
      "[2150]\tvalidation_0-mlogloss:1.24930\n",
      "[2160]\tvalidation_0-mlogloss:1.24928\n",
      "[2170]\tvalidation_0-mlogloss:1.24930\n",
      "[2180]\tvalidation_0-mlogloss:1.24928\n",
      "[2190]\tvalidation_0-mlogloss:1.24929\n",
      "[2200]\tvalidation_0-mlogloss:1.24928\n",
      "[2210]\tvalidation_0-mlogloss:1.24932\n",
      "[2220]\tvalidation_0-mlogloss:1.24929\n",
      "[2230]\tvalidation_0-mlogloss:1.24926\n",
      "[2240]\tvalidation_0-mlogloss:1.24927\n",
      "[2250]\tvalidation_0-mlogloss:1.24928\n",
      "[2260]\tvalidation_0-mlogloss:1.24925\n",
      "[2270]\tvalidation_0-mlogloss:1.24927\n",
      "[2280]\tvalidation_0-mlogloss:1.24927\n",
      "[2290]\tvalidation_0-mlogloss:1.24928\n",
      "[2300]\tvalidation_0-mlogloss:1.24930\n",
      "[2310]\tvalidation_0-mlogloss:1.24932\n",
      "[2320]\tvalidation_0-mlogloss:1.24928\n",
      "[2330]\tvalidation_0-mlogloss:1.24928\n",
      "[2340]\tvalidation_0-mlogloss:1.24931\n",
      "[2350]\tvalidation_0-mlogloss:1.24933\n",
      "[2360]\tvalidation_0-mlogloss:1.24939\n",
      "[2370]\tvalidation_0-mlogloss:1.24939\n",
      "[2380]\tvalidation_0-mlogloss:1.24939\n",
      "[2390]\tvalidation_0-mlogloss:1.24942\n",
      "[2400]\tvalidation_0-mlogloss:1.24941\n",
      "[2410]\tvalidation_0-mlogloss:1.24940\n",
      "[2420]\tvalidation_0-mlogloss:1.24940\n",
      "[2430]\tvalidation_0-mlogloss:1.24941\n",
      "[2440]\tvalidation_0-mlogloss:1.24941\n",
      "[2450]\tvalidation_0-mlogloss:1.24942\n",
      "[2460]\tvalidation_0-mlogloss:1.24942\n",
      "[2464]\tvalidation_0-mlogloss:1.24941\n",
      "calcul scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [18:39:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> TITAN FINI - acc: 0.6319 | f1: 0.6212\n",
      "sauvegardé : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\M2_IMAGE_Classic_XGBoost.json\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "print(\">>> lancement titan depth 10 (validé par test) <<<\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\")\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_data, \"implementation\", \"outputs\")\n",
    "\n",
    "# 1. verif features en memoire\n",
    "try:\n",
    "    if 'X_features' not in locals(): raise NameError(\"pas de features\")\n",
    "    print(f\"features ok : {X_features.shape}\")\n",
    "except:\n",
    "    raise SystemExit(\"erreur : relance l extraction avant le titan\")\n",
    "\n",
    "# 2. split (identique voting)\n",
    "print(\"split train val...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_features, y_encoded, \n",
    "    test_size=0.15, \n",
    "    stratify=y_encoded, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. config titan\n",
    "print(\"config depth 10 activee...\")\n",
    "model_xgb = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(le.classes_),\n",
    "    n_estimators=5000,       # endurance max\n",
    "    max_depth=10,            # mode titan validé\n",
    "    learning_rate=0.01,      # precision fine\n",
    "    subsample=0.8,           \n",
    "    colsample_bytree=0.8,    \n",
    "    gamma=0.2,               \n",
    "    tree_method='hist',      # gpu\n",
    "    device='cuda',\n",
    "    early_stopping_rounds=200 # patience augmentée car lr faible\n",
    ")\n",
    "\n",
    "# 4. entrainement\n",
    "print(\"demarrage (environ 2h30)...\")\n",
    "model_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=10 # affiche progression tous les 10 arbres\n",
    ")\n",
    "\n",
    "# 5. resultats\n",
    "print(\"calcul scores...\")\n",
    "y_pred = model_xgb.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "print(f\">>> TITAN FINI - acc: {acc:.4f} | f1: {f1:.4f}\")\n",
    "\n",
    "# sauvegarde\n",
    "path_model = os.path.join(path_out, \"M2_IMAGE_Classic_XGBoost.json\")\n",
    "model_xgb.save_model(path_model)\n",
    "print(f\"sauvegardé : {path_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc613fd-e2e8-4a8d-b0fe-0420986ebb8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ETAPE 1 : EXTRACTION DES FEATURES (OBLIGATOIRE) <<<\n",
      "Recherche des images...\n",
      "Chargement ResNet50...\n",
      "Extraction des features en cours (Patience ~10min)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction: 100%|██████████| 1327/1327 [07:02<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features prêtes : (84916, 2048)\n",
      "\n",
      ">>> ETAPE 2 : PROTOCOLE COMMANDO (RECHERCHE DU SCORE ELITE) <<<\n",
      "Préparation du terrain (Split)...\n",
      "\n",
      "--- MISSION : COMMANDO 1 (SNIPER) ---\n",
      "[0]\tvalidation_0-mlogloss:3.20469\n",
      "[50]\tvalidation_0-mlogloss:2.07340\n",
      "[100]\tvalidation_0-mlogloss:1.73100\n",
      "[150]\tvalidation_0-mlogloss:1.55275\n",
      "[200]\tvalidation_0-mlogloss:1.44954\n",
      "[250]\tvalidation_0-mlogloss:1.38642\n",
      "[300]\tvalidation_0-mlogloss:1.34732\n",
      "[350]\tvalidation_0-mlogloss:1.32220\n",
      "[400]\tvalidation_0-mlogloss:1.30536\n",
      "[450]\tvalidation_0-mlogloss:1.29403\n",
      "[500]\tvalidation_0-mlogloss:1.28605\n",
      "[550]\tvalidation_0-mlogloss:1.28043\n",
      "[600]\tvalidation_0-mlogloss:1.27693\n",
      "[650]\tvalidation_0-mlogloss:1.27398\n",
      "[700]\tvalidation_0-mlogloss:1.27215\n",
      "[750]\tvalidation_0-mlogloss:1.27076\n",
      "[800]\tvalidation_0-mlogloss:1.26946\n",
      "[850]\tvalidation_0-mlogloss:1.26887\n",
      "[900]\tvalidation_0-mlogloss:1.26827\n",
      "[950]\tvalidation_0-mlogloss:1.26799\n",
      "[1000]\tvalidation_0-mlogloss:1.26774\n",
      "[1050]\tvalidation_0-mlogloss:1.26762\n",
      "[1100]\tvalidation_0-mlogloss:1.26752\n",
      "[1150]\tvalidation_0-mlogloss:1.26748\n",
      "[1200]\tvalidation_0-mlogloss:1.26753\n",
      "[1250]\tvalidation_0-mlogloss:1.26766\n",
      "[1300]\tvalidation_0-mlogloss:1.26763\n",
      "[1334]\tvalidation_0-mlogloss:1.26767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [05:37:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTAT COMMANDO 1 (SNIPER) : F1 = 0.6192 | Acc = 0.6297 | Temps = 26640s\n",
      ">>> NOUVEAU LEADER : COMMANDO 1 (SNIPER)\n",
      "\n",
      "--- MISSION : COMMANDO 2 (RUSHER - EX 85%) ---\n",
      "[0]\tvalidation_0-mlogloss:3.10034\n",
      "[50]\tvalidation_0-mlogloss:1.63326\n",
      "[100]\tvalidation_0-mlogloss:1.40853\n",
      "[150]\tvalidation_0-mlogloss:1.33477\n",
      "[200]\tvalidation_0-mlogloss:1.30185\n",
      "[250]\tvalidation_0-mlogloss:1.28627\n",
      "[300]\tvalidation_0-mlogloss:1.27729\n",
      "[350]\tvalidation_0-mlogloss:1.27367\n",
      "[400]\tvalidation_0-mlogloss:1.27150\n",
      "[450]\tvalidation_0-mlogloss:1.27150\n",
      "[500]\tvalidation_0-mlogloss:1.27130\n",
      "[550]\tvalidation_0-mlogloss:1.27106\n",
      "[600]\tvalidation_0-mlogloss:1.27193\n",
      "[650]\tvalidation_0-mlogloss:1.27250\n",
      "[700]\tvalidation_0-mlogloss:1.27327\n",
      "[749]\tvalidation_0-mlogloss:1.27380\n",
      "RESULTAT COMMANDO 2 (RUSHER - EX 85%) : F1 = 0.6213 | Acc = 0.6312 | Temps = 960s\n",
      ">>> NOUVEAU LEADER : COMMANDO 2 (RUSHER - EX 85%)\n",
      "\n",
      "--- MISSION : COMMANDO 3 (TANK) ---\n",
      "[0]\tvalidation_0-mlogloss:3.16680\n",
      "[50]\tvalidation_0-mlogloss:1.86255\n",
      "[100]\tvalidation_0-mlogloss:1.55287\n",
      "[150]\tvalidation_0-mlogloss:1.42118\n",
      "[200]\tvalidation_0-mlogloss:1.35776\n",
      "[250]\tvalidation_0-mlogloss:1.32455\n",
      "[300]\tvalidation_0-mlogloss:1.30563\n",
      "[350]\tvalidation_0-mlogloss:1.29531\n",
      "[400]\tvalidation_0-mlogloss:1.28967\n",
      "[450]\tvalidation_0-mlogloss:1.28643\n",
      "[500]\tvalidation_0-mlogloss:1.28489\n",
      "[550]\tvalidation_0-mlogloss:1.28487\n",
      "[600]\tvalidation_0-mlogloss:1.28534\n",
      "[650]\tvalidation_0-mlogloss:1.28635\n",
      "[700]\tvalidation_0-mlogloss:1.28771\n",
      "[719]\tvalidation_0-mlogloss:1.28836\n",
      "RESULTAT COMMANDO 3 (TANK) : F1 = 0.6114 | Acc = 0.6222 | Temps = 2008s\n",
      "\n",
      "==============================\n",
      "VICTOIRE FINALE : COMMANDO 2 (RUSHER - EX 85%)\n",
      "MEILLEUR SCORE F1 : 0.6213\n",
      "==============================\n",
      "Modèle Champion sauvegardé sous : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\M2_IMAGE_Classic_XGBoost.json\n",
      "Prêt pour le Voting.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\">>> ETAPE 1 : EXTRACTION DES FEATURES (OBLIGATOIRE) <<<\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_data, \"implementation\", \"outputs\")\n",
    "\n",
    "# 1. radar a images\n",
    "print(\"Recherche des images...\")\n",
    "real_path_img = None\n",
    "cands = [\n",
    "    os.path.join(path_data, \"data\", \"raw\", \"images\", \"images\", \"image_train\"),\n",
    "    r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "]\n",
    "for p in cands:\n",
    "    if os.path.exists(p) and len(os.listdir(p)) > 100: real_path_img = p; break\n",
    "\n",
    "if not real_path_img: raise FileNotFoundError(\"Pas d'images trouvées.\")\n",
    "\n",
    "# 2. dataframe\n",
    "df = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"X_train_update.csv\"))\n",
    "y = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"Y_train_CVw08PX.csv\"))\n",
    "if 'prdtypecode' not in y.columns: y = y.rename(columns={y.columns[1]: 'prdtypecode'})\n",
    "df = df.merge(y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda r: os.path.join(real_path_img, f\"image_{r['imageid']}_product_{r['productid']}.jpg\"), axis=1)\n",
    "df = df[df['path'].apply(os.path.exists)]\n",
    "\n",
    "# encodage\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['prdtypecode'])\n",
    "\n",
    "# 3. extracteur resnet\n",
    "print(\"Chargement ResNet50...\")\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "extractor = nn.Sequential(*list(resnet.children())[:-1]) # on vire la fin\n",
    "extractor.to(device).eval()\n",
    "\n",
    "# 4. boucle extraction\n",
    "print(\"Extraction des features en cours (Patience ~10min)...\")\n",
    "class FeatDS(Dataset):\n",
    "    def __init__(self, p): self.p = p\n",
    "    def __len__(self): return len(self.p)\n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            im = cv2.imread(self.p[i]); im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            im = cv2.resize(im, (224, 224))\n",
    "            im = im / 255.0\n",
    "            im = (im - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "            return torch.tensor(im.transpose(2,0,1), dtype=torch.float32)\n",
    "        except: return torch.zeros((3,224,224))\n",
    "\n",
    "loader = DataLoader(FeatDS(df['path'].values), batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "feats = []\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(loader, desc=\"Extraction\"):\n",
    "        b = b.to(device)\n",
    "        f = extractor(b).squeeze(-1).squeeze(-1)\n",
    "        feats.append(f.cpu().numpy())\n",
    "\n",
    "X_features = np.concatenate(feats)\n",
    "print(f\"Features prêtes : {X_features.shape}\")\n",
    "\n",
    "# ICI COMMENCE LA PARTIE XGBOOST (SEPARÉE PROPREMENT)\n",
    "\n",
    "\n",
    "print(\"\\n>>> ETAPE 2 : PROTOCOLE COMMANDO (RECHERCHE DU SCORE ELITE) <<<\")\n",
    "\n",
    "# 1. split stratifié\n",
    "print(\"Préparation du terrain (Split)...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_features, y_encoded, \n",
    "    test_size=0.15, \n",
    "    stratify=y_encoded, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. definition des 3 profils\n",
    "configs = [\n",
    "    {\n",
    "        \"name\": \"COMMANDO 1 (SNIPER)\",\n",
    "        \"params\": {\n",
    "            'max_depth': 12,        # Tres profond\n",
    "            'learning_rate': 0.02,  # Lent et precis\n",
    "            'n_estimators': 4000,\n",
    "            'gamma': 0.2,           # Securite anti-overfit\n",
    "            'subsample': 0.85\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"COMMANDO 2 (RUSHER - EX 85%)\",\n",
    "        \"params\": {\n",
    "            'max_depth': 8,         # Standard efficace\n",
    "            'learning_rate': 0.05,  # Rapide\n",
    "            'n_estimators': 3000,\n",
    "            'gamma': 0.1,           \n",
    "            'subsample': 0.8\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"COMMANDO 3 (TANK)\",\n",
    "        \"params\": {\n",
    "            'max_depth': 10,\n",
    "            'learning_rate': 0.03,\n",
    "            'n_estimators': 3500,\n",
    "            'gamma': 0,             # AUCUN FREIN\n",
    "            'subsample': 0.9\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "best_score = 0\n",
    "best_model = None\n",
    "best_name = \"\"\n",
    "\n",
    "# 3. execution de la bataille\n",
    "for cfg in configs:\n",
    "    print(f\"\\n--- MISSION : {cfg['name']} ---\")\n",
    "    p = cfg['params']\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=len(le.classes_),\n",
    "        tree_method='hist',      # Moteur GPU\n",
    "        device='cuda',\n",
    "        early_stopping_rounds=200, # Patience\n",
    "        **p\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    # J'ai mis verbose=50 pour eviter de faire laguer ton navigateur\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        verbose=50  \n",
    "    )\n",
    "    duration = time.time() - start\n",
    "    \n",
    "    # eval\n",
    "    preds = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, preds, average='weighted')\n",
    "    acc = accuracy_score(y_val, preds)\n",
    "    \n",
    "    print(f\"RESULTAT {cfg['name']} : F1 = {f1:.4f} | Acc = {acc:.4f} | Temps = {duration:.0f}s\")\n",
    "    \n",
    "    # selection du champion\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_model = model\n",
    "        best_name = cfg['name']\n",
    "        print(f\">>> NOUVEAU LEADER : {best_name}\")\n",
    "\n",
    "# 4. sauvegarde du vainqueur\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"VICTOIRE FINALE : {best_name}\")\n",
    "print(f\"MEILLEUR SCORE F1 : {best_score:.4f}\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "path_model = os.path.join(path_out, \"M2_IMAGE_Classic_XGBoost.json\")\n",
    "if best_model:\n",
    "    best_model.save_model(path_model)\n",
    "    # sauvegarde encodeur obligatoire\n",
    "    joblib.dump(le, os.path.join(path_out, \"M2_IMAGE_XGBoost_Encoder.pkl\"))\n",
    "    print(f\"Modèle Champion sauvegardé sous : {path_model}\")\n",
    "else:\n",
    "    print(\"Echec de l'entrainement.\")\n",
    "\n",
    "print(\"Prêt pour le Voting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e687ec2-75d7-40fc-8940-484bec7734b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> OPÉRATION SAUVETAGE : AUGMENTATION COMPATIBLE VOTING <<<\n",
      "\n",
      "--- DEBUT EXTRACTION MULTIPLE ---\n",
      "Extraction version : Original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1327/1327 [09:58<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction version : Miroir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1327/1327 [10:51<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction version : Rotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1327/1327 [12:04<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONNÉES PRÊTES : (254748, 2048) (C'est ça la puissance !)\n",
      "\n",
      ">>> LANCEMENT XGBOOST SUR DONNÉES AUGMENTÉES <<<\n",
      "[0]\tvalidation_0-mlogloss:3.10264\n",
      "[50]\tvalidation_0-mlogloss:1.55982\n",
      "[100]\tvalidation_0-mlogloss:1.28229\n",
      "[150]\tvalidation_0-mlogloss:1.16014\n",
      "[200]\tvalidation_0-mlogloss:1.08543\n",
      "[250]\tvalidation_0-mlogloss:1.03192\n",
      "[300]\tvalidation_0-mlogloss:0.98979\n",
      "[350]\tvalidation_0-mlogloss:0.95513\n",
      "[400]\tvalidation_0-mlogloss:0.92646\n",
      "[450]\tvalidation_0-mlogloss:0.90150\n",
      "[500]\tvalidation_0-mlogloss:0.87918\n",
      "[550]\tvalidation_0-mlogloss:0.85988\n",
      "[600]\tvalidation_0-mlogloss:0.84320\n",
      "[650]\tvalidation_0-mlogloss:0.82833\n",
      "[700]\tvalidation_0-mlogloss:0.81535\n",
      "[750]\tvalidation_0-mlogloss:0.80411\n",
      "[800]\tvalidation_0-mlogloss:0.79489\n",
      "[850]\tvalidation_0-mlogloss:0.78649\n",
      "[900]\tvalidation_0-mlogloss:0.77934\n",
      "[950]\tvalidation_0-mlogloss:0.77321\n",
      "[1000]\tvalidation_0-mlogloss:0.76771\n",
      "[1050]\tvalidation_0-mlogloss:0.76292\n",
      "[1100]\tvalidation_0-mlogloss:0.75869\n",
      "[1150]\tvalidation_0-mlogloss:0.75509\n",
      "[1200]\tvalidation_0-mlogloss:0.75209\n",
      "[1250]\tvalidation_0-mlogloss:0.74907\n",
      "[1300]\tvalidation_0-mlogloss:0.74657\n",
      "[1350]\tvalidation_0-mlogloss:0.74398\n",
      "[1400]\tvalidation_0-mlogloss:0.74179\n",
      "[1450]\tvalidation_0-mlogloss:0.73973\n",
      "[1500]\tvalidation_0-mlogloss:0.73752\n",
      "[1550]\tvalidation_0-mlogloss:0.73583\n",
      "[1600]\tvalidation_0-mlogloss:0.73401\n",
      "[1650]\tvalidation_0-mlogloss:0.73228\n",
      "[1700]\tvalidation_0-mlogloss:0.73075\n",
      "[1750]\tvalidation_0-mlogloss:0.72936\n",
      "[1800]\tvalidation_0-mlogloss:0.72783\n",
      "[1850]\tvalidation_0-mlogloss:0.72675\n",
      "[1900]\tvalidation_0-mlogloss:0.72554\n",
      "[1950]\tvalidation_0-mlogloss:0.72439\n",
      "[2000]\tvalidation_0-mlogloss:0.72338\n",
      "[2050]\tvalidation_0-mlogloss:0.72234\n",
      "[2100]\tvalidation_0-mlogloss:0.72141\n",
      "[2150]\tvalidation_0-mlogloss:0.72035\n",
      "[2200]\tvalidation_0-mlogloss:0.71948\n",
      "[2250]\tvalidation_0-mlogloss:0.71864\n",
      "[2300]\tvalidation_0-mlogloss:0.71767\n",
      "[2350]\tvalidation_0-mlogloss:0.71688\n",
      "[2400]\tvalidation_0-mlogloss:0.71594\n",
      "[2450]\tvalidation_0-mlogloss:0.71512\n",
      "[2500]\tvalidation_0-mlogloss:0.71449\n",
      "[2550]\tvalidation_0-mlogloss:0.71378\n",
      "[2600]\tvalidation_0-mlogloss:0.71323\n",
      "[2650]\tvalidation_0-mlogloss:0.71254\n",
      "[2700]\tvalidation_0-mlogloss:0.71187\n",
      "[2750]\tvalidation_0-mlogloss:0.71144\n",
      "[2800]\tvalidation_0-mlogloss:0.71082\n",
      "[2850]\tvalidation_0-mlogloss:0.71040\n",
      "[2900]\tvalidation_0-mlogloss:0.70987\n",
      "[2950]\tvalidation_0-mlogloss:0.70938\n",
      "[2999]\tvalidation_0-mlogloss:0.70889\n",
      "\n",
      ">>> SCORE FINAL AVEC AUGMENTATION : 0.7906 <<<\n",
      "Sauvegardé. Ce modèle est compatible Voting (il mange du ResNet50).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import joblib\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "print(\">>> OPÉRATION SAUVETAGE : AUGMENTATION COMPATIBLE VOTING <<<\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_data, \"implementation\", \"outputs\")\n",
    "\n",
    "# 1. Chargement Dataframe\n",
    "df = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"X_train_update.csv\"))\n",
    "y = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"Y_train_CVw08PX.csv\"))\n",
    "if 'prdtypecode' not in y.columns: y = y.rename(columns={y.columns[1]: 'prdtypecode'})\n",
    "df = df.merge(y, left_index=True, right_index=True)\n",
    "\n",
    "# Recherche images\n",
    "path_img = os.path.join(path_data, \"data\", \"raw\", \"images\", \"images\", \"image_train\")\n",
    "if not os.path.exists(path_img): # fallback\n",
    "    path_img = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "\n",
    "df['path'] = df.apply(lambda r: os.path.join(path_img, f\"image_{r['imageid']}_product_{r['productid']}.jpg\"), axis=1)\n",
    "df = df[df['path'].apply(os.path.exists)]\n",
    "\n",
    "# Encodage labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_encoded = le.fit_transform(df['prdtypecode'])\n",
    "\n",
    "# 2. Préparation Augmentation + ResNet\n",
    "# C'est ici que la magie opère. On garde le meme ResNet que le voting.\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "extractor.to(device).eval()\n",
    "\n",
    "# Transformation de base (celle du voting)\n",
    "transform_base = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformation Miroir (Augmentation 1)\n",
    "transform_flip = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=1.0), # Force flip\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformation Rotation (Augmentation 2)\n",
    "transform_rot = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class AugmentDS(Dataset):\n",
    "    def __init__(self, paths, labels, transform):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            # On utilise PIL pour etre compatible avec transforms\n",
    "            img = Image.open(self.paths[i]).convert('RGB')\n",
    "            img = self.transform(img)\n",
    "            return img, self.labels[i]\n",
    "        except:\n",
    "            return torch.zeros((3,224,224)), self.labels[i]\n",
    "\n",
    "# 3. Extraction Massive (x3)\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "configs_aug = [\n",
    "    (\"Original\", transform_base),\n",
    "    (\"Miroir\", transform_flip),\n",
    "    (\"Rotation\", transform_rot)\n",
    "]\n",
    "\n",
    "print(\"\\n--- DEBUT EXTRACTION MULTIPLE ---\")\n",
    "for name, trans in configs_aug:\n",
    "    print(f\"Extraction version : {name}\")\n",
    "    ds = AugmentDS(df['path'].values, y_encoded, trans)\n",
    "    loader = DataLoader(ds, batch_size=64, shuffle=False, num_workers=0)\n",
    "    \n",
    "    current_feats = []\n",
    "    with torch.no_grad():\n",
    "        for bx, by in tqdm(loader):\n",
    "            bx = bx.to(device)\n",
    "            f = extractor(bx).squeeze(-1).squeeze(-1)\n",
    "            current_feats.append(f.cpu().numpy())\n",
    "            \n",
    "    all_features.append(np.concatenate(current_feats))\n",
    "    all_labels.append(y_encoded) # On duplique les labels aussi\n",
    "\n",
    "# Fusion\n",
    "X_final = np.concatenate(all_features)\n",
    "y_final = np.concatenate(all_labels)\n",
    "\n",
    "print(f\"\\nDONNÉES PRÊTES : {X_final.shape} (C'est ça la puissance !)\")\n",
    "\n",
    "# 4. Entraînement XGBoost (Config Rusher)\n",
    "print(\"\\n>>> LANCEMENT XGBOOST SUR DONNÉES AUGMENTÉES <<<\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_final, y_final, test_size=0.1, stratify=y_final, random_state=42\n",
    ")\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(le.classes_),\n",
    "    tree_method='hist',\n",
    "    device='cuda',\n",
    "    # Parametres Rusher optimisés\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=3000,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# 5. Sauvegarde et Verdict\n",
    "preds = model.predict(X_val)\n",
    "f1 = f1_score(y_val, preds, average='weighted')\n",
    "print(f\"\\n>>> SCORE FINAL AVEC AUGMENTATION : {f1:.4f} <<<\")\n",
    "\n",
    "path_model = os.path.join(path_out, \"M2_IMAGE_Classic_XGBoost.json\")\n",
    "model.save_model(path_model)\n",
    "joblib.dump(le, os.path.join(path_out, \"M2_IMAGE_XGBoost_Encoder.pkl\"))\n",
    "print(\"Sauvegardé. Ce modèle est compatible Voting (il mange du ResNet50).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306d025d-74cf-4f33-9b7f-4d16207df289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> LANCEMENT DU FINAL PUSH (8000 ARBRES) <<<\n",
      "Entraînement sur 254748 images (Original + Miroir + Rotation)\n",
      "Démarrage... (Va prendre un moment, observe le loss)\n",
      "[0]\tvalidation_0-mlogloss:3.13731\n",
      "[100]\tvalidation_0-mlogloss:1.35791\n",
      "[200]\tvalidation_0-mlogloss:1.13826\n",
      "[300]\tvalidation_0-mlogloss:1.03754\n",
      "[400]\tvalidation_0-mlogloss:0.97148\n",
      "[500]\tvalidation_0-mlogloss:0.92240\n",
      "[600]\tvalidation_0-mlogloss:0.88376\n",
      "[700]\tvalidation_0-mlogloss:0.85240\n",
      "[800]\tvalidation_0-mlogloss:0.82677\n",
      "[900]\tvalidation_0-mlogloss:0.80617\n",
      "[1000]\tvalidation_0-mlogloss:0.78994\n",
      "[1100]\tvalidation_0-mlogloss:0.77718\n",
      "[1200]\tvalidation_0-mlogloss:0.76691\n",
      "[1300]\tvalidation_0-mlogloss:0.75855\n",
      "[1400]\tvalidation_0-mlogloss:0.75155\n",
      "[1500]\tvalidation_0-mlogloss:0.74576\n",
      "[1600]\tvalidation_0-mlogloss:0.74103\n",
      "[1700]\tvalidation_0-mlogloss:0.73698\n",
      "[1800]\tvalidation_0-mlogloss:0.73342\n",
      "[1900]\tvalidation_0-mlogloss:0.73017\n",
      "[2000]\tvalidation_0-mlogloss:0.72733\n",
      "[2100]\tvalidation_0-mlogloss:0.72458\n",
      "[2200]\tvalidation_0-mlogloss:0.72197\n",
      "[2300]\tvalidation_0-mlogloss:0.71988\n",
      "[2400]\tvalidation_0-mlogloss:0.71803\n",
      "[2500]\tvalidation_0-mlogloss:0.71619\n",
      "[2600]\tvalidation_0-mlogloss:0.71442\n",
      "[2700]\tvalidation_0-mlogloss:0.71277\n",
      "[2800]\tvalidation_0-mlogloss:0.71130\n",
      "[2900]\tvalidation_0-mlogloss:0.70987\n",
      "[3000]\tvalidation_0-mlogloss:0.70853\n",
      "[3100]\tvalidation_0-mlogloss:0.70734\n",
      "[3200]\tvalidation_0-mlogloss:0.70634\n",
      "[3300]\tvalidation_0-mlogloss:0.70542\n",
      "[3400]\tvalidation_0-mlogloss:0.70451\n",
      "[3500]\tvalidation_0-mlogloss:0.70350\n",
      "[3600]\tvalidation_0-mlogloss:0.70277\n",
      "[3700]\tvalidation_0-mlogloss:0.70192\n",
      "[3800]\tvalidation_0-mlogloss:0.70118\n",
      "[3900]\tvalidation_0-mlogloss:0.70050\n",
      "[4000]\tvalidation_0-mlogloss:0.69979\n",
      "[4100]\tvalidation_0-mlogloss:0.69930\n",
      "[4200]\tvalidation_0-mlogloss:0.69878\n",
      "[4300]\tvalidation_0-mlogloss:0.69832\n",
      "[4400]\tvalidation_0-mlogloss:0.69771\n",
      "[4500]\tvalidation_0-mlogloss:0.69720\n",
      "[4600]\tvalidation_0-mlogloss:0.69687\n",
      "[4700]\tvalidation_0-mlogloss:0.69632\n",
      "[4800]\tvalidation_0-mlogloss:0.69595\n",
      "[4900]\tvalidation_0-mlogloss:0.69564\n",
      "[5000]\tvalidation_0-mlogloss:0.69517\n",
      "[5100]\tvalidation_0-mlogloss:0.69487\n",
      "[5200]\tvalidation_0-mlogloss:0.69459\n",
      "[5300]\tvalidation_0-mlogloss:0.69447\n",
      "[5400]\tvalidation_0-mlogloss:0.69434\n",
      "[5500]\tvalidation_0-mlogloss:0.69435\n",
      "[5600]\tvalidation_0-mlogloss:0.69430\n",
      "[5700]\tvalidation_0-mlogloss:0.69421\n",
      "[5800]\tvalidation_0-mlogloss:0.69404\n",
      "[5900]\tvalidation_0-mlogloss:0.69389\n",
      "[6000]\tvalidation_0-mlogloss:0.69376\n",
      "[6100]\tvalidation_0-mlogloss:0.69356\n",
      "[6200]\tvalidation_0-mlogloss:0.69344\n",
      "[6300]\tvalidation_0-mlogloss:0.69325\n",
      "[6400]\tvalidation_0-mlogloss:0.69327\n",
      "[6500]\tvalidation_0-mlogloss:0.69330\n",
      "[6600]\tvalidation_0-mlogloss:0.69331\n",
      "[6700]\tvalidation_0-mlogloss:0.69338\n",
      "[6771]\tvalidation_0-mlogloss:0.69340\n",
      "\n",
      ">>> RESULTAT FINAL PUSH : F1 = 0.8012 | Acc = 0.8027\n",
      "Temps : 11961s\n",
      "Modèle écrasé et sauvegardé : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\M2_IMAGE_Classic_XGBoost.json\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "print(\">>> LANCEMENT DU FINAL PUSH (8000 ARBRES) <<<\")\n",
    "\n",
    "# Verif que les données augmentées sont là\n",
    "if 'X_final' not in locals() or 'y_final' not in locals():\n",
    "    raise SystemExit(\"ERREUR : Les données augmentées (X_final) ne sont plus en mémoire. Ne relance pas tout, relance juste la fin de l'extraction précédente.\")\n",
    "\n",
    "print(f\"Entraînement sur {X_final.shape[0]} images (Original + Miroir + Rotation)\")\n",
    "\n",
    "# Config \"Marathon\"\n",
    "# On baisse le learning rate a 0.04 pour profiter des 8000 arbres\n",
    "# On garde la depth 8 qui marche bien\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(le.classes_),\n",
    "    tree_method='hist',\n",
    "    device='cuda',\n",
    "    max_depth=8,            # On garde ce qui marche\n",
    "    learning_rate=0.04,     # Un poil plus fin car on a le temps\n",
    "    n_estimators=8000,      # On pousse le bouchon\n",
    "    subsample=0.85,         # On augmente un peu car on a beaucoup de data\n",
    "    colsample_bytree=0.8,\n",
    "    early_stopping_rounds=300 # On lui laisse le temps de respirer\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "print(\"Démarrage... (Va prendre un moment, observe le loss)\")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=100 # Point tous les 100\n",
    ")\n",
    "\n",
    "duration = time.time() - start\n",
    "\n",
    "# Verdict\n",
    "preds = model.predict(X_val)\n",
    "f1 = f1_score(y_val, preds, average='weighted')\n",
    "acc = accuracy_score(y_val, preds)\n",
    "\n",
    "print(f\"\\n>>> RESULTAT FINAL PUSH : F1 = {f1:.4f} | Acc = {acc:.4f}\")\n",
    "print(f\"Temps : {duration:.0f}s\")\n",
    "\n",
    "# Si on dépasse 80%, c'est champagne.\n",
    "path_model = os.path.join(path_out, \"M2_IMAGE_Classic_XGBoost.json\")\n",
    "model.save_model(path_model)\n",
    "print(f\"Modèle écrasé et sauvegardé : {path_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1f4ddb-6506-4c99-8ed7-468c7ca36a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> reation du fichier pkl manquant <<<\n",
      "encodeur pret. classes detectees : 27\n",
      "sauvegarde ok sous : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\M2_IMAGE_XGBoost_Encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from sklearn import preprocessing\n",
    "\n",
    "print(\">>> reation du fichier pkl manquant <<<\")\n",
    "\n",
    "# config\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_data, \"implementation\", \"outputs\")\n",
    "\n",
    "# 1 chargement des cibles originales\n",
    "df_y = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"Y_train_CVw08PX.csv\"))\n",
    "\n",
    "# secu nom colonne\n",
    "if 'prdtypecode' not in df_y.columns: \n",
    "    df_y = df_y.rename(columns={df_y.columns[1]: 'prdtypecode'})\n",
    "\n",
    "# 2 recreation encodeur\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_y['prdtypecode'])\n",
    "\n",
    "print(f\"encodeur pret. classes detectees : {len(le.classes_)}\")\n",
    "\n",
    "# 3 sauvegarde\n",
    "path_pkl = os.path.join(path_out, \"M2_IMAGE_XGBoost_Encoder.pkl\")\n",
    "joblib.dump(le, path_pkl)\n",
    "\n",
    "print(f\"sauvegarde ok sous : {path_pkl}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass_tooling",
   "language": "python",
   "name": "masterclass_tooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
