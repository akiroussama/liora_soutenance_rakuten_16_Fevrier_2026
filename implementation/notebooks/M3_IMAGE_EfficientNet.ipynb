{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b375ff-ddd5-4872-887d-dab5a075b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ mode gpu activ√© : NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# config paths\n",
    "# attention chemin corrige suite au debug precedent\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "IMG_DIR = os.path.join(PROJECT_ROOT, \"data\", \"raw\", \"images\", \"images\", \"image_train\")\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "\n",
    "# params light pr tourner partout\n",
    "BATCH_SIZE = 32 \n",
    "IMG_SIZE = (224, 224) # standard efficientnet b0\n",
    "EPOCHS = 5\n",
    "LR = 1e-3\n",
    "\n",
    "# auto-switch gpu/cpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"üöÄ mode gpu activ√© : {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"‚ö†Ô∏è pas de gpu d√©tect√©. passage en mode cpu (sera plus lent mais fonctionnel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce1e585-84bd-40e3-bf4f-47902908f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ data ready : 67932 train / 16984 val\n"
     ]
    }
   ],
   "source": [
    "# load csvs\n",
    "csv_path = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "\n",
    "# chemin img\n",
    "df['filename'] = df.apply(lambda x: f\"image_{x['imageid']}_product_{x['productid']}.jpg\", axis=1)\n",
    "df['path'] = df['filename'].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "# split train/val\n",
    "# on garde un bon morceau pr valider le score\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "print(f\"‚úÖ data ready : {len(train_df)} train / {len(val_df)} val\")\n",
    "\n",
    "# dataset class\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try:\n",
    "            # conversion rgb obligatoire\n",
    "            img = Image.open(row['path']).convert(\"RGB\")\n",
    "        except:\n",
    "            # fallback noir si erreur fichier\n",
    "            img = Image.new('RGB', IMG_SIZE, (0, 0, 0))\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "\n",
    "# transformations standard (pas trop lourd pr cpu)\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# loaders\n",
    "# num_workers=0 pr eviter deadlock windows si cpu\n",
    "train_ds = SimpleDataset(train_df, transform=trans)\n",
    "val_ds = SimpleDataset(val_df, transform=trans)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd40dcf5-a7cb-4662-a915-6e5c679d1d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è init modele classique (efficientnet_b0)...\n",
      "‚úÖ modele charg√© sur cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"üõ†Ô∏è init modele classique (efficientnet_b0)...\")\n",
    "\n",
    "# load poids imagenet par defaut\n",
    "model = models.efficientnet_b0(weights=\"DEFAULT\")\n",
    "\n",
    "# freeze backbone (gain temps enorme + moins lourd pr cpu)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# replace head pr nos 27 classes\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "print(f\"‚úÖ modele charg√© sur {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38d382e8-c3d1-408f-8b86-f77bf48a44a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîì d√©blocage du modele complet pour booster le score...\n",
      "üî• start fine-tuning (10 epochs max)...\n",
      "üéØ objectif : > 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 1 | batch 2100 | loss 1.1315\n",
      "‚úÖ end ep 1 | time 485s | loss 1.4413 | f1 0.6278 | lr 0.000100\n",
      "   üíæ new best score saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 2 | batch 2100 | loss 0.8902\n",
      "‚úÖ end ep 2 | time 535s | loss 1.1139 | f1 0.6536 | lr 0.000100\n",
      "   üíæ new best score saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 3 | batch 2100 | loss 0.7591\n",
      "‚úÖ end ep 3 | time 515s | loss 0.9234 | f1 0.6623 | lr 0.000100\n",
      "   üíæ new best score saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 4 | batch 2100 | loss 1.0752\n",
      "‚úÖ end ep 4 | time 487s | loss 0.7700 | f1 0.6694 | lr 0.000100\n",
      "   üíæ new best score saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 5 | batch 2100 | loss 0.8867\n",
      "‚úÖ end ep 5 | time 488s | loss 0.6346 | f1 0.6750 | lr 0.000100\n",
      "   üíæ new best score saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 6 | batch 2100 | loss 0.4635\n",
      "‚úÖ end ep 6 | time 487s | loss 0.5282 | f1 0.6768 | lr 0.000100\n",
      "   üíæ new best score saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 7 | batch 2100 | loss 0.2748\n",
      "‚úÖ end ep 7 | time 483s | loss 0.4341 | f1 0.6712 | lr 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 8 | batch 2100 | loss 0.0851\n",
      "‚úÖ end ep 8 | time 481s | loss 0.3620 | f1 0.6692 | lr 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 9 | batch 2100 | loss 0.2423\n",
      "‚úÖ end ep 9 | time 483s | loss 0.3001 | f1 0.6689 | lr 0.000020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_49576\\1046154534.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ep 10 | batch 2100 | loss 0.3172\n",
      "‚úÖ end ep 10 | time 483s | loss 0.2046 | f1 0.6788 | lr 0.000020\n",
      "   üíæ new best score saved.\n",
      "üèÅ fin training classique. meilleur f1 : 0.6788\n"
     ]
    }
   ],
   "source": [
    "# --- OPTIMISATION : FINE TUNING (DEBRIDAGE) ---\n",
    "# on debloque tout le modele pour qu'il apprenne vraiment\n",
    "print(\"üîì d√©blocage du modele complet pour booster le score...\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# config \"douce\" pour ne pas casser les poids existants\n",
    "# on passe en AdamW (meilleur) avec un learning rate faible\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# scheduler : si ca stagne 2 epochs, on divise le lr par 5\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.2, patience=2\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history = {'f1': []}\n",
    "best_f1 = 0.0\n",
    "\n",
    "print(\"üî• start fine-tuning (10 epochs max)...\")\n",
    "print(\"üéØ objectif : > 0.75\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    loss_ep = 0.0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for i, (imgs, lbls) in enumerate(train_loader):\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # autocast pas obligatoire ici car modele leger, mais bon si gpu dispo\n",
    "        if device.type == 'cuda':\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = model(imgs)\n",
    "                loss = criterion(out, lbls)\n",
    "            \n",
    "            # backward classique (sans scaler si pas amp, ou avec scaler)\n",
    "            # ici on fait simple sans scaler complexe vu que c'est le \"classique\"\n",
    "            loss.backward()\n",
    "        else:\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, lbls)\n",
    "            loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        loss_ep += loss.item()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"   ep {epoch+1} | batch {i} | loss {loss.item():.4f}\", end=\"\\r\")\n",
    "            \n",
    "    # validation\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            out = model(imgs)\n",
    "            _, p = torch.max(out, 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(lbls.cpu().numpy())\n",
    "            \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    duree = time.time() - t0\n",
    "    avg_loss = loss_ep / len(train_loader)\n",
    "    \n",
    "    # update scheduler\n",
    "    scheduler.step(val_f1)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"\\n‚úÖ end ep {epoch+1} | time {duree:.0f}s | loss {avg_loss:.4f} | f1 {val_f1:.4f} | lr {current_lr:.6f}\")\n",
    "    \n",
    "    # save best\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"classic_efficientnet_b0.pth\"))\n",
    "        print(\"   üíæ new best score saved.\")\n",
    "        \n",
    "    # stop si score suffisant (on veut juste un modele decent)\n",
    "    if val_f1 > 0.82:\n",
    "        print(\"üöÄ score cible atteint. on arrete.\")\n",
    "        break\n",
    "\n",
    "print(f\"üèÅ fin training classique. meilleur f1 : {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e8cb80-ab90-4b13-81ce-f4815d649624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ packaging modele classique...\n",
      "‚úÖ livrable classique pr√™t : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\livrable_model_classique_effnetb0.pth\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#  EXPORT LIVRABLE CLASSIQUE \n",
    "print(\"\\nüì¶ packaging modele classique...\")\n",
    "\n",
    "out_dir = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "final_path = os.path.join(out_dir, \"livrable_model_classique_effnetb0.pth\")\n",
    "\n",
    "# sauvegarde poids\n",
    "torch.save(model.state_dict(), final_path)\n",
    "\n",
    "# sauvegarde meta\n",
    "classes_mapping = {int(i): str(c) for i, c in enumerate(le.classes_)}\n",
    "meta_data = {\n",
    "    \"model_name\": \"EfficientNet-B0 Classique\",\n",
    "    \"input_size\": [224, 224],\n",
    "    \"num_classes\": num_classes, # attention variable minuscule dans ce notebook\n",
    "    \"class_mapping\": classes_mapping,\n",
    "    \"description\": \"modele leger pour cpu/mobile\"\n",
    "}\n",
    "\n",
    "with open(os.path.join(out_dir, \"livrable_classique_metadata.json\"), 'w') as f:\n",
    "    json.dump(meta_data, f, indent=4)\n",
    "\n",
    "print(f\"‚úÖ livrable classique pr√™t : {final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852e3f9-f2f0-4c0f-b2ea-1ab2b735cd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass_tooling",
   "language": "python",
   "name": "masterclass_tooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
