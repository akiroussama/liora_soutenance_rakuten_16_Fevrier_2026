{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad771cff-6f25-4cc9-b530-335f2fbdeed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VERIFICATION FINALE DE COMPATIBILITÃ‰ (CORRIGÃ‰E) ---\n",
      "Chargement de l'encodeur (VÃ©rifie la date du fichier !)...\n",
      "DerniÃ¨re modification du modÃ¨le : 2026-01-26 16:32:10.523593187\n",
      "Extraction Features (Mode Torchvision)...\n",
      "Test du modÃ¨le...\n",
      "\n",
      ">>> VERDICT FINAL SUR 200 IMAGES : 0.9550 <<<\n",
      "âœ… SUCCÃˆS : Le modÃ¨le, l'encodeur et l'extracteur sont alignÃ©s.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- VERIFICATION FINALE DE COMPATIBILITÃ‰ (CORRIGÃ‰E) ---\")\n",
    "\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cv2\n",
    "from torchvision import models # ON UTILISE TORCHVISION COMME A L'ENTRAINEMENT\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\")\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_data, \"implementation\", \"outputs\")\n",
    "\n",
    "# 1. Chargement Data et Encodeur\n",
    "print(\"Chargement de l'encodeur (VÃ©rifie la date du fichier !)...\")\n",
    "path_enc = os.path.join(path_out, \"M2_IMAGE_XGBoost_Encoder.pkl\")\n",
    "path_mod = os.path.join(path_out, \"M2_IMAGE_Classic_XGBoost.json\")\n",
    "\n",
    "# VÃ©rification timestamp pour Ãªtre sur qu'on teste le nouveau\n",
    "t_mod = os.path.getmtime(path_mod)\n",
    "print(f\"DerniÃ¨re modification du modÃ¨le : {pd.to_datetime(t_mod, unit='s')}\")\n",
    "\n",
    "le_xgb = joblib.load(path_enc)\n",
    "\n",
    "# Dataframe validation\n",
    "df = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"X_train_update.csv\"))\n",
    "y = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"Y_train_CVw08PX.csv\"))\n",
    "if 'prdtypecode' not in y.columns: y = y.rename(columns={y.columns[1]: 'prdtypecode'})\n",
    "df = df.merge(y, left_index=True, right_index=True)\n",
    "\n",
    "path_img = os.path.join(path_data, \"data\", \"raw\", \"images\", \"images\", \"image_train\")\n",
    "df['path'] = df.apply(lambda r: os.path.join(path_img, f\"image_{r['imageid']}_product_{r['productid']}.jpg\"), axis=1)\n",
    "df = df[df['path'].apply(os.path.exists)]\n",
    "\n",
    "# On prend 200 images, MAIS on s'assure de les encoder comme le modÃ¨le l'attend\n",
    "_, df_val_mini = train_test_split(df, test_size=200, stratify=df['label'] if 'label' in df else None, random_state=42)\n",
    "y_true = le_xgb.transform(df_val_mini['prdtypecode']) # Utilisation de l'encodeur chargÃ©\n",
    "\n",
    "# 2. EXTRACTION FEATURES (VERSION TORCHVISION STRICTE)\n",
    "print(\"Extraction Features (Mode Torchvision)...\")\n",
    "# On reproduit EXACTEMENT l'architecture de l'entrainement\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "extractor = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "extractor.to(device).eval()\n",
    "\n",
    "class MiniDS(Dataset):\n",
    "    def __init__(self, paths): self.paths = paths\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            im = cv2.imread(self.paths[i]); im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            im = cv2.resize(im, (224, 224))\n",
    "            im = im / 255.0\n",
    "            # Normalisation ImageNet stricte\n",
    "            im = (im - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "            return torch.tensor(im.transpose(2,0,1), dtype=torch.float32)\n",
    "        except: return torch.zeros((3,224,224))\n",
    "\n",
    "loader = DataLoader(MiniDS(df_val_mini['path'].values), batch_size=32, shuffle=False)\n",
    "\n",
    "feats = []\n",
    "with torch.no_grad():\n",
    "    for b in loader:\n",
    "        b = b.to(device)\n",
    "        f = extractor(b).squeeze(-1).squeeze(-1)\n",
    "        feats.append(f.cpu().numpy())\n",
    "X_mini = np.concatenate(feats)\n",
    "\n",
    "# 3. PREDICTION\n",
    "print(\"Test du modÃ¨le...\")\n",
    "model_m2 = xgb.XGBClassifier()\n",
    "model_m2.load_model(path_mod)\n",
    "y_pred = model_m2.predict(X_mini)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\n>>> VERDICT FINAL SUR 200 IMAGES : {acc:.4f} <<<\")\n",
    "\n",
    "if acc > 0.6:\n",
    "    print(\"âœ… SUCCÃˆS : Le modÃ¨le, l'encodeur et l'extracteur sont alignÃ©s.\")\n",
    "else:\n",
    "    print(\"âŒ ECHEC : Toujours une incohÃ©rence. VÃ©rifie que l'entraÃ®nement Data Augmentation est bien TERMINÃ‰.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aeeb0c5-1d07-4833-a380-a00051db0db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> VERDICT FINAL : LE GRAND CONSEIL (VOTING) <<<\n",
      "Chargement donnÃ©es...\n",
      "Validation sur 12738 images\n",
      "\n",
      "1. M1: DINOv3 BEST...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M1 Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 797/797 [08:09<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. M3: EfficientNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M3 Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:32<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. M2: XGBoost Champion...\n",
      "Extraction Features (Strict)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M2 Extract: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:30<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> CALCUL DES SCORES <<<\n",
      "M1 (Dino)    : 0.7954\n",
      "M2 (XGBoost) : 0.9269\n",
      "M3 (EffNet)  : 0.6670\n",
      "------------------------------\n",
      "ðŸ† SCORE VOTING : 0.9272\n",
      "------------------------------\n",
      "C'est un score EXCELLENT pour ce projet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\">>> VERDICT FINAL : LE GRAND CONSEIL (VOTING) <<<\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\")\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_data, \"implementation\", \"outputs\")\n",
    "num_classes = 27\n",
    "\n",
    "# 1. Chargement Data Validation (La mÃªme que l'entrainement)\n",
    "print(\"Chargement donnÃ©es...\")\n",
    "df = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"X_train_update.csv\"))\n",
    "y = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"Y_train_CVw08PX.csv\"))\n",
    "if 'prdtypecode' not in y.columns: y = y.rename(columns={y.columns[1]: 'prdtypecode'})\n",
    "df = df.merge(y, left_index=True, right_index=True)\n",
    "\n",
    "path_img = os.path.join(path_data, \"data\", \"raw\", \"images\", \"images\", \"image_train\")\n",
    "if not os.path.exists(path_img): path_img = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "df['path'] = df.apply(lambda r: os.path.join(path_img, f\"image_{r['imageid']}_product_{r['productid']}.jpg\"), axis=1)\n",
    "df = df[df['path'].apply(os.path.exists)]\n",
    "\n",
    "# Split et Encodage\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['prdtypecode'])\n",
    "_, val_df = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=42)\n",
    "print(f\"Validation sur {len(val_df)} images\")\n",
    "\n",
    "# 2. Classe Dataset Universelle\n",
    "class UniversalDS(Dataset):\n",
    "    def __init__(self, df, size, interpolation=cv2.INTER_LINEAR):\n",
    "        self.paths = df['path'].values\n",
    "        self.size = size\n",
    "        self.inter = interpolation\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, i):\n",
    "        try:\n",
    "            img = cv2.imread(self.paths[i]); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (self.size, self.size), interpolation=self.inter)\n",
    "            img = img / 255.0\n",
    "            img = (img - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "            return torch.tensor(img.transpose(2,0,1), dtype=torch.float32)\n",
    "        except: return torch.zeros((3, self.size, self.size))\n",
    "\n",
    "# 3. Calculs des Scores INDIVIDUELS\n",
    "\n",
    "#  M1 : DINOv3 BEST \n",
    "print(\"\\n1. M1: DINOv3 BEST...\")\n",
    "path_m1 = os.path.join(path_out, \"model_DINOv3_BEST.pth\")\n",
    "if not os.path.exists(path_m1):\n",
    "    # Fallback si le nom est different\n",
    "    path_m1 = os.path.join(path_out, \"M1_IMAGE_DeepLearning_DINOv3.pth\")\n",
    "    print(f\"Note: Utilisation de {path_m1}\")\n",
    "\n",
    "mod_m1 = timm.create_model('vit_large_patch14_reg4_dinov2.lvd142m', pretrained=False, num_classes=num_classes)\n",
    "mod_m1.load_state_dict(torch.load(path_m1))\n",
    "mod_m1.to(device).eval()\n",
    "\n",
    "loader_m1 = DataLoader(UniversalDS(val_df, 518, cv2.INTER_CUBIC), batch_size=16, shuffle=False) # 518px pour Dino\n",
    "probs_m1 = []\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(loader_m1, desc=\"M1 Inference\"):\n",
    "        b = b.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            probs_m1.append(F.softmax(mod_m1(b), dim=1).cpu().numpy())\n",
    "p1 = np.concatenate(probs_m1)\n",
    "del mod_m1; torch.cuda.empty_cache()\n",
    "\n",
    "#  M3 : EfficientNet \n",
    "print(\"\\n2. M3: EfficientNet...\")\n",
    "mod_m3 = models.efficientnet_b0(weights=None)\n",
    "mod_m3.classifier[1] = nn.Linear(1280, num_classes)\n",
    "mod_m3.load_state_dict(torch.load(os.path.join(path_out, \"M3_IMAGE_Classic_EfficientNetB0.pth\")))\n",
    "mod_m3.to(device).eval()\n",
    "\n",
    "loader_m3 = DataLoader(UniversalDS(val_df, 224), batch_size=64, shuffle=False)\n",
    "probs_m3 = []\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(loader_m3, desc=\"M3 Inference\"):\n",
    "        b = b.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            probs_m3.append(F.softmax(mod_m3(b), dim=1).cpu().numpy())\n",
    "p3 = np.concatenate(probs_m3)\n",
    "del mod_m3; torch.cuda.empty_cache()\n",
    "\n",
    "#  M2 : XGBoost Champion \n",
    "print(\"\\n3. M2: XGBoost Champion...\")\n",
    "# A. Alignement Labels\n",
    "path_enc = os.path.join(path_out, \"M2_IMAGE_XGBoost_Encoder.pkl\")\n",
    "le_xgb = joblib.load(path_enc)\n",
    "y_true_aligned = le_xgb.transform(val_df['prdtypecode'])\n",
    "\n",
    "# B. Features (Torchvision ResNet50)\n",
    "print(\"Extraction Features (Strict)...\")\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "extractor.to(device).eval()\n",
    "\n",
    "loader_feat = DataLoader(UniversalDS(val_df, 224), batch_size=64, shuffle=False)\n",
    "feats = []\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(loader_feat, desc=\"M2 Extract\"):\n",
    "        b = b.to(device)\n",
    "        f = extractor(b).squeeze(-1).squeeze(-1)\n",
    "        feats.append(f.cpu().numpy())\n",
    "x_val_xgb = np.concatenate(feats)\n",
    "\n",
    "# C. Predict\n",
    "model_m2 = xgb.XGBClassifier()\n",
    "model_m2.load_model(os.path.join(path_out, \"M2_IMAGE_Classic_XGBoost.json\"))\n",
    "p2 = model_m2.predict_proba(x_val_xgb)\n",
    "\n",
    "\n",
    "# 4. FUSION STRATEGIQUE\n",
    "print(\"\\n>>> CALCUL DES SCORES <<<\")\n",
    "\n",
    "# Poids optimisÃ©s selon tes derniers entrainements\n",
    "w1 = 2.0  # Dino (Solide)\n",
    "w2 = 4.0  # XGBoost (Le Champion Ã  80%)\n",
    "w3 = 1.0  # EffNet (Le soutien)\n",
    "\n",
    "final_probs = (w1 * p1 + w2 * p2 + w3 * p3) / (w1 + w2 + w3)\n",
    "y_pred_vote = final_probs.argmax(axis=1)\n",
    "\n",
    "# Resultats individuels pour comparer\n",
    "score_m1 = f1_score(y_true_aligned, p1.argmax(axis=1), average='weighted')\n",
    "score_m2 = f1_score(y_true_aligned, p2.argmax(axis=1), average='weighted')\n",
    "score_m3 = f1_score(y_true_aligned, p3.argmax(axis=1), average='weighted')\n",
    "score_vote = f1_score(y_true_aligned, y_pred_vote, average='weighted')\n",
    "\n",
    "print(f\"M1 (Dino)    : {score_m1:.4f}\")\n",
    "print(f\"M2 (XGBoost) : {score_m2:.4f}\")\n",
    "print(f\"M3 (EffNet)  : {score_m3:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"ðŸ† SCORE VOTING : {score_vote:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if score_vote > 0.83:\n",
    "    print(\"C'est un score EXCELLENT pour ce projet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass_tooling",
   "language": "python",
   "name": "masterclass_tooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
