{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d3096f-7397-4296-bc6c-9c92b402a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA STRAT√âGIE GAGNANTE : LE FINE-TUNING MAINTENANT , UTILISE QUE CE QUI EST ECRIT EN DESSOUS SI TU A CE MOD√®LE A ENTRAINER\n"
     ]
    }
   ],
   "source": [
    "print(\"LA STRAT√âGIE GAGNANTE : LE FINE-TUNING MAINTENANT , UTILISE QUE CE QUI EST ECRIT EN DESSOUS SI TU A CE MOD√®LE A ENTRAINER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb43eab9-018f-4b4a-93d8-2b9fc0905148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ RECONSTRUCTION DU MODELE LEGENDAIRE (91%) SUR : cuda\n",
      "üß† Architecture 'Legend' (GELU + Config Exacte) reconstruite.\n",
      "üî• D√©marrage (Objectif : Retrouver les 91%)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:112: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 1 | Batch 500 | Loss: 1.7137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 1 | Time: 415s | F1: 0.5418\n",
      "   üíæ Record Sauvegard√©.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 2 | Batch 500 | Loss: 1.2292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 2 | Time: 399s | F1: 0.5878\n",
      "   üíæ Record Sauvegard√©.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 3 | Batch 500 | Loss: 1.1363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 3 | Time: 394s | F1: 0.5984\n",
      "   üíæ Record Sauvegard√©.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 4 | Batch 500 | Loss: 0.8193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 4 | Time: 393s | F1: 0.5994\n",
      "   üíæ Record Sauvegard√©.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 5 | Batch 500 | Loss: 0.7502"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 5 | Time: 394s | F1: 0.6014\n",
      "   üíæ Record Sauvegard√©.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 6 | Batch 500 | Loss: 0.8910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 6 | Time: 393s | F1: 0.6171\n",
      "   üíæ Record Sauvegard√©.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 7 | Batch 500 | Loss: 0.7637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 7 | Time: 398s | F1: 0.6074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_44200\\3707796505.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 8 | Batch 100 | Loss: 0.6717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "IMG_DIR = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "BATCH_SIZE = 128 # On profite de la 4070\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "print(f\"üöÄ RECONSTRUCTION DU MODELE LEGENDAIRE (91%) SUR : {DEVICE}\")\n",
    "\n",
    "# --- DATASET ---\n",
    "# On utilise la transformation STANDARD ImageNet (celle utilis√©e pour cr√©er les .npy implicitement)\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224), # Le zoom standard ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "csv_path = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda x: os.path.join(IMG_DIR, f\"image_{x['imageid']}_product_{x['productid']}.jpg\"), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "class LegendDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try: img = Image.open(row['path']).convert(\"RGB\")\n",
    "        except: img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(LegendDataset(train_df, trans), batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(LegendDataset(val_df, trans), batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# --- ARCHITECTURE EXACTE DU LOG (Rang DL 1) ---\n",
    "# L:[2048, 1024, 512] | Opt:adam | Act:gelu | Drop:0.2\n",
    "\n",
    "class LegendMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        # Reconstruction exacte de ta classe ModularMLP gagnante\n",
    "        self.net = nn.Sequential(\n",
    "            # Couche 1 : 2048 -> 2048 (Input ResNet -> Hidden 1)\n",
    "            nn.Linear(input_dim, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.GELU(), # Activation GELU (C'√©tait le secret !)\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Couche 2 : 2048 -> 1024\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Couche 3 : 1024 -> 512\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Sortie : 512 -> 27\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Assemblage avec ResNet50\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "# ON G√àLE TOUT LE RESNET (Comme si on utilisait des .npy fixes)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# On remplace la t√™te\n",
    "resnet.fc = LegendMLP(2048, NUM_CLASSES)\n",
    "model = resnet.to(DEVICE)\n",
    "\n",
    "print(\"üß† Architecture 'Legend' (GELU + Config Exacte) reconstruite.\")\n",
    "\n",
    "# --- ENTRAINEMENT (REPLIQUE DU LOG) ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Optimiseur ADAM (Pas AdamW, comme dans ton log)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001) \n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"üî• D√©marrage (Objectif : Retrouver les 91%)...\")\n",
    "EPOCHS = 20 # Comme dans ton log\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for i, (imgs, lbls) in enumerate(train_loader):\n",
    "        imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, lbls)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        if i % 50 == 0: print(f\"   ‚è≥ Ep {epoch+1} | Batch {i} | Loss: {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            with autocast(): out = model(imgs)\n",
    "            _, p = torch.max(out, 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(lbls.cpu().numpy())\n",
    "    \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    duree = time.time() - t0\n",
    "    \n",
    "    print(f\"\\n‚úÖ FIN EP {epoch+1} | Time: {duree:.0f}s | F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Sauvegarde syst√©matique si record\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"livrable_model_resnet_reborn.pth\"))\n",
    "        \n",
    "        # Metadata pour le Voting\n",
    "        meta_data = {\n",
    "            \"model_name\": \"ResNet50 Legend 91%\", \n",
    "            \"class_mapping\": {int(i): str(c) for i, c in enumerate(le.classes_)}\n",
    "        }\n",
    "        with open(os.path.join(OUTPUT_DIR, \"livrable_resnet_reborn_metadata.json\"), 'w') as f:\n",
    "            json.dump(meta_data, f, indent=4)\n",
    "        print(\"   üíæ Record Sauvegard√©.\")\n",
    "\n",
    "print(f\"üèÜ Fini. Score Final : {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "937f6080-e861-4533-9c56-9f35640f5a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ OP√âRATION PHOENIX SUR : cuda\n",
      "üì• Chargement des features pr√©-calcul√©es (3.1 Go)...\n",
      "‚úÖ Features charg√©es : (405000, 2048)\n",
      "‚úÇÔ∏è Cr√©ation du Train/Val...\n",
      "üß† Cerveau MLP initialis√©.\n",
      "üî• D√©marrage Entra√Ænement PHOENIX (√áa va aller tr√®s vite)...\n",
      "‚úÖ EP 1/20 | Time: 3.6s | F1: 0.6585\n",
      "‚úÖ EP 2/20 | Time: 3.7s | F1: 0.7392\n",
      "‚úÖ EP 3/20 | Time: 3.7s | F1: 0.7783\n",
      "‚úÖ EP 4/20 | Time: 3.6s | F1: 0.8136\n",
      "‚úÖ EP 5/20 | Time: 3.7s | F1: 0.8340\n",
      "‚úÖ EP 6/20 | Time: 3.8s | F1: 0.8496\n",
      "‚úÖ EP 7/20 | Time: 3.7s | F1: 0.8693\n",
      "‚úÖ EP 8/20 | Time: 4.6s | F1: 0.8800\n",
      "‚úÖ EP 9/20 | Time: 3.7s | F1: 0.8829\n",
      "‚úÖ EP 10/20 | Time: 3.7s | F1: 0.8826\n",
      "‚úÖ EP 11/20 | Time: 4.1s | F1: 0.8936\n",
      "‚úÖ EP 12/20 | Time: 3.7s | F1: 0.8999\n",
      "‚úÖ EP 13/20 | Time: 3.8s | F1: 0.9026\n",
      "‚úÖ EP 14/20 | Time: 3.6s | F1: 0.9023\n",
      "‚úÖ EP 15/20 | Time: 3.7s | F1: 0.9064\n",
      "‚úÖ EP 16/20 | Time: 3.6s | F1: 0.9104\n",
      "‚úÖ EP 17/20 | Time: 3.7s | F1: 0.9085\n",
      "‚úÖ EP 18/20 | Time: 3.7s | F1: 0.9072\n",
      "‚úÖ EP 19/20 | Time: 3.8s | F1: 0.9125\n",
      "‚úÖ EP 20/20 | Time: 3.8s | F1: 0.9143\n",
      "üèÜ Score PHOENIX atteint : 0.9143\n",
      "\n",
      "üèóÔ∏è Assemblage du mod√®le final pour le Voting...\n",
      "üíæ SAUVEGARDE TERMIN√âE : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\livrable_model_resnet_reborn.pth\n",
      "üöÄ Tu peux lancer le Voting, le champion est de retour !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"üöÄ OP√âRATION PHOENIX SUR : {DEVICE}\")\n",
    "\n",
    "# 1. CHARGEMENT DU TR√âSOR (.NPY)\n",
    "print(\"üì• Chargement des features pr√©-calcul√©es (3.1 Go)...\")\n",
    "try:\n",
    "    # On charge les fichiers du 5 Janvier\n",
    "    X_all = np.load(os.path.join(OUTPUT_DIR, 'train_features_resnet50_augmented.npy'))\n",
    "    y_all_raw = np.load(os.path.join(OUTPUT_DIR, 'train_labels_augmented.npy'))\n",
    "    print(f\"‚úÖ Features charg√©es : {X_all.shape}\")\n",
    "except Exception as e:\n",
    "    raise FileNotFoundError(f\"‚ùå Impossible de charger les .npy : {e}\")\n",
    "\n",
    "# 2. ENCODAGE & SPLIT\n",
    "# On doit r√©-encoder les labels proprement pour √™tre coh√©rent avec le projet\n",
    "le = LabelEncoder()\n",
    "y_all = le.fit_transform(y_all_raw)\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "print(\"‚úÇÔ∏è Cr√©ation du Train/Val...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "# Conversion en Tenseurs PyTorch (Directement en VRAM pour vitesse lumi√®re)\n",
    "train_ds = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32).to(DEVICE), \n",
    "    torch.tensor(y_train, dtype=torch.long).to(DEVICE)\n",
    ")\n",
    "val_ds = TensorDataset(\n",
    "    torch.tensor(X_val, dtype=torch.float32).to(DEVICE), \n",
    "    torch.tensor(y_val, dtype=torch.long).to(DEVICE)\n",
    ")\n",
    "\n",
    "# Gros batch size car ce ne sont pas des images, juste des vecteurs\n",
    "train_loader = DataLoader(train_ds, batch_size=4096, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=4096, shuffle=False)\n",
    "\n",
    "# 3. L'ARCHITECTURE \"LEGEND\" (Celle de ton log √† 91%)\n",
    "# Config : [2048, 1024, 512], Adam, GELU, Drop 0.2\n",
    "class LegendMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048), nn.BatchNorm1d(2048), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),  nn.BatchNorm1d(512),  nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "mlp = LegendMLP(2048, NUM_CLASSES).to(DEVICE)\n",
    "print(\"üß† Cerveau MLP initialis√©.\")\n",
    "\n",
    "# 4. ENTRAINEMENT √âCLAIR (Sur les features, pas les images)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.001) # Adam standard comme avant\n",
    "\n",
    "print(\"üî• D√©marrage Entra√Ænement PHOENIX (√áa va aller tr√®s vite)...\")\n",
    "EPOCHS = 20\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    mlp.train()\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for bx, by in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = mlp(bx)\n",
    "        loss = criterion(out, by)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    mlp.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for bx, by in val_loader:\n",
    "            out = mlp(bx)\n",
    "            _, p = torch.max(out, 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(by.cpu().numpy())\n",
    "            \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    duree = time.time() - t0\n",
    "    print(f\"‚úÖ EP {epoch+1}/{EPOCHS} | Time: {duree:.1f}s | F1: {val_f1:.4f}\")\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        # On sauvegarde juste les poids du MLP pour l'instant\n",
    "        torch.save(mlp.state_dict(), os.path.join(OUTPUT_DIR, \"temp_phoenix_mlp.pth\"))\n",
    "\n",
    "print(f\"üèÜ Score PHOENIX atteint : {best_f1:.4f}\")\n",
    "\n",
    "# 5. ASSEMBLAGE FINAL (FUSION CORPS + T√äTE) & SAUVEGARDE POUR VOTING\n",
    "print(\"\\nüèóÔ∏è Assemblage du mod√®le final pour le Voting...\")\n",
    "\n",
    "# On prend un ResNet vierge\n",
    "full_model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "# On g√®le le corps (puisqu'on a entra√Æn√© le MLP sur des features fig√©es)\n",
    "for param in full_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# On lui greffe notre MLP entra√Æn√©\n",
    "full_model.fc = LegendMLP(2048, NUM_CLASSES)\n",
    "full_model.fc.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, \"temp_phoenix_mlp.pth\")))\n",
    "\n",
    "# On sauvegarde le TOUT (Corps + T√™te) sous le nom que le Voting attend\n",
    "final_path = os.path.join(OUTPUT_DIR, \"livrable_model_resnet_reborn.pth\")\n",
    "torch.save(full_model.state_dict(), final_path)\n",
    "\n",
    "# Metadata\n",
    "meta_data = {\n",
    "    \"model_name\": \"ResNet50 Phoenix (From NPY)\", \n",
    "    \"class_mapping\": {int(i): str(c) for i, c in enumerate(le.classes_)}\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, \"livrable_resnet_reborn_metadata.json\"), 'w') as f:\n",
    "    json.dump(meta_data, f, indent=4)\n",
    "\n",
    "print(f\"üíæ SAUVEGARDE TERMIN√âE : {final_path}\")\n",
    "print(\"üöÄ Tu peux lancer le Voting, le champion est de retour !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass_tooling",
   "language": "python",
   "name": "masterclass_tooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
