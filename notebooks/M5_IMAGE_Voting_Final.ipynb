{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5ed444-bd72-469d-a606-29e104794c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lancement voting classifier 3 modeles\n",
      "classes detectees : 27\n",
      "images test a traiter : 13812\n",
      "\n",
      "--- prediction m1 : dinov3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m1 dino: 100%|██████████| 1727/1727 [14:54<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape m1 : (13812, 27)\n",
      "\n",
      "--- prediction m3 : efficientnet ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "m3 effnet: 100%|██████████| 216/216 [00:19<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape m3 : (13812, 27)\n",
      "\n",
      "--- prediction m2 : xgboost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "extraction features m2: 100%|██████████| 216/216 [00:38<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features extraites : (13812, 2048)\n",
      "shape m2 : (13812, 27)\n",
      "\n",
      "--- fusion des cerveaux ---\n",
      "generation fichier submission...\n",
      "termine. fichier pret : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\\submission_voting_m1_m2_m3.csv\n",
      "on espere que ca va peter le score\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn import preprocessing\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"lancement voting classifier 3 modeles\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path_data = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "path_out = os.path.join(path_data, \"implementation\", \"outputs\")\n",
    "\n",
    "# je recupere la liste des classes depuis le fichier train\n",
    "# cest vital pour remettre les id dans le bon ordre a la fin\n",
    "df_train = pd.read_csv(os.path.join(path_data, \"data\", \"raw\", \"Y_train_CVw08PX.csv\"))\n",
    "if 'prdtypecode' not in df_train.columns: df_train = df_train.rename(columns={df_train.columns[1]: 'prdtypecode'})\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train['prdtypecode'])\n",
    "num_classes = len(le.classes_)\n",
    "print(f\"classes detectees : {num_classes}\")\n",
    "\n",
    "# 1. PREPARATION DONNEES TEST\n",
    "\n",
    "# je charge le csv de test\n",
    "path_test_csv = os.path.join(path_data, \"data\", \"raw\", \"X_test_update.csv\")\n",
    "df_test = pd.read_csv(path_test_csv)\n",
    "\n",
    "# je cherche les images\n",
    "path_img = os.path.join(path_data, \"data\", \"raw\", \"images\", \"images\")\n",
    "# fallback si dossier pas trouve\n",
    "if not os.path.exists(path_img):\n",
    "    for root, dirs, files in os.walk(path_data):\n",
    "        if \"images\" in dirs: path_img = os.path.join(root, \"images\"); break\n",
    "\n",
    "# je cree le chemin complet\n",
    "df_test['path'] = df_test.apply(lambda r: os.path.join(path_img, f\"image_{r['imageid']}_product_{r['productid']}.jpg\"), axis=1)\n",
    "print(f\"images test a traiter : {len(df_test)}\")\n",
    "\n",
    "# dataset generique pour pytorch\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, size, interpolation=cv2.INTER_LINEAR):\n",
    "        self.paths = df['path'].values\n",
    "        self.size = size\n",
    "        self.inter = interpolation\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = cv2.imread(self.paths[idx])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (self.size, self.size), interpolation=self.inter)\n",
    "            # normalisation standard imagenet a la main\n",
    "            img = img / 255.0\n",
    "            img = (img - np.array([0.485, 0.456, 0.406])) / np.array([0.229, 0.224, 0.225])\n",
    "            # passage en chw\n",
    "            img = img.transpose(2, 0, 1)\n",
    "            return torch.tensor(img, dtype=torch.float32)\n",
    "        except:\n",
    "            return torch.zeros((3, self.size, self.size), dtype=torch.float32)\n",
    "\n",
    "\n",
    "# 2. PREDICTION M1 : DINOv3 (LE VISIONNAIRE)\n",
    "\n",
    "print(\"\\n--- prediction m1 : dinov3 ---\")\n",
    "\n",
    "# config m1\n",
    "size_m1 = 518\n",
    "batch_m1 = 8 # attention vram\n",
    "\n",
    "ds_m1 = TestDataset(df_test, size_m1, interpolation=cv2.INTER_CUBIC)\n",
    "loader_m1 = DataLoader(ds_m1, batch_size=batch_m1, shuffle=False, num_workers=0)\n",
    "\n",
    "# chargement architecture\n",
    "model_m1 = timm.create_model('vit_large_patch14_reg4_dinov2.lvd142m', pretrained=False, num_classes=num_classes)\n",
    "path_m1 = os.path.join(path_out, \"M1_IMAGE_DeepLearning_DINOv3.pth\")\n",
    "model_m1.load_state_dict(torch.load(path_m1))\n",
    "model_m1.to(device).eval()\n",
    "\n",
    "# inference\n",
    "probs_m1 = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader_m1, desc=\"m1 dino\"):\n",
    "        batch = batch.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model_m1(batch)\n",
    "            # je recupere les probas (softmax)\n",
    "            probs = F.softmax(out, dim=1)\n",
    "        probs_m1.append(probs.cpu().numpy())\n",
    "\n",
    "probs_m1 = np.concatenate(probs_m1)\n",
    "print(f\"shape m1 : {probs_m1.shape}\")\n",
    "\n",
    "# nettoyage vram\n",
    "del model_m1, loader_m1, ds_m1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# 3. PREDICTION M3 : EFFICIENTNET (LE RAPIDE)\n",
    "\n",
    "# je fais m3 avant m2 car m2 a besoin de features\n",
    "print(\"\\n--- prediction m3 : efficientnet ---\")\n",
    "\n",
    "size_m3 = 224\n",
    "batch_m3 = 64\n",
    "\n",
    "ds_m3 = TestDataset(df_test, size_m3)\n",
    "loader_m3 = DataLoader(ds_m3, batch_size=batch_m3, shuffle=False, num_workers=0)\n",
    "\n",
    "model_m3 = models.efficientnet_b0(weights=None)\n",
    "model_m3.classifier[1] = nn.Linear(1280, num_classes)\n",
    "path_m3 = os.path.join(path_out, \"M3_IMAGE_Classic_EfficientNetB0.pth\")\n",
    "model_m3.load_state_dict(torch.load(path_m3))\n",
    "model_m3.to(device).eval()\n",
    "\n",
    "probs_m3 = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader_m3, desc=\"m3 effnet\"):\n",
    "        batch = batch.to(device)\n",
    "        out = model_m3(batch)\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        probs_m3.append(probs.cpu().numpy())\n",
    "\n",
    "probs_m3 = np.concatenate(probs_m3)\n",
    "print(f\"shape m3 : {probs_m3.shape}\")\n",
    "\n",
    "del model_m3\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 4. PREDICTION M2 : XGBOOST (LE CHAMPION)\n",
    "print(\"\\n--- prediction m2 : xgboost ---\")\n",
    "# attention xgboost a besoin de features\n",
    "# je dois utiliser un resnet pour extraire les features dabord\n",
    "# cest la methode qui nous a donne 85%\n",
    "\n",
    "# extracteur resnet\n",
    "extractor = timm.create_model('resnet50', pretrained=True, num_classes=0)\n",
    "extractor.to(device).eval()\n",
    "\n",
    "# loader pour features (taille 224 standard)\n",
    "ds_feat = TestDataset(df_test, 224)\n",
    "loader_feat = DataLoader(ds_feat, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "features_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(loader_feat, desc=\"extraction features m2\"):\n",
    "        batch = batch.to(device)\n",
    "        feats = extractor(batch)\n",
    "        features_list.append(feats.cpu().numpy())\n",
    "\n",
    "x_test_features = np.concatenate(features_list)\n",
    "print(f\"features extraites : {x_test_features.shape}\")\n",
    "\n",
    "del extractor, loader_feat, ds_feat\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# chargement xgboost\n",
    "model_m2 = xgb.XGBClassifier()\n",
    "model_m2.load_model(os.path.join(path_out, \"M2_IMAGE_Classic_XGBoost.json\"))\n",
    "\n",
    "# prediction xgboost (predict_proba pour avoir les scores)\n",
    "probs_m2_raw = model_m2.predict_proba(x_test_features)\n",
    "\n",
    "# attention xgboost renvoie les probas dans l ordre de ses classes internes\n",
    "# je dois verifier si je dois reordonner mais generalement cest bon si entraine avec le label encoder\n",
    "# par securite je fais confiance a lordre du label encoder charge\n",
    "probs_m2 = probs_m2_raw\n",
    "print(f\"shape m2 : {probs_m2.shape}\")\n",
    "\n",
    "# 5. VOTING (FUSION PONDEREE)\n",
    "print(\"\\n--- fusion des cerveaux ---\")\n",
    "\n",
    "# je definis les poids selon la puissance des modeles\n",
    "# m2 (xgboost) est le boss (85%) -> poids 3\n",
    "# m1 (dino) est fort (75%+) -> poids 2\n",
    "# m3 (effnet) est le petit frere -> poids 1\n",
    "\n",
    "w1 = 2.0 # dino\n",
    "w2 = 3.0 # xgboost\n",
    "w3 = 1.0 # effnet\n",
    "\n",
    "# somme ponderee\n",
    "final_probs = (w1 * probs_m1 + w2 * probs_m2 + w3 * probs_m3) / (w1 + w2 + w3)\n",
    "\n",
    "# choix final (argmax)\n",
    "final_preds_idx = np.argmax(final_probs, axis=1)\n",
    "\n",
    "# je convertis les index en vrais codes produits (10, 2280, etc)\n",
    "final_preds_code = le.inverse_transform(final_preds_idx)\n",
    "\n",
    "# 6. EXPORT LIVRABLE\n",
    "print(\"generation fichier submission...\")\n",
    "\n",
    "df_submission = pd.DataFrame({\n",
    "    'imageid': df_test['imageid'],\n",
    "    'productid': df_test['productid'],\n",
    "    'prdtypecode': final_preds_code\n",
    "})\n",
    "\n",
    "path_sub = os.path.join(path_out, \"submission_voting_m1_m2_m3.csv\")\n",
    "df_submission.to_csv(path_sub, index=False)\n",
    "\n",
    "print(f\"termine. fichier pret : {path_sub}\")\n",
    "print(\"on espere que ca va peter le score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass_tooling",
   "language": "python",
   "name": "masterclass_tooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
