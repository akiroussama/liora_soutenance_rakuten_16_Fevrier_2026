{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be238232-012f-4b34-bcde-513402a42ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (1.16.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\amisf\\anaconda3\\envs\\masterclass_tooling\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Installation des librairies nÃ©cessaires\n",
    "!pip install tensorflow pillow scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b86d7e9-072a-4545-bc64-a44d6deed0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Racine projet : C:\\Users\\amisf\\Desktop\\datascientest_projet\n",
      "ðŸ“‚ Images sources : C:\\Users\\amisf\\Desktop\\datascientest_projet\\images\\images\\image_train\n",
      "ðŸ“‚ Dossier de sortie (pour Oussama) : C:\\Users\\amisf\\Desktop\\datascientest_projet\\implementation\\outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input\n",
    "\n",
    "# --- CONFIGURATION DES CHEMINS ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "PATH_IMG_TRAIN = os.path.join(PROJECT_ROOT, \"images\", \"images\", \"image_train\")\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "\n",
    "# CrÃ©ation du dossier de sortie si Ã§a bug\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ðŸ“‚ Racine projet : {PROJECT_ROOT}\")\n",
    "print(f\"ðŸ“‚ Images sources : {PATH_IMG_TRAIN}\")\n",
    "print(f\"ðŸ“‚ Dossier de sortie (pour Oussama) : {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82846f75-1449-47f6-8e7c-61ed58d3a638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ CSV recherchÃ©s dans : C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\n",
      "ðŸ“‚ Images recherchÃ©es dans : C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\n",
      "âœ… Fichiers CSV chargÃ©s avec succÃ¨s.\n",
      "âš–ï¸ DÃ©marrage du rÃ©Ã©quilibrage (Cible : 15000 images par classe)...\n",
      "âœ… Dataset original : 84916 images.\n",
      "âœ… Dataset augmentÃ© : 405000 images prÃªt Ã  l'emploi.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 1. LE BON  CHEMINS ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "\n",
    "# Chemin spÃ©cifique pour les fichiers CSV\n",
    "PATH_CSV = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "\n",
    "# Chemin spÃ©cifique pour les images (Mise Ã  jour pour Ã©viter la prochaine erreur)\n",
    "PATH_IMG_TRAIN = os.path.join(PROJECT_ROOT, \"data\", \"raw\", \"images\", \"images\", \"image_train\")\n",
    "\n",
    "print(f\"ðŸ“‚ CSV recherchÃ©s dans : {PATH_CSV}\")\n",
    "print(f\"ðŸ“‚ Images recherchÃ©es dans : {PATH_IMG_TRAIN}\")\n",
    "\n",
    "# --- 2. CHARGEMENT DES DONNÃ‰ES ---\n",
    "try:\n",
    "    df_x = pd.read_csv(os.path.join(PATH_CSV, \"X_train_update.csv\"), index_col=0)\n",
    "    df_y = pd.read_csv(os.path.join(PATH_CSV, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "    df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "    print(\"âœ… Fichiers CSV chargÃ©s avec succÃ¨s.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"âŒ Erreur : Impossible de trouver les fichiers dans {PATH_CSV}\")\n",
    "    raise e\n",
    "\n",
    "# Construction du nom de fichier complet pour Keras\n",
    "df['filename'] = df.apply(lambda x: f\"image_{x['imageid']}_product_{x['productid']}.jpg\", axis=1)\n",
    "df['class_str'] = df['prdtypecode'].astype(str) # Keras demande des strings pour les classes\n",
    "\n",
    "# --- 3. OVERSAMPLING CIBLÃ‰ Ã€ 15 000 ---\n",
    "TARGET_COUNT = 15000\n",
    "df_balanced = pd.DataFrame()\n",
    "\n",
    "print(f\"âš–ï¸ DÃ©marrage du rÃ©Ã©quilibrage (Cible : {TARGET_COUNT} images par classe)...\")\n",
    "\n",
    "for code in df['prdtypecode'].unique():\n",
    "    df_class = df[df['prdtypecode'] == code]\n",
    "    \n",
    "    # On duplique les donnÃ©es (oversampling) pour atteindre 15 000\n",
    "    df_resampled = resample(df_class, \n",
    "                            replace=True,     \n",
    "                            n_samples=TARGET_COUNT, \n",
    "                            random_state=42)\n",
    "    df_balanced = pd.concat([df_balanced, df_resampled])\n",
    "\n",
    "# MÃ©lange final\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… Dataset original : {len(df)} images.\")\n",
    "print(f\"âœ… Dataset augmentÃ© : {len(df_balanced)} images prÃªt Ã  l'emploi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5be3ba-9bf3-47c8-952c-74c9f8047e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©finition de la taille d'entrÃ©e (Standard ResNet = 224x224)\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Chargement de ResNet50 sans la tÃªte de classification\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
    "\n",
    "# Ajout du pooling pour aplatir les rÃ©sultats\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "model_extractor = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "print(\"ðŸ§  ModÃ¨le ResNet50 chargÃ© pour l'extraction de features.\")\n",
    "model_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1bb81-8c91-407c-b1b9-f48704bfca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'Augmentation\n",
    "# Ces paramÃ¨tres seront appliquÃ©s Ã  CHAQUE image passant dans le modÃ¨le\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, # Important pour ResNet\n",
    "    rotation_range=30,      # Rotation alÃ©atoire +/- 30Â°\n",
    "    width_shift_range=0.2,  # DÃ©calage horizontal\n",
    "    height_shift_range=0.2, # DÃ©calage vertical\n",
    "    shear_range=0.1,        # Cisaillement\n",
    "    zoom_range=0.2,         # Zoom alÃ©atoire\n",
    "    horizontal_flip=True,   # Miroir horizontal\n",
    "    fill_mode='nearest'     # Remplissage des pixels crÃ©Ã©s\n",
    ")\n",
    "\n",
    "# CrÃ©ation du flux de donnÃ©es\n",
    "# ATTENTION : shuffle=False est CRUCIAL ici pour garder l'ordre des labels !\n",
    "generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df_balanced,\n",
    "    directory=PATH_IMG_TRAIN,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class_str\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None, # On ne veut que les features, pas les labels pour l'instant\n",
    "    shuffle=False    # IMPÃ‰RATIF pour aligner X et y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e795290-c02f-4e1c-b737-af92ac02bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸš€ DÃ©but de l'extraction des features... Prenez un cafÃ© â˜•\")\n",
    "\n",
    "# Extraction (Prediction)\n",
    "# Le rÃ©sultat sera une matrice Numpy de taille (405000, 2048)\n",
    "features = model_extractor.predict(generator, verbose=1)\n",
    "\n",
    "print(f\"âœ… Extraction terminÃ©e. Dimensions des features : {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135ac6d4-7454-4766-a576-828a50891046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©cupÃ©ration des labels correspondant aux features (grÃ¢ce Ã  shuffle=False)\n",
    "# generator.classes nous donne les indices (0, 1, 2...)\n",
    "# generator.class_indices nous donne le mapping {'10': 0, '1140': 1...}\n",
    "\n",
    "labels_indices = generator.classes\n",
    "class_indices_map = generator.class_indices\n",
    "# Inversion du mapping pour retrouver les codes produits originaux (ex: 2583)\n",
    "idx_to_code = {v: k for k, v in class_indices_map.items()}\n",
    "labels_original_code = [int(idx_to_code[i]) for i in labels_indices]\n",
    "\n",
    "# Conversion en Numpy Array\n",
    "y_train_augmented = np.array(labels_original_code)\n",
    "\n",
    "# Sauvegarde\n",
    "print(\"ðŸ’¾ Sauvegarde des fichiers .npy...\")\n",
    "\n",
    "np.save(os.path.join(OUTPUT_DIR, 'train_features_resnet50_augmented.npy'), features)\n",
    "np.save(os.path.join(OUTPUT_DIR, 'train_labels_augmented.npy'), y_train_augmented)\n",
    "\n",
    "# Sauvegarde des mÃ©tadonnÃ©es (Classes, Mapping)\n",
    "import json\n",
    "metadata = {\n",
    "    'num_classes': 27,\n",
    "    'feature_dim': 2048,\n",
    "    'model_source': 'ResNet50_ImageNet_Augmented',\n",
    "    'class_mapping': class_indices_map\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, 'metadata_augmented.json'), 'w') as f:\n",
    "    json.dump(metadata, f)\n",
    "\n",
    "print(\"âœ… Tout est sauvegardÃ© !\")\n",
    "print(f\"   -> X (Features) : {os.path.join(OUTPUT_DIR, 'train_features_resnet50_augmented.npy')}\")\n",
    "print(f\"   -> Y (Labels)   : {os.path.join(OUTPUT_DIR, 'train_labels_augmented.npy')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe24019-258f-4963-9dc2-f3845036a4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95788af2-819e-4442-a3d0-7fa03ac7a745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee247f-b77c-43f4-942c-1743a9d846e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:masterclass_tooling]",
   "language": "python",
   "name": "conda-env-masterclass_tooling-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
