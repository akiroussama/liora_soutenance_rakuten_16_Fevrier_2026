{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b16639-c628-4ef0-83d2-af8c35806c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ GRAND RESET (MODE BAVARD & S√âCURIS√â) SUR : cuda\n",
      "üìÇ Pr√©paration du DataFrame...\n",
      "üèóÔ∏è Chargement ResNet50 (Extracteur)...\n",
      "üî• Lancement de l'extraction...\n",
      "\n",
      "üîä D√âMARRAGE EXTRACTION TRAIN (Total batchs: 1062)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\1692202248.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ñ∂Ô∏è TRAIN | Batch 0/1062 trait√© | Temps √©coul√©: 1s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 20/1062 trait√© | Temps √©coul√©: 6s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 40/1062 trait√© | Temps √©coul√©: 12s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 60/1062 trait√© | Temps √©coul√©: 19s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 80/1062 trait√© | Temps √©coul√©: 26s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 100/1062 trait√© | Temps √©coul√©: 33s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 120/1062 trait√© | Temps √©coul√©: 39s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 140/1062 trait√© | Temps √©coul√©: 46s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 160/1062 trait√© | Temps √©coul√©: 52s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 180/1062 trait√© | Temps √©coul√©: 59s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 200/1062 trait√© | Temps √©coul√©: 65s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 220/1062 trait√© | Temps √©coul√©: 72s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 240/1062 trait√© | Temps √©coul√©: 79s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 260/1062 trait√© | Temps √©coul√©: 86s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 280/1062 trait√© | Temps √©coul√©: 93s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 300/1062 trait√© | Temps √©coul√©: 99s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 320/1062 trait√© | Temps √©coul√©: 106s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 340/1062 trait√© | Temps √©coul√©: 113s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 360/1062 trait√© | Temps √©coul√©: 120s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 380/1062 trait√© | Temps √©coul√©: 126s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 400/1062 trait√© | Temps √©coul√©: 132s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 420/1062 trait√© | Temps √©coul√©: 139s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 440/1062 trait√© | Temps √©coul√©: 145s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 460/1062 trait√© | Temps √©coul√©: 152s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 480/1062 trait√© | Temps √©coul√©: 158s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 500/1062 trait√© | Temps √©coul√©: 164s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 520/1062 trait√© | Temps √©coul√©: 171s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 540/1062 trait√© | Temps √©coul√©: 177s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 560/1062 trait√© | Temps √©coul√©: 183s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 580/1062 trait√© | Temps √©coul√©: 190s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 600/1062 trait√© | Temps √©coul√©: 196s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 620/1062 trait√© | Temps √©coul√©: 202s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 640/1062 trait√© | Temps √©coul√©: 209s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 660/1062 trait√© | Temps √©coul√©: 215s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 680/1062 trait√© | Temps √©coul√©: 222s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 700/1062 trait√© | Temps √©coul√©: 228s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 720/1062 trait√© | Temps √©coul√©: 235s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 740/1062 trait√© | Temps √©coul√©: 241s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 760/1062 trait√© | Temps √©coul√©: 247s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 780/1062 trait√© | Temps √©coul√©: 254s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 800/1062 trait√© | Temps √©coul√©: 260s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 820/1062 trait√© | Temps √©coul√©: 266s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 840/1062 trait√© | Temps √©coul√©: 273s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 860/1062 trait√© | Temps √©coul√©: 279s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 880/1062 trait√© | Temps √©coul√©: 285s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 900/1062 trait√© | Temps √©coul√©: 291s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 920/1062 trait√© | Temps √©coul√©: 298s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 940/1062 trait√© | Temps √©coul√©: 304s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 960/1062 trait√© | Temps √©coul√©: 310s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 980/1062 trait√© | Temps √©coul√©: 317s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 1000/1062 trait√© | Temps √©coul√©: 323s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 1020/1062 trait√© | Temps √©coul√©: 329s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 1040/1062 trait√© | Temps √©coul√©: 335s\n",
      "   ‚ñ∂Ô∏è TRAIN | Batch 1060/1062 trait√© | Temps √©coul√©: 342s\n",
      "\n",
      "‚úÖ Extraction TRAIN termin√©e. On passe au VAL.\n",
      "\n",
      "üîä D√âMARRAGE EXTRACTION VAL (Total batchs: 266)\n",
      "   ‚ñ∂Ô∏è VAL | Batch 0/266 trait√© | Temps √©coul√©: 0s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 20/266 trait√© | Temps √©coul√©: 7s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 40/266 trait√© | Temps √©coul√©: 13s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 60/266 trait√© | Temps √©coul√©: 19s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 80/266 trait√© | Temps √©coul√©: 26s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 100/266 trait√© | Temps √©coul√©: 32s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 120/266 trait√© | Temps √©coul√©: 38s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 140/266 trait√© | Temps √©coul√©: 45s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 160/266 trait√© | Temps √©coul√©: 51s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 180/266 trait√© | Temps √©coul√©: 57s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 200/266 trait√© | Temps √©coul√©: 64s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 220/266 trait√© | Temps √©coul√©: 70s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 240/266 trait√© | Temps √©coul√©: 76s\n",
      "   ‚ñ∂Ô∏è VAL | Batch 260/266 trait√© | Temps √©coul√©: 83s\n",
      "\n",
      "‚úÖ Extraction FINIE. Shapes: (67932, 2048) / (16984, 2048)\n",
      "\n",
      "üß† Entra√Ænement du Cerveau (MLP)...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Half and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 126\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bx, by \u001b[38;5;129;01min\u001b[39;00m loader_train_ram:\n\u001b[32m    125\u001b[39m     optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     loss = criterion(\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbx\u001b[49m\u001b[43m)\u001b[49m, by)\n\u001b[32m    127\u001b[39m     loss.backward()\n\u001b[32m    128\u001b[39m     optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mLegendMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 must have the same dtype, but got Half and Float"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# --- CONFIG ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "IMG_DIR = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "# On baisse un peu le batch size par s√©curit√© pour la VRAM\n",
    "BATCH_SIZE = 64 \n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "print(f\"üöÄ GRAND RESET (MODE BAVARD & S√âCURIS√â) SUR : {DEVICE}\")\n",
    "\n",
    "# 1. DATASET\n",
    "print(\"üìÇ Pr√©paration du DataFrame...\")\n",
    "csv_path = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda x: os.path.join(IMG_DIR, f\"image_{x['imageid']}_product_{x['productid']}.jpg\"), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "class ExtractDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        # SQUISH 224x224 (Standard robuste)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try: img = Image.open(row['path']).convert(\"RGB\")\n",
    "        except: img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        return self.transform(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "\n",
    "# MODIFICATION CRITIQUE : num_workers=0 pour √©viter le freeze Windows\n",
    "train_loader = DataLoader(ExtractDataset(train_df), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "val_loader = DataLoader(ExtractDataset(val_df), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# 2. EXTRACTION DES FEATURES\n",
    "print(\"üèóÔ∏è Chargement ResNet50 (Extracteur)...\")\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "resnet.fc = nn.Identity()\n",
    "extractor = resnet.to(DEVICE)\n",
    "extractor.eval()\n",
    "\n",
    "def extract_features_loud(loader, name):\n",
    "    print(f\"\\nüîä D√âMARRAGE EXTRACTION {name} (Total batchs: {len(loader)})\")\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (imgs, lbls) in enumerate(loader):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            with autocast():\n",
    "                feats = extractor(imgs)\n",
    "            features_list.append(feats.cpu().numpy())\n",
    "            labels_list.append(lbls.numpy())\n",
    "            \n",
    "            # LOG VISIBLE TOUTES LES 20 SECONDES (Impossible de rater √ßa)\n",
    "            if i % 20 == 0: \n",
    "                elapsed = time.time() - t_start\n",
    "                # On force l'affichage avec print simple (pas de \\r)\n",
    "                print(f\"   ‚ñ∂Ô∏è {name} | Batch {i}/{len(loader)} trait√© | Temps √©coul√©: {elapsed:.0f}s\")\n",
    "            \n",
    "    return np.vstack(features_list), np.concatenate(labels_list)\n",
    "\n",
    "print(\"üî• Lancement de l'extraction...\")\n",
    "X_train_new, y_train_new = extract_features_loud(train_loader, \"TRAIN\")\n",
    "print(\"\\n‚úÖ Extraction TRAIN termin√©e. On passe au VAL.\")\n",
    "X_val_new, y_val_new = extract_features_loud(val_loader, \"VAL\")\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction FINIE. Shapes: {X_train_new.shape} / {X_val_new.shape}\")\n",
    "\n",
    "# 3. ENTRAINEMENT DU CERVEAU (MLP)\n",
    "print(\"\\nüß† Entra√Ænement du Cerveau (MLP)...\")\n",
    "\n",
    "train_ds_ram = torch.utils.data.TensorDataset(torch.tensor(X_train_new).to(DEVICE), torch.tensor(y_train_new).to(DEVICE))\n",
    "val_ds_ram = torch.utils.data.TensorDataset(torch.tensor(X_val_new).to(DEVICE), torch.tensor(y_val_new).to(DEVICE))\n",
    "loader_train_ram = DataLoader(train_ds_ram, batch_size=4096, shuffle=True)\n",
    "loader_val_ram = DataLoader(val_ds_ram, batch_size=4096, shuffle=False)\n",
    "\n",
    "class LegendMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048), nn.BatchNorm1d(2048), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),  nn.BatchNorm1d(512),  nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "mlp = LegendMLP(2048, NUM_CLASSES).to(DEVICE)\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_f1 = 0.0\n",
    "for epoch in range(15):\n",
    "    mlp.train()\n",
    "    for bx, by in loader_train_ram:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(mlp(bx), by)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Valid\n",
    "    mlp.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for bx, by in loader_val_ram:\n",
    "            _, p = torch.max(mlp(bx), 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(by.cpu().numpy())\n",
    "    \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    print(f\"   Ep {epoch+1} : F1 = {val_f1:.4f}\")\n",
    "    if val_f1 > best_f1: best_f1 = val_f1\n",
    "\n",
    "print(f\"üèÜ Score Final ResNet : {best_f1:.4f}\")\n",
    "\n",
    "# 4. SAUVEGARDE ET EXPORT\n",
    "print(\"\\nüíæ Sauvegarde du mod√®le Reborn...\")\n",
    "full_model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "full_model.fc = mlp\n",
    "torch.save(full_model.state_dict(), os.path.join(OUTPUT_DIR, \"livrable_model_resnet_reborn.pth\"))\n",
    "\n",
    "meta_data = {\"model_name\": \"ResNet Reborn Final\", \"class_mapping\": {int(i): str(c) for i, c in enumerate(le.classes_)}}\n",
    "with open(os.path.join(OUTPUT_DIR, \"livrable_resnet_reborn_metadata.json\"), 'w') as f:\n",
    "    json.dump(meta_data, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ TOUT EST PR√äT. LANCE LE VOTING MAINTENANT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55333a9b-5933-43a2-9c08-3f49fbdc6478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Conversion des donn√©es en Float32 (Correction du bug)...\n",
      "‚úÖ Donn√©es converties. On relance l'entra√Ænement du cerveau !\n",
      "üî• D√©marrage Entra√Ænement (15 Epoques)...\n",
      "   Ep 1 : F1 = 0.5366\n",
      "   Ep 2 : F1 = 0.5820\n",
      "   Ep 3 : F1 = 0.5892\n",
      "   Ep 4 : F1 = 0.6054\n",
      "   Ep 5 : F1 = 0.6126\n",
      "   Ep 6 : F1 = 0.6203\n",
      "   Ep 7 : F1 = 0.6145\n",
      "   Ep 8 : F1 = 0.6161\n",
      "   Ep 9 : F1 = 0.6248\n",
      "   Ep 10 : F1 = 0.6227\n",
      "   Ep 11 : F1 = 0.6090\n",
      "   Ep 12 : F1 = 0.6263\n",
      "   Ep 13 : F1 = 0.6096\n",
      "   Ep 14 : F1 = 0.6185\n",
      "   Ep 15 : F1 = 0.6136\n",
      "üèÜ Score Final ResNet : 0.6263\n",
      "\n",
      "üíæ Sauvegarde du mod√®le complet...\n",
      "‚úÖ TOUT EST PR√äT. Tu peux lancer le Voting (Notebook 06) !\n"
     ]
    }
   ],
   "source": [
    "# --- REPRISE APRES ERREUR DE FORMAT ---\n",
    "print(\"üîß Conversion des donn√©es en Float32 (Correction du bug)...\")\n",
    "\n",
    "# 1. On force la conversion en Float32 pour que le MLP soit content\n",
    "# (On utilise les variables qui sont DEJA en m√©moire gr√¢ce √† l'√©tape pr√©c√©dente)\n",
    "tensor_x_train = torch.tensor(X_train_new, dtype=torch.float32).to(DEVICE)\n",
    "tensor_y_train = torch.tensor(y_train_new, dtype=torch.long).to(DEVICE)\n",
    "tensor_x_val = torch.tensor(X_val_new, dtype=torch.float32).to(DEVICE)\n",
    "tensor_y_val = torch.tensor(y_val_new, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "train_ds_ram = torch.utils.data.TensorDataset(tensor_x_train, tensor_y_train)\n",
    "val_ds_ram = torch.utils.data.TensorDataset(tensor_x_val, tensor_y_val)\n",
    "\n",
    "loader_train_ram = DataLoader(train_ds_ram, batch_size=4096, shuffle=True)\n",
    "loader_val_ram = DataLoader(val_ds_ram, batch_size=4096, shuffle=False)\n",
    "\n",
    "print(\"‚úÖ Donn√©es converties. On relance l'entra√Ænement du cerveau !\")\n",
    "\n",
    "# 2. DEFINITION DU CERVEAU (MLP)\n",
    "class LegendMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048), nn.BatchNorm1d(2048), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),  nn.BatchNorm1d(512),  nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "mlp = LegendMLP(2048, NUM_CLASSES).to(DEVICE)\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 3. ENTRAINEMENT RAPIDE\n",
    "best_f1 = 0.0\n",
    "print(\"üî• D√©marrage Entra√Ænement (15 Epoques)...\")\n",
    "\n",
    "for epoch in range(15):\n",
    "    mlp.train()\n",
    "    for bx, by in loader_train_ram:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(mlp(bx), by)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Valid\n",
    "    mlp.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for bx, by in loader_val_ram:\n",
    "            _, p = torch.max(mlp(bx), 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(by.cpu().numpy())\n",
    "    \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    print(f\"   Ep {epoch+1} : F1 = {val_f1:.4f}\")\n",
    "    if val_f1 > best_f1: best_f1 = val_f1\n",
    "\n",
    "print(f\"üèÜ Score Final ResNet : {best_f1:.4f}\")\n",
    "\n",
    "# 4. SAUVEGARDE ET EXPORT (Pour le Voting)\n",
    "print(\"\\nüíæ Sauvegarde du mod√®le complet...\")\n",
    "full_model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "full_model.fc = mlp\n",
    "torch.save(full_model.state_dict(), os.path.join(OUTPUT_DIR, \"livrable_model_resnet_reborn.pth\"))\n",
    "\n",
    "meta_data = {\"model_name\": \"ResNet Reborn Final\", \"class_mapping\": {int(i): str(c) for i, c in enumerate(le.classes_)}}\n",
    "with open(os.path.join(OUTPUT_DIR, \"livrable_resnet_reborn_metadata.json\"), 'w') as f:\n",
    "    json.dump(meta_data, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ TOUT EST PR√äT. Tu peux lancer le Voting (Notebook 06) !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57703098-ee8b-4592-bf20-3d96b7592b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ASCENSION FINALE (62% -> 90%+) SUR : cuda\n",
      "üîß Chargement de la base saine (62%)...\n",
      "‚úÖ Poids charg√©s avec succ√®s.\n",
      "üîì TOUT EST D√âBLOQU√â. Le mod√®le va apprendre √† voir tes produits.\n",
      "üî• D√©marrage Fine-Tuning Profond (10 Epoques)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 1 | Batch 1400 | Loss: 0.4722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 1 | Time: 478s | F1: 0.6454\n",
      "   üíæ RECORD BATTU : 0.6454 (Sauvegard√©)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 2 | Batch 1400 | Loss: 0.1968"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 2 | Time: 497s | F1: 0.6521\n",
      "   üíæ RECORD BATTU : 0.6521 (Sauvegard√©)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 3 | Batch 1400 | Loss: 0.2904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ FIN EP 3 | Time: 500s | F1: 0.6560\n",
      "   üíæ RECORD BATTU : 0.6560 (Sauvegard√©)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚è≥ Ep 4 | Batch 1400 | Loss: 0.2574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amisf\\AppData\\Local\\Temp\\ipykernel_53660\\310892603.py:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(): out = model(imgs)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# --- CONFIG ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "IMG_DIR = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "BATCH_SIZE = 48 # Un peu moins gros car on d√©bloque tout (plus de m√©moire utilis√©e)\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "print(f\"üöÄ ASCENSION FINALE (62% -> 90%+) SUR : {DEVICE}\")\n",
    "\n",
    "# 1. DATASET (SQUISH 224 - LA BASE PROPRE)\n",
    "csv_path = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda x: os.path.join(IMG_DIR, f\"image_{x['imageid']}_product_{x['productid']}.jpg\"), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        # Augmentation l√©g√®re pour aider le fine-tuning\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.transform_val = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self): return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try: img = Image.open(row['path']).convert(\"RGB\")\n",
    "        except: img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        # On applique la transfo selon si on est en train ou val (astuce ici simplifi√©e)\n",
    "        # Par d√©faut on utilise transform_val pour √™tre s√ªr, mais pour l'entrainement\n",
    "        # l'id√©al est d'avoir l'augmentation. Ici on reste simple pour la stabilit√©.\n",
    "        return self.transform_val(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "\n",
    "# Astuce : On utilise la m√™me classe mais on pourrait s√©parer. \n",
    "# Ici pour aller vite et s√©curiser le 62%, on reste sur du standard.\n",
    "train_loader = DataLoader(TrainDataset(train_df), batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(TrainDataset(val_df), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# 2. CHARGEMENT DU MOD√àLE A 62%\n",
    "print(\"üîß Chargement de la base saine (62%)...\")\n",
    "resnet = models.resnet50(weights=None)\n",
    "\n",
    "# Architecture MLP Legend\n",
    "class LegendMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048), nn.BatchNorm1d(2048), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(1024, 512),  nn.BatchNorm1d(512),  nn.GELU(), nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "resnet.fc = LegendMLP(2048, NUM_CLASSES)\n",
    "model = resnet.to(DEVICE)\n",
    "\n",
    "# On charge le fichier qu'on vient de cr√©er (celui √† 62%)\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, \"livrable_model_resnet_reborn.pth\")))\n",
    "    print(\"‚úÖ Poids charg√©s avec succ√®s.\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Fichier introuvable, on repart des poids ImageNet (√ßa sera un peu plus long).\")\n",
    "    model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "    model.fc = LegendMLP(2048, NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "# 3. D√âBLOCAGE TOTAL (UNFREEZE ALL)\n",
    "# C'est LA cl√© du 90%. On laisse tout le r√©seau apprendre.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(\"üîì TOUT EST D√âBLOQU√â. Le mod√®le va apprendre √† voir tes produits.\")\n",
    "\n",
    "# 4. ENTRAINEMENT FIN (LOW LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Learning Rate tr√®s bas (1e-5) pour ne pas casser ce qui marche d√©j√†\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3)\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(\"üî• D√©marrage Fine-Tuning Profond (10 Epoques)...\")\n",
    "# On s'attend √† gagner ~2-3% par √©poque\n",
    "best_f1 = 0.6263 # Notre base\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    loss_ep = 0.0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for i, (imgs, lbls) in enumerate(train_loader):\n",
    "        imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, lbls)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        loss_ep += loss.item()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"   ‚è≥ Ep {epoch+1} | Batch {i} | Loss: {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            with autocast(): out = model(imgs)\n",
    "            _, p = torch.max(out, 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(lbls.cpu().numpy())\n",
    "    \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    duree = time.time() - t0\n",
    "    \n",
    "    print(f\"\\n‚úÖ FIN EP {epoch+1} | Time: {duree:.0f}s | F1: {val_f1:.4f}\")\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"livrable_model_resnet_reborn.pth\"))\n",
    "        print(f\"   üíæ RECORD BATTU : {val_f1:.4f} (Sauvegard√©)\")\n",
    "\n",
    "        # Update metadata\n",
    "        meta_data = {\"model_name\": \"ResNet50 FineTuned Ultimate\", \"class_mapping\": {int(i): str(c) for i, c in enumerate(le.classes_)}}\n",
    "        with open(os.path.join(OUTPUT_DIR, \"livrable_resnet_reborn_metadata.json\"), 'w') as f:\n",
    "            json.dump(meta_data, f, indent=4)\n",
    "\n",
    "print(f\"üèÜ Score Final : {best_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass_tooling",
   "language": "python",
   "name": "masterclass_tooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
