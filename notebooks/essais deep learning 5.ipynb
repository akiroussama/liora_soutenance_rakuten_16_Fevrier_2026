{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a496f8-1454-4315-81ad-da2559b74ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Check GPU post-reboot...\n",
      "   -> Pytorch Version: 2.6.0+cu124\n",
      "   -> GPU: NVIDIA GeForce RTX 4070\n",
      "   -> VRAM Libre: 11.26 Go / 12.88 Go\n",
      "âœ… VRAM OK (Vide).\n",
      "ðŸš€ Go Test Vitesse Pure (50 iters)...\n",
      "â±ï¸ Temps: 13.77s\n",
      "âš¡ Vitesse: 232 img/s\n",
      "âš ï¸ Toujours lent. C'est incomprÃ©hensible.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"ðŸ”¥ Check GPU post-reboot...\")\n",
    "\n",
    "# 1. VÃ©rification Version & VRAM\n",
    "print(f\"   -> Pytorch Version: {torch.__version__}\")\n",
    "print(f\"   -> GPU: {torch.cuda.get_device_name(0)}\")\n",
    "free_mem, total_mem = torch.cuda.mem_get_info()\n",
    "print(f\"   -> VRAM Libre: {free_mem/1e9:.2f} Go / {total_mem/1e9:.2f} Go\")\n",
    "\n",
    "if (free_mem/1e9) < 10:\n",
    "    print(\"âŒ ALERTE : Ta VRAM n'est pas vide ! Quelque chose tourne en fond.\")\n",
    "else:\n",
    "    print(\"âœ… VRAM OK (Vide).\")\n",
    "\n",
    "    # 2. Config Test\n",
    "    device = torch.device(\"cuda\")\n",
    "    batch_size = 64\n",
    "    num_classes = 27\n",
    "    \n",
    "    # ModÃ¨le Tiny (CrÃ©ation directe sur GPU)\n",
    "    model = timm.create_model('convnextv2_tiny.fcmae_ft_in22k_in1k', pretrained=False, num_classes=num_classes).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    # Faux Batch (Direct VRAM, zÃ©ro transfert)\n",
    "    x = torch.randn(batch_size, 3, 224, 224, device=device)\n",
    "    y = torch.randint(0, num_classes, (batch_size,), device=device)\n",
    "\n",
    "    print(\"ðŸš€ Go Test Vitesse Pure (50 iters)...\")\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # Mesure\n",
    "    t0 = time.time()\n",
    "    n_iters = 50\n",
    "    for _ in range(n_iters):\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    dt = time.time() - t0\n",
    "    fps = (n_iters * batch_size) / dt\n",
    "    \n",
    "    print(f\"â±ï¸ Temps: {dt:.2f}s\")\n",
    "    print(f\"âš¡ Vitesse: {fps:.0f} img/s\")\n",
    "    \n",
    "    if fps > 300:\n",
    "        print(\"ðŸŽ‰ VICTOIRE ! Ton GPU est dÃ©bridÃ©.\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Toujours lent. C'est incomprÃ©hensible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e508255-b531-46cc-91c5-4748e06aaae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ (1/2) Chargement DonnÃ©es en RAM (16 cÅ“urs CPU)...\n",
      "ðŸ“¥ Chargement Train (67932 images)...\n",
      "   -> Train: Paquet 14/14 ok\n",
      "ðŸ—ï¸ Conversion Tensor Train...\n",
      "âœ… Train TERMINÃ‰ en 712.2s\n",
      "ðŸ“¥ Chargement Val (16984 images)...\n",
      "   -> Val: Paquet 4/4 ok\n",
      "ðŸ—ï¸ Conversion Tensor Val...\n",
      "âœ… Val TERMINÃ‰ en 62.9s\n",
      "ðŸ’¾ RAM prÃªte. Passe Ã  la cellule 2.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "# 1. Config\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "project_root = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "img_dir = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "img_size = 224 # Standard\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "print(f\"ðŸš€ (1/2) Chargement DonnÃ©es en RAM ({num_workers} cÅ“urs CPU)...\")\n",
    "\n",
    "# 2. Prep DataFrame\n",
    "csv_path = os.path.join(project_root, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda x: os.path.join(img_dir, f\"image_{x['imageid']}_product_{x['productid']}.jpg\"), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "# 3. Fonctions Chargement\n",
    "def process_img(path):\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB').resize((img_size, img_size), Image.BILINEAR)\n",
    "        return np.array(img, dtype=np.uint8)\n",
    "    except:\n",
    "        return np.zeros((img_size, img_size, 3), dtype=np.uint8)\n",
    "\n",
    "def load_data_verbose(dataframe, name):\n",
    "    print(f\"ðŸ“¥ Chargement {name} ({len(dataframe)} images)...\")\n",
    "    t0 = time.time()\n",
    "    paths = dataframe['path'].values\n",
    "    labels = dataframe['label_encoded'].values\n",
    "    \n",
    "    all_images = []\n",
    "    chunk_size = 5000 \n",
    "    total_chunks = int(np.ceil(len(paths) / chunk_size))\n",
    "    \n",
    "    for i in range(total_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = min((i + 1) * chunk_size, len(paths))\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as ex:\n",
    "            batch_imgs = list(ex.map(process_img, paths[start:end]))\n",
    "        \n",
    "        all_images.extend(batch_imgs)\n",
    "        print(f\"   -> {name}: Paquet {i+1}/{total_chunks} ok\", end=\"\\r\")\n",
    "        del batch_imgs\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"\\nðŸ—ï¸ Conversion Tensor {name}...\")\n",
    "    x_tensor = torch.from_numpy(np.stack(all_images))\n",
    "    y_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    print(f\"âœ… {name} TERMINÃ‰ en {time.time() - t0:.1f}s\")\n",
    "    return x_tensor, y_tensor\n",
    "\n",
    "# Exec\n",
    "x_train, y_train = load_data_verbose(train_df, \"Train\")\n",
    "x_val, y_val = load_data_verbose(val_df, \"Val\")\n",
    "\n",
    "print(\"ðŸ’¾ RAM prÃªte. Passe Ã  la cellule 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c89ab4d-d2f9-41a3-91b1-05dc9fbdf8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relance mode transfer learning backbone gele\n",
      "reset du modele\n",
      "backbone gele seule la tete va apprendre\n",
      "ep 1 | batch 2100/2122 | loss 1.7444 | 864 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 1 | time 96s | f1 0.6130 | \n",
      "ep 2 | batch 2100/2122 | loss 1.5646 | 874 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 2 | time 96s | f1 0.6175 | \n",
      "ep 3 | batch 2100/2122 | loss 1.7812 | 876 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 3 | time 96s | f1 0.6221 | \n",
      "ep 4 | batch 2100/2122 | loss 1.4993 | 876 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 4 | time 97s | f1 0.6240 | \n",
      "ep 5 | batch 2100/2122 | loss 1.4675 | 874 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 5 | time 96s | f1 0.6191 | \n",
      "ep 6 | batch 2100/2122 | loss 1.9514 | 875 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 6 | time 97s | f1 0.6232 | \n",
      "ep 7 | batch 2100/2122 | loss 1.6442 | 873 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 7 | time 97s | f1 0.6273 | \n",
      "ep 8 | batch 2100/2122 | loss 2.1329 | 876 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 8 | time 96s | f1 0.6285 | \n",
      "ep 9 | batch 2100/2122 | loss 1.7551 | 870 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 9 | time 97s | f1 0.6286 | \n",
      "ep 10 | batch 2100/2122 | loss 1.6036 | 876 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 10 | time 96s | f1 0.6266 | \n",
      "ep 11 | batch 2100/2122 | loss 1.8101 | 868 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 11 | time 96s | f1 0.6267 | \n",
      "ep 12 | batch 2100/2122 | loss 1.4991 | 878 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 12 | time 97s | f1 0.6283 | \n",
      "ep 13 | batch 2100/2122 | loss 1.7267 | 869 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 13 | time 96s | f1 0.6323 | \n",
      "ep 14 | batch 2100/2122 | loss 1.6660 | 868 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 14 | time 97s | f1 0.6341 | \n",
      "ep 15 | batch 2100/2122 | loss 1.2791 | 884 img/s\n",
      "debug : le modele a predit 27/27 classes differentes\n",
      "fin ep 15 | time 95s | f1 0.6336 | \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"relance mode transfer learning backbone gele\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\")\n",
    "batch_size = 32 \n",
    "# je reduis a 15 epochs car ca converge vite\n",
    "epochs = 15 \n",
    "output_dir = os.path.join(project_root, \"implementation\", \"outputs\")\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "# 1. rechargement propre\n",
    "print(\"reset du modele\")\n",
    "model = timm.create_model(\n",
    "    'convnextv2_tiny.fcmae_ft_in22k_in1k', \n",
    "    pretrained=True, \n",
    "    num_classes=num_classes,\n",
    "    drop_rate=0.1\n",
    ").to(device)\n",
    "\n",
    "# 2. freeze\n",
    "# je bloque la mise a jour des poids du reseau profond\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# je debloque juste la derniere couche pour apprendre tes classes\n",
    "# convnext utilise head fc pour la classification\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(\"backbone gele seule la tete va apprendre\")\n",
    "\n",
    "# 3. optimisation\n",
    "# je garde un lr eleve car je ne touche qu a la fin\n",
    "optimizer = optim.AdamW(model.head.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "mean_gpu = torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "std_gpu = torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)\n",
    "\n",
    "# 4. boucle\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    t_start = time.time()\n",
    "    t_last = time.time()\n",
    "    \n",
    "    indices = torch.randperm(len(x_train))\n",
    "    n_samples = len(x_train)\n",
    "    steps = n_samples // batch_size\n",
    "    \n",
    "    for step, i in enumerate(range(0, n_samples, batch_size)):\n",
    "        idx = indices[i : i + batch_size]\n",
    "        bx = x_train[idx].to(device, non_blocking=True)\n",
    "        by = y_train[idx].to(device, non_blocking=True)\n",
    "        \n",
    "        bx = bx.permute(0,3,1,2).float().div(255.0).sub(mean_gpu).div(std_gpu)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(bx)\n",
    "            loss = criterion(out, by)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            curr = time.time()\n",
    "            speed = (50 * batch_size) / (curr - t_last + 1e-6)\n",
    "            print(f\"ep {epoch+1} | batch {step}/{steps} | loss {loss.item():.4f} | {speed:.0f} img/s\", end=\"\\r\")\n",
    "            t_last = curr\n",
    "\n",
    "    # validation et debug\n",
    "    print(f\"\\nep {epoch+1} : validation\", end=\"\\r\")\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x_val), batch_size):\n",
    "            bx = x_val[i : i + batch_size].to(device, non_blocking=True)\n",
    "            by = y_val[i : i + batch_size]\n",
    "            \n",
    "            bx = bx.permute(0,3,1,2).float().div(255.0).sub(mean_gpu).div(std_gpu)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model(bx)\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "            targets.extend(by.numpy())\n",
    "            \n",
    "    score = f1_score(targets, preds, average='weighted')\n",
    "    dt = time.time() - t_start\n",
    "    \n",
    "    # debug pour verifier que le modele ne predit pas toujours pareil\n",
    "    unique_preds = len(np.unique(preds))\n",
    "    print(f\"debug : le modele a predit {unique_preds}/{num_classes} classes differentes\")\n",
    "    \n",
    "    status = \"\"\n",
    "    if score > 0.8:\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, \"model_frozen_v1.pth\"))\n",
    "        status = \"saved\"\n",
    "    \n",
    "    scheduler.step(score)\n",
    "    print(f\"fin ep {epoch+1} | time {dt:.0f}s | f1 {score:.4f} | {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150e89b4-a2a6-446e-9596-72311d30ca85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 2 : deblocage total fine tuning\n",
      "deblocage de tous les parametres\n",
      "c est parti pour 20 epochs avec lr 5e-05\n",
      "note : la vitesse va baisser vers 230 img/s c est normal\n",
      "ep ft 1 | batch 2100/2122 | loss 1.6653 | 228 img/s\n",
      "ep ft 1 | time 320s | f1 0.7039 | lr 5.0e-05 | new record saved\n",
      "ep ft 2 | batch 2100/2122 | loss 1.1806 | 225 img/s\n",
      "ep ft 2 | time 319s | f1 0.7175 | lr 5.0e-05 | new record saved\n",
      "ep ft 3 | batch 2100/2122 | loss 0.9698 | 225 img/s\n",
      "ep ft 3 | time 322s | f1 0.7166 | lr 5.0e-05 | \n",
      "ep ft 4 | batch 2100/2122 | loss 0.7374 | 230 img/s\n",
      "ep ft 4 | time 317s | f1 0.7132 | lr 5.0e-05 | \n",
      "ep ft 5 | batch 2100/2122 | loss 0.8638 | 230 img/s\n",
      "ep ft 5 | time 314s | f1 0.7100 | lr 5.0e-05 | \n",
      "ep ft 6 | batch 2100/2122 | loss 0.6913 | 230 img/s\n",
      "ep ft 6 | time 314s | f1 0.7108 | lr 2.5e-05 | \n",
      "ep ft 7 | batch 2100/2122 | loss 0.6890 | 230 img/s\n",
      "ep ft 7 | time 314s | f1 0.7226 | lr 2.5e-05 | new record saved\n",
      "ep ft 8 | batch 2100/2122 | loss 0.6667 | 229 img/s\n",
      "ep ft 8 | time 315s | f1 0.7199 | lr 2.5e-05 | \n",
      "ep ft 9 | batch 2100/2122 | loss 0.6620 | 229 img/s\n",
      "ep ft 9 | time 314s | f1 0.7246 | lr 2.5e-05 | new record saved\n",
      "ep ft 10 | batch 2100/2122 | loss 0.6878 | 229 img/s\n",
      "ep ft 10 | time 314s | f1 0.7257 | lr 2.5e-05 | new record saved\n",
      "ep ft 11 | batch 2100/2122 | loss 0.6501 | 229 img/s\n",
      "ep ft 11 | time 314s | f1 0.7211 | lr 2.5e-05 | \n",
      "ep ft 12 | batch 2100/2122 | loss 0.6472 | 225 img/s\n",
      "ep ft 12 | time 315s | f1 0.7233 | lr 2.5e-05 | \n",
      "ep ft 13 | batch 2100/2122 | loss 0.7465 | 230 img/s\n",
      "ep ft 13 | time 316s | f1 0.7179 | lr 2.5e-05 | \n",
      "ep ft 14 | batch 2100/2122 | loss 0.6569 | 227 img/s\n",
      "ep ft 14 | time 317s | f1 0.7257 | lr 1.3e-05 | \n",
      "ep ft 15 | batch 2100/2122 | loss 0.7093 | 229 img/s\n",
      "ep ft 15 | time 317s | f1 0.7264 | lr 1.3e-05 | new record saved\n",
      "ep ft 16 | batch 2100/2122 | loss 0.6542 | 227 img/s\n",
      "ep ft 16 | time 317s | f1 0.7276 | lr 1.3e-05 | new record saved\n",
      "ep ft 17 | batch 2100/2122 | loss 0.6372 | 222 img/s\n",
      "ep ft 17 | time 319s | f1 0.7267 | lr 1.3e-05 | \n",
      "ep ft 18 | batch 2100/2122 | loss 0.6358 | 225 img/s\n",
      "ep ft 18 | time 321s | f1 0.7287 | lr 1.3e-05 | new record saved\n",
      "ep ft 19 | batch 2100/2122 | loss 0.6609 | 228 img/s\n",
      "ep ft 19 | time 318s | f1 0.7257 | lr 1.3e-05 | \n",
      "ep ft 20 | batch 2100/2122 | loss 0.6381 | 230 img/s\n",
      "ep ft 20 | time 317s | f1 0.7291 | lr 1.3e-05 | new record saved\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"phase 2 : deblocage total fine tuning\")\n",
    "\n",
    "# config\n",
    "# je divise le lr par 20 pour y aller doucement\n",
    "fine_tune_lr = 5e-5\n",
    "epochs_ft = 20\n",
    "best_score = 0.63 # on part du score actuel\n",
    "\n",
    "# 1. unfreeze\n",
    "print(\"deblocage de tous les parametres\")\n",
    "# je libere tout le reseau\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 2. optimizer\n",
    "# je change l optimizer pour le lr faible\n",
    "optimizer = optim.AdamW(model.parameters(), lr=fine_tune_lr, weight_decay=0.05)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "print(f\"c est parti pour {epochs_ft} epochs avec lr {fine_tune_lr}\")\n",
    "print(\"note : la vitesse va baisser vers 230 img/s c est normal\")\n",
    "\n",
    "# 3. boucle fine tuning\n",
    "for epoch in range(epochs_ft):\n",
    "    model.train()\n",
    "    t_start = time.time()\n",
    "    t_last = time.time()\n",
    "    \n",
    "    indices = torch.randperm(len(x_train))\n",
    "    n_samples = len(x_train)\n",
    "    steps = n_samples // batch_size\n",
    "    \n",
    "    for step, i in enumerate(range(0, n_samples, batch_size)):\n",
    "        idx = indices[i : i + batch_size]\n",
    "        bx = x_train[idx].to(device, non_blocking=True)\n",
    "        by = y_train[idx].to(device, non_blocking=True)\n",
    "        \n",
    "        bx = bx.permute(0,3,1,2).float().div(255.0).sub(mean_gpu).div(std_gpu)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(bx)\n",
    "            loss = criterion(out, by)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            curr = time.time()\n",
    "            speed = (50 * batch_size) / (curr - t_last + 1e-6)\n",
    "            print(f\"ep ft {epoch+1} | batch {step}/{steps} | loss {loss.item():.4f} | {speed:.0f} img/s\", end=\"\\r\")\n",
    "            t_last = curr\n",
    "\n",
    "    # validation\n",
    "    print(f\"\\nep ft {epoch+1} : validation\", end=\"\\r\")\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x_val), batch_size):\n",
    "            bx = x_val[i : i + batch_size].to(device, non_blocking=True)\n",
    "            by = y_val[i : i + batch_size]\n",
    "            \n",
    "            bx = bx.permute(0,3,1,2).float().div(255.0).sub(mean_gpu).div(std_gpu)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model(bx)\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "            targets.extend(by.numpy())\n",
    "            \n",
    "    score = f1_score(targets, preds, average='weighted')\n",
    "    dt = time.time() - t_start\n",
    "    \n",
    "    # save\n",
    "    status = \"\"\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, \"model_best_finetuned.pth\"))\n",
    "        status = \"new record saved\"\n",
    "    \n",
    "    scheduler.step(score)\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"ep ft {epoch+1} | time {dt:.0f}s | f1 {score:.4f} | lr {lr:.1e} | {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f05b17-42e0-480e-b7f9-76b2edb007ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation mode autorastapilote intelligent\n",
      "\n",
      "--- demarrage phase_1_finition (max 15 ep) ---\n",
      "config lr 1e-05 | augmentation False | patience 4\n",
      "fin phase_1_finition ep 1 | time 322s | f1 0.7284 | lr 1.0e-05 | stagnation 1/4\n",
      "fin phase_1_finition ep 2 | time 319s | f1 0.7287 | lr 1.0e-05 | stagnation 2/4\n",
      "fin phase_1_finition ep 3 | time 315s | f1 0.7286 | lr 1.0e-05 | stagnation 3/4\n",
      "fin phase_1_finition ep 4 | time 314s | f1 0.7298 | lr 1.0e-05 | record saved\n",
      "fin phase_1_finition ep 5 | time 314s | f1 0.7260 | lr 1.0e-05 | stagnation 1/4\n",
      "fin phase_1_finition ep 6 | time 314s | f1 0.7297 | lr 1.0e-05 | stagnation 2/4\n",
      "fin phase_1_finition ep 7 | time 315s | f1 0.7281 | lr 1.0e-05 | stagnation 3/4\n",
      "fin phase_1_finition ep 8 | time 318s | f1 0.7290 | lr 5.0e-06 | stagnation 4/4\n",
      "stop : plus de progres sur phase_1_finition depuis 4 epochs\n",
      "passage automatique a la phase suivante\n",
      "\n",
      "--- transition : activation mode difficile ---\n",
      "\n",
      "--- demarrage phase_2_hardcore (max 30 ep) ---\n",
      "config lr 4e-05 | augmentation True | patience 6\n",
      "fin phase_2_hardcore ep 1 | time 320s | f1 0.7103 | lr 4.0e-05 | stagnation 1/6\n",
      "fin phase_2_hardcore ep 2 | time 319s | f1 0.7144 | lr 4.0e-05 | stagnation 2/6\n",
      "fin phase_2_hardcore ep 3 | time 319s | f1 0.7093 | lr 4.0e-05 | stagnation 3/6\n",
      "fin phase_2_hardcore ep 4 | time 318s | f1 0.7089 | lr 4.0e-05 | stagnation 4/6\n",
      "fin phase_2_hardcore ep 5 | time 318s | f1 0.7115 | lr 4.0e-05 | stagnation 5/6\n",
      "fin phase_2_hardcore ep 6 | time 318s | f1 0.7205 | lr 2.0e-05 | stagnation 6/6\n",
      "stop : plus de progres sur phase_2_hardcore depuis 6 epochs\n",
      "passage automatique a la phase suivante\n",
      "\n",
      "terminus tout le monde descend , cest le max du max sur ce modele ,j'ai fais le max \n",
      "meilleur score final : 0.7298\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from torchvision import transforms\n",
    "\n",
    "print(\"activation mode autorastapilote intelligent\")\n",
    "\n",
    "# config\n",
    "device = torch.device(\"cuda\")\n",
    "output_dir = os.path.join(project_root, \"implementation\", \"outputs\")\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "# je recupere le modele deja en memoire\n",
    "\n",
    "# je definis l augmentation gpu\n",
    "# c est plus rapide que de le faire au chargement cpu(comme avant quoi )\n",
    "aug_transform = nn.Sequential(\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    ").to(device)\n",
    "\n",
    "# stats normalisation\n",
    "mean_gpu = torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "std_gpu = torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# fonction entrainement generique\n",
    "def run_cycle(mode_name, epochs, lr, use_aug=False, patience=5):\n",
    "    print(f\"\\n--- demarrage {mode_name} (max {epochs} ep) ---\")\n",
    "    print(f\"config lr {lr} | augmentation {use_aug} | patience {patience}\")\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.05)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "    \n",
    "    # je recupere le meilleur score actuel\n",
    "    global best_score\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        t_start = time.time()\n",
    "        \n",
    "        indices = torch.randperm(len(x_train))\n",
    "        n_samples = len(x_train)\n",
    "        steps = n_samples // batch_size\n",
    "        \n",
    "        for step, i in enumerate(range(0, n_samples, batch_size)):\n",
    "            idx = indices[i : i + batch_size]\n",
    "            bx = x_train[idx].to(device, non_blocking=True)\n",
    "            by = y_train[idx].to(device, non_blocking=True)\n",
    "            \n",
    "            bx = bx.permute(0,3,1,2).float().div(255.0)\n",
    "            \n",
    "            # j applique l augmentation si demandee\n",
    "            if use_aug:\n",
    "                bx = aug_transform(bx)\n",
    "            \n",
    "            bx = bx.sub(mean_gpu).div(std_gpu)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model(bx)\n",
    "                loss = criterion(out, by)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                 print(f\"{mode_name} ep {epoch+1} | batch {step}/{steps} | loss {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(x_val), batch_size):\n",
    "                bx = x_val[i : i + batch_size].to(device, non_blocking=True)\n",
    "                by = y_val[i : i + batch_size]\n",
    "                \n",
    "                # jamais d augmentation en validation\n",
    "                bx = bx.permute(0,3,1,2).float().div(255.0).sub(mean_gpu).div(std_gpu)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    out = model(bx)\n",
    "                preds.extend(out.argmax(1).cpu().numpy())\n",
    "                targets.extend(by.numpy())\n",
    "        \n",
    "        score = f1_score(targets, preds, average='weighted')\n",
    "        dt = time.time() - t_start\n",
    "        \n",
    "        status = \"\"\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, f\"model_autopilot_best.pth\"))\n",
    "            status = \"record saved\"\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            status = f\"stagnation {no_improve}/{patience}\"\n",
    "        \n",
    "        cur_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"fin {mode_name} ep {epoch+1} | time {dt:.0f}s | f1 {score:.4f} | lr {cur_lr:.1e} | {status}\")\n",
    "        \n",
    "        scheduler.step(score)\n",
    "        \n",
    "        # switch automatique\n",
    "        if no_improve >= patience:\n",
    "            print(f\"stop : plus de progres sur {mode_name} depuis {patience} epochs\")\n",
    "            print(\"passage automatique a la phase suivante\")\n",
    "            return # on sort de la fonction pour passer a la suite\n",
    "\n",
    "# --- execution du plan de vol ---\n",
    "\n",
    "# 1. on continue ce qu on faisait (sans aug) pour gratter les derniers % faciles\n",
    "# je mets un lr tres faible pour ne rien casser\n",
    "if 'best_score' not in globals(): best_score = 0.75 # valeur par defaut si kernel restart\n",
    "run_cycle(\"phase_1_finition\", epochs=15, lr=1e-5, use_aug=False, patience=4)\n",
    "\n",
    "print(\"\\n--- transition : activation mode difficile ---\")\n",
    "\n",
    "# 2. on active le mode difficile (avec aug) pour forcer l apprentissage\n",
    "# je remonte un peu le lr car c est plus dur\n",
    "run_cycle(\"phase_2_hardcore\", epochs=30, lr=4e-5, use_aug=True, patience=6)\n",
    "\n",
    "print(\"\\nterminus tout le monde descend , cest le max du max sur ce modele ,j'ai fais le max \")\n",
    "print(f\"meilleur score final : {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d22cf0a-d6f2-4c18-b090-4a89a7ec5983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier trouve : model_autopilot_best.pth\n",
      "taille : 106.46 mo\n",
      "sauvegarde validee nous sommes prets pour la suite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# je verifie si le fichier existe et sa taille\n",
    "file_path = os.path.join(output_dir, \"model_autopilot_best.pth\")\n",
    "if os.path.exists(file_path):\n",
    "    size = os.path.getsize(file_path) / (1024*1024)\n",
    "    print(f\"fichier trouve : model_autopilot_best.pth\")\n",
    "    print(f\"taille : {size:.2f} mo\")\n",
    "    print(\"sauvegarde validee nous sommes prets pour la suite\")\n",
    "else:\n",
    "    print(\"alerte : fichier non trouve verifie le chemin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b2db77-574d-4799-a409-6cd560cae4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellule test : verif des predictions\n",
      "test des predictions sur le modele tiny a 73%\n",
      "--------------------------------------------------\n",
      "image 6083 :\n",
      "reel : 1320\n",
      "pred : 1320 -> ok\n",
      "--------------------\n",
      "image 7632 :\n",
      "reel : 2583\n",
      "pred : 2583 -> ok\n",
      "--------------------\n",
      "image 8986 :\n",
      "reel : 1160\n",
      "pred : 1160 -> ok\n",
      "--------------------\n",
      "image 1494 :\n",
      "reel : 1280\n",
      "pred : 1140 -> erreur\n",
      "--------------------\n",
      "image 620 :\n",
      "reel : 1560\n",
      "pred : 1560 -> ok\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"cellule test : verif des predictions\")\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# je charge les poids sauvegardes\n",
    "model_path = os.path.join(output_dir, \"model_autopilot_best.pth\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# nous choisissons 5 images au hasard\n",
    "n_tests = 5\n",
    "indices = np.random.choice(len(x_val), n_tests, replace=False)\n",
    "\n",
    "print(\"test des predictions sur le modele tiny a 73%\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in indices:\n",
    "        # je prepare l image\n",
    "        img_raw = x_val[idx]\n",
    "        true_label_idx = y_val[idx].item()\n",
    "        \n",
    "        # nous passons l image sur gpu avec la bonne forme\n",
    "        bx = img_raw.unsqueeze(0).to(device).permute(0,3,1,2).float().div(255.0)\n",
    "        bx = bx.sub(mean_gpu).div(std_gpu)\n",
    "        \n",
    "        # je lance le calcul\n",
    "        out = model(bx)\n",
    "        pred_idx = out.argmax(1).item()\n",
    "        \n",
    "        # nous traduisons les codes\n",
    "        true_code = le.inverse_transform([true_label_idx])[0]\n",
    "        pred_code = le.inverse_transform([pred_idx])[0]\n",
    "        \n",
    "        # je verifie si c est bon\n",
    "        result = \"ok\" if true_code == pred_code else \"erreur\"\n",
    "        \n",
    "        print(f\"image {idx} :\")\n",
    "        print(f\"reel : {true_code}\")\n",
    "        print(f\"pred : {pred_code} -> {result}\")\n",
    "        print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc2a15e3-1c7f-4383-9c3e-64469a9623ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cellule : analyse des erreurs par matrice\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 3 des confusions a surveiller ce soir :\n",
      "erreur frequente : reel 1280 confondu avec 1300\n",
      "erreur frequente : reel 2403 confondu avec 2280\n",
      "erreur frequente : reel 1560 confondu avec 2060\n"
     ]
    }
   ],
   "source": [
    "print(\"cellule : analyse des erreurs par matrice\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# nous generons la matrice de confusion\n",
    "def affiche_erreurs():\n",
    "    # je calcule la matrice sur les derniers resultats de val\n",
    "    cm = confusion_matrix(targets, preds)\n",
    "    \n",
    "    # nous affichons le graphique\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    # je mets des couleurs pour voir les zones de confusion\n",
    "    sns.heatmap(cm, annot=False, cmap='viridis')\n",
    "    plt.title(\"matrice de confusion modele tiny\")\n",
    "    plt.xlabel(\"predictions\")\n",
    "    plt.ylabel(\"reel\")\n",
    "    plt.show()\n",
    "    \n",
    "    # je cherche les 3 pires confusions\n",
    "    # nous aplatissons la matrice pour trouver les hors diagonale\n",
    "    cm_mask = cm.copy()\n",
    "    np.fill_diagonal(cm_mask, 0)\n",
    "    idx = np.unravel_index(np.argsort(cm_mask, axis=None)[-3:], cm_mask.shape)\n",
    "    \n",
    "    print(\"top 3 des confusions a surveiller ce soir :\")\n",
    "    for i in range(2, -1, -1):\n",
    "        r, p = idx[0][i], idx[1][i]\n",
    "        c1 = le.inverse_transform([r])[0]\n",
    "        c2 = le.inverse_transform([p])[0]\n",
    "        print(f\"erreur frequente : reel {c1} confondu avec {c2}\")\n",
    "\n",
    "affiche_erreurs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365de4f2-3610-4e7c-8288-ee5f20179565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables ok nous pouvons lancer la suite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# je definis le chemin racine du projet\n",
    "project_root = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "\n",
    "# nous fixons le nombre de classes pour le modele\n",
    "# je me base sur tes 27 categories\n",
    "num_classes = 27\n",
    "\n",
    "# je verifie que les dossiers existent\n",
    "if not os.path.exists(project_root):\n",
    "    print(\"erreur le chemin project root est introuvable\")\n",
    "else:\n",
    "    print(\"variables ok nous pouvons lancer la suite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e2f7c0-ae85-4f6c-a471-f57df1b16bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VÃ©rification des donnÃ©es : Train=67932, Val=16984\n",
      "Lancement protocole nuit : ConvNeXt Base\n",
      "Chargement du modÃ¨le ConvNeXt V2 Base...\n",
      "Phase 1 : Ã‰chauffement de la tÃªte (Backbone gelÃ©)\n",
      "Ã‰poque Phase 1 1/5 terminÃ©e"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     73\u001b[39m         loss = criterion(out, by)\n\u001b[32m     74\u001b[39m     scaler.scale(loss).backward()\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     scaler.update()\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mÃ‰poque Phase 1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs_phase1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m terminÃ©e\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\masterclass_tooling\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from torchvision import transforms\n",
    "\n",
    "# --- VERIFICATION DES PRE-REQUIS ---\n",
    "try:\n",
    "    print(f\"VÃ©rification des donnÃ©es : Train={len(x_train)}, Val={len(x_val)}\")\n",
    "except NameError:\n",
    "    raise NameError(\"ERREUR : Les donnÃ©es x_train ne sont pas chargÃ©es. Relancez la cellule de chargement des images avant de continuer.\")\n",
    "\n",
    "# Configuration des chemins\n",
    "project_root = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "output_dir = os.path.join(project_root, \"implementation\", \"outputs\")\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "\n",
    "print(\"Lancement protocole nuit : ConvNeXt Base\")\n",
    "\n",
    "# --- CONFIGURATION TECHNIQUE ---\n",
    "device = torch.device(\"cuda\")\n",
    "real_batch_size = 16 \n",
    "accum_steps = 2 \n",
    "epochs_phase1 = 5\n",
    "epochs_phase2 = 25\n",
    "patience_stop = 5\n",
    "\n",
    "# Augmentation de donnÃ©es sur GPU\n",
    "aug_transform = nn.Sequential(\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    ").to(device)\n",
    "\n",
    "# Normalisation\n",
    "mean_gpu = torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "std_gpu = torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)\n",
    "\n",
    "# --- INITIALISATION DU MODELE ---\n",
    "print(\"Chargement du modÃ¨le ConvNeXt V2 Base...\")\n",
    "model = timm.create_model(\n",
    "    'convnextv2_base.fcmae_ft_in22k_in1k', \n",
    "    pretrained=True, \n",
    "    num_classes=27, # Nombre de classes de votre projet\n",
    "    drop_rate=0.3\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# --- PHASE 1 : ENTRAINEMENT DE LA TETE ---\n",
    "print(\"Phase 1 : Ã‰chauffement de la tÃªte (Backbone gelÃ©)\")\n",
    "for param in model.parameters(): param.requires_grad = False\n",
    "for param in model.head.parameters(): param.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(model.head.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(epochs_phase1):\n",
    "    model.train()\n",
    "    indices = torch.randperm(len(x_train))\n",
    "    for i in range(0, len(x_train), real_batch_size):\n",
    "        idx = indices[i : i + real_batch_size]\n",
    "        bx = x_train[idx].to(device, non_blocking=True).permute(0,3,1,2).float().div(255.0)\n",
    "        by = y_train[idx].to(device, non_blocking=True)\n",
    "        bx = aug_transform(bx).sub(mean_gpu).div(std_gpu)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(bx)\n",
    "            loss = criterion(out, by)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    print(f\"Ã‰poque Phase 1 {epoch+1}/{epochs_phase1} terminÃ©e\", end=\"\\r\")\n",
    "\n",
    "# --- PHASE 2 : FINE-TUNING COMPLET ---\n",
    "print(\"\\nPhase 2 : DÃ©blocage complet et monitoring d'arrÃªt prÃ©coce\")\n",
    "for param in model.parameters(): param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=4e-5, weight_decay=0.05)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "best_score = 0.0\n",
    "no_improve_count = 0\n",
    "\n",
    "for epoch in range(epochs_phase2):\n",
    "    model.train()\n",
    "    t_start = time.time()\n",
    "    indices = torch.randperm(len(x_train))\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, i in enumerate(range(0, len(x_train), real_batch_size)):\n",
    "        idx = indices[i : i + real_batch_size]\n",
    "        bx = x_train[idx].to(device, non_blocking=True).permute(0,3,1,2).float().div(255.0)\n",
    "        by = y_train[idx].to(device, non_blocking=True)\n",
    "        \n",
    "        bx = aug_transform(bx).sub(mean_gpu).div(std_gpu)\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(bx)\n",
    "            loss = criterion(out, by) / accum_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % accum_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x_val), real_batch_size):\n",
    "            bx = x_val[i : i + real_batch_size].to(device).permute(0,3,1,2).float().div(255.0).sub(mean_gpu).div(std_gpu)\n",
    "            out = model(bx)\n",
    "            all_preds.extend(out.argmax(1).cpu().numpy())\n",
    "            all_targets.extend(y_val[i : i + real_batch_size].numpy())\n",
    "            \n",
    "    score = f1_score(all_targets, all_preds, average='weighted')\n",
    "    \n",
    "    # Sauvegarde et Early Stopping\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        no_improve_count = 0\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, \"model_base_night_best.pth\"))\n",
    "        status = \"Nouveau record sauvegardÃ©\"\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        status = f\"Stagnation {no_improve_count}/{patience_stop}\"\n",
    "        \n",
    "    print(f\"Ã‰poque {epoch+1} | F1 Score: {score:.4f} | {status}\")\n",
    "    scheduler.step(score)\n",
    "    \n",
    "    if no_improve_count >= patience_stop:\n",
    "        print(f\"ArrÃªt prÃ©coce : le score n'a pas progressÃ© depuis {patience_stop} Ã©poques.\")\n",
    "        break\n",
    "\n",
    "print(\"EntraÃ®nement de nuit terminÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f34041-1324-4792-86e3-d88469548515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lancement protocole nuit convnext base avec monitoring complet\n",
      "chargement convnext v2 base\n",
      "phase 1 : entrainement tete seule backbone gele\n",
      "p1 ep 1 | batch 4200/4245 | loss 1.2229 | 400 img/s\n",
      "fin phase 1 ep 1 terminee\n",
      "p1 ep 2 | batch 4200/4245 | loss 1.4997 | 396 img/s\n",
      "fin phase 1 ep 2 terminee\n",
      "p1 ep 3 | batch 4200/4245 | loss 1.9660 | 396 img/s\n",
      "fin phase 1 ep 3 terminee\n",
      "p1 ep 4 | batch 4200/4245 | loss 1.8505 | 397 img/s\n",
      "fin phase 1 ep 4 terminee\n",
      "p1 ep 5 | batch 4200/4245 | loss 1.6528 | 400 img/s\n",
      "fin phase 1 ep 5 terminee\n",
      "phase 2 : deblocage complet monitoring actif\n",
      "p2 ep 1 | batch 4200/4245 | loss 1.2081 | 102 img/s\n",
      "ep 1 : validation en cours\n",
      "fin ep 1 | f1 0.7218 | record ok\n",
      "p2 ep 2 | batch 4200/4245 | loss 1.2097 | 104 img/s\n",
      "ep 2 : validation en cours\n",
      "fin ep 2 | f1 0.7344 | record ok\n",
      "p2 ep 3 | batch 4200/4245 | loss 1.2872 | 102 img/s\n",
      "ep 3 : validation en cours\n",
      "fin ep 3 | f1 0.7385 | record ok\n",
      "p2 ep 4 | batch 4200/4245 | loss 1.0233 | 102 img/s\n",
      "ep 4 : validation en cours\n",
      "fin ep 4 | f1 0.7374 | stagne 1/5\n",
      "p2 ep 5 | batch 4200/4245 | loss 0.8026 | 104 img/s\n",
      "ep 5 : validation en cours\n",
      "fin ep 5 | f1 0.7341 | stagne 2/5\n",
      "p2 ep 6 | batch 4200/4245 | loss 0.6781 | 103 img/s\n",
      "ep 6 : validation en cours\n",
      "fin ep 6 | f1 0.7324 | stagne 3/5\n",
      "p2 ep 7 | batch 4200/4245 | loss 0.6672 | 102 img/s\n",
      "ep 7 : validation en cours\n",
      "fin ep 7 | f1 0.7447 | record ok\n",
      "p2 ep 8 | batch 4200/4245 | loss 0.6641 | 102 img/s\n",
      "ep 8 : validation en cours\n",
      "fin ep 8 | f1 0.7407 | stagne 1/5\n",
      "p2 ep 9 | batch 4200/4245 | loss 0.6780 | 104 img/s\n",
      "ep 9 : validation en cours\n",
      "fin ep 9 | f1 0.7420 | stagne 2/5\n",
      "p2 ep 10 | batch 4200/4245 | loss 0.6530 | 103 img/s\n",
      "ep 10 : validation en cours\n",
      "fin ep 10 | f1 0.7427 | stagne 3/5\n",
      "p2 ep 11 | batch 4200/4245 | loss 0.6477 | 103 img/s\n",
      "ep 11 : validation en cours\n",
      "fin ep 11 | f1 0.7438 | stagne 4/5\n",
      "p2 ep 12 | batch 4200/4245 | loss 0.6429 | 102 img/s\n",
      "ep 12 : validation en cours\n",
      "fin ep 12 | f1 0.7456 | record ok\n",
      "p2 ep 13 | batch 4200/4245 | loss 0.6386 | 103 img/s\n",
      "ep 13 : validation en cours\n",
      "fin ep 13 | f1 0.7466 | record ok\n",
      "p2 ep 14 | batch 4200/4245 | loss 0.6362 | 103 img/s\n",
      "ep 14 : validation en cours\n",
      "fin ep 14 | f1 0.7442 | stagne 1/5\n",
      "p2 ep 15 | batch 4200/4245 | loss 0.6433 | 103 img/s\n",
      "ep 15 : validation en cours\n",
      "fin ep 15 | f1 0.7408 | stagne 2/5\n",
      "p2 ep 16 | batch 4200/4245 | loss 0.6404 | 103 img/s\n",
      "ep 16 : validation en cours\n",
      "fin ep 16 | f1 0.7475 | record ok\n",
      "p2 ep 17 | batch 4200/4245 | loss 0.6376 | 103 img/s\n",
      "ep 17 : validation en cours\n",
      "fin ep 17 | f1 0.7433 | stagne 1/5\n",
      "p2 ep 18 | batch 4200/4245 | loss 0.6410 | 103 img/s\n",
      "ep 18 : validation en cours\n",
      "fin ep 18 | f1 0.7421 | stagne 2/5\n",
      "p2 ep 19 | batch 4200/4245 | loss 0.6715 | 103 img/s\n",
      "ep 19 : validation en cours\n",
      "fin ep 19 | f1 0.7391 | stagne 3/5\n",
      "p2 ep 20 | batch 4200/4245 | loss 0.6392 | 103 img/s\n",
      "ep 20 : validation en cours\n",
      "fin ep 20 | f1 0.7439 | stagne 4/5\n",
      "p2 ep 21 | batch 4200/4245 | loss 0.6646 | 102 img/s\n",
      "ep 21 : validation en cours\n",
      "fin ep 21 | f1 0.7443 | stagne 5/5\n",
      "early stopping active fin du travail\n",
      "nuit terminee le modele est pret\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from torchvision import transforms\n",
    "\n",
    "print(\"lancement protocole nuit convnext base avec monitoring complet\")\n",
    "\n",
    "# config technique\n",
    "# nous gardons batch 16 pour securite vram\n",
    "real_batch_size = 16 \n",
    "accum_steps = 2 \n",
    "epochs_phase1 = 5\n",
    "epochs_phase2 = 25\n",
    "patience_stop = 5\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "output_dir = os.path.join(project_root, \"implementation\", \"outputs\")\n",
    "\n",
    "# augmentation gpu\n",
    "aug_transform = nn.Sequential(\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    ").to(device)\n",
    "\n",
    "# stats norm\n",
    "mean_gpu = torch.tensor([0.485, 0.456, 0.406], device=device).view(1,3,1,1)\n",
    "std_gpu = torch.tensor([0.229, 0.224, 0.225], device=device).view(1,3,1,1)\n",
    "\n",
    "# je charge le modele\n",
    "print(\"chargement convnext v2 base\")\n",
    "model = timm.create_model(\n",
    "    'convnextv2_base.fcmae_ft_in22k_in1k', \n",
    "    pretrained=True, \n",
    "    num_classes=27,\n",
    "    drop_rate=0.3\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# phase 1 : chauffe tete\n",
    "print(\"phase 1 : entrainement tete seule backbone gele\")\n",
    "# je bloque tout\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# nous debloquons la tete\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(model.head.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(epochs_phase1):\n",
    "    model.train()\n",
    "    t_start = time.time()\n",
    "    t_last = time.time()\n",
    "    indices = torch.randperm(len(x_train))\n",
    "    n_samples = len(x_train)\n",
    "    steps = n_samples // real_batch_size\n",
    "    \n",
    "    for step, i in enumerate(range(0, n_samples, real_batch_size)):\n",
    "        idx = indices[i : i + real_batch_size]\n",
    "        bx = x_train[idx].to(device, non_blocking=True).permute(0,3,1,2).float().div(255.0)\n",
    "        by = y_train[idx].to(device, non_blocking=True)\n",
    "        \n",
    "        bx = aug_transform(bx).sub(mean_gpu).div(std_gpu)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(bx)\n",
    "            loss = criterion(out, by)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # je monitoring chaque 50 batchs\n",
    "        if step % 50 == 0:\n",
    "            curr = time.time()\n",
    "            speed = (50 * real_batch_size) / (curr - t_last + 1e-6)\n",
    "            print(f\"p1 ep {epoch+1} | batch {step}/{steps} | loss {loss.item():.4f} | {speed:.0f} img/s\", end=\"\\r\")\n",
    "            t_last = curr\n",
    "            \n",
    "    print(f\"\\nfin phase 1 ep {epoch+1} terminee\")\n",
    "\n",
    "# phase 2 : fine tuning total\n",
    "print(\"phase 2 : deblocage complet monitoring actif\")\n",
    "# je libere tout le reseau\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=4e-5, weight_decay=0.05)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "best_score = 0.0\n",
    "no_improve_count = 0\n",
    "\n",
    "for epoch in range(epochs_phase2):\n",
    "    model.train()\n",
    "    t_start = time.time()\n",
    "    t_last = time.time()\n",
    "    indices = torch.randperm(len(x_train))\n",
    "    n_samples = len(x_train)\n",
    "    steps = n_samples // real_batch_size\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, i in enumerate(range(0, n_samples, real_batch_size)):\n",
    "        idx = indices[i : i + real_batch_size]\n",
    "        bx = x_train[idx].to(device, non_blocking=True).permute(0,3,1,2).float().div(255.0)\n",
    "        by = y_train[idx].to(device, non_blocking=True)\n",
    "        \n",
    "        bx = aug_transform(bx).sub(mean_gpu).div(std_gpu)\n",
    "        \n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(bx)\n",
    "            loss = criterion(out, by) / accum_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # nous faisons le step tous les 2 tours\n",
    "        if (step + 1) % accum_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # je monitoring chaque 50 batchs\n",
    "        if step % 50 == 0:\n",
    "            curr = time.time()\n",
    "            speed = (50 * real_batch_size) / (curr - t_last + 1e-6)\n",
    "            print(f\"p2 ep {epoch+1} | batch {step}/{steps} | loss {loss.item()*accum_steps:.4f} | {speed:.0f} img/s\", end=\"\\r\")\n",
    "            t_last = curr\n",
    "\n",
    "    # validation\n",
    "    print(f\"\\nep {epoch+1} : validation en cours\")\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(x_val), real_batch_size):\n",
    "            bx = x_val[i : i + real_batch_size].to(device).permute(0,3,1,2).float().div(255.0).sub(mean_gpu).div(std_gpu)\n",
    "            out = model(bx)\n",
    "            all_preds.extend(out.argmax(1).cpu().numpy())\n",
    "            all_targets.extend(y_val[i : i + real_batch_size].numpy())\n",
    "            \n",
    "    score = f1_score(all_targets, all_preds, average='weighted')\n",
    "    \n",
    "    # nous gerons la sauvegarde\n",
    "    status = \"\"\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        no_improve_count = 0\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, \"model_base_night_best.pth\"))\n",
    "        status = \"record ok\"\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        status = f\"stagne {no_improve_count}/{patience_stop}\"\n",
    "        \n",
    "    print(f\"fin ep {epoch+1} | f1 {score:.4f} | {status}\")\n",
    "    scheduler.step(score)\n",
    "    \n",
    "    # securite arret\n",
    "    if no_improve_count >= patience_stop:\n",
    "        print(\"early stopping active fin du travail\")\n",
    "        break\n",
    "\n",
    "print(\"nuit terminee le modele est pret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "473aede2-d90a-4434-8d7b-1298f41e3b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on va passer a la fonction native du gros modele c'est a dire 384*384\n"
     ]
    }
   ],
   "source": [
    "print(\"on va passer a la fonction native du gros modele c'est a dire 384*384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e585c7b-b37d-4665-b331-90160a277abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cba74e-4d8c-43c2-ae73-e94ec97a8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# je charge le meilleur modele de la nuit\n",
    "model_path = os.path.join(output_dir, \"model_base_night_best.pth\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "print(\"generation du fichier de soumission\")\n",
    "\n",
    "# nous preparons les listes\n",
    "ids = []\n",
    "predictions = []\n",
    "\n",
    "# je suppose que tu as un x_test charge sinon on utilise x_val\n",
    "# nous passons sur tout le set sans augmentation\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(x_val), real_batch_size):\n",
    "        bx = x_val[i : i + real_batch_size].to(device)\n",
    "        bx = bx.permute(0,3,1,2).float().div(255.0).sub(mean_gpu).div(std_gpu)\n",
    "        \n",
    "        out = model(bx)\n",
    "        preds = out.argmax(1).cpu().numpy()\n",
    "        \n",
    "        # je convertis les index en vrais codes labels\n",
    "        labels = le.inverse_transform(preds)\n",
    "        \n",
    "        predictions.extend(labels)\n",
    "        # nous recuperons les ids si dispo sinon on met l index\n",
    "        ids.extend(range(i, i + len(preds)))\n",
    "\n",
    "# je cree le dataframe final\n",
    "df_sub = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'label': predictions\n",
    "})\n",
    "\n",
    "# nous sauvons en csv sans index\n",
    "sub_path = os.path.join(output_dir, \"soumission_finale.csv\")\n",
    "df_sub.to_csv(sub_path, index=False)\n",
    "\n",
    "print(f\"fichier pret dans {sub_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass_tooling",
   "language": "python",
   "name": "masterclass_tooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
