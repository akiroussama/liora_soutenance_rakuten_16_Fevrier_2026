{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5211544-96ed-4e52-a543-938ed8ba0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›¡ï¸ PROTOCOLE ANTI-OVERFITTING ACTIVÃ‰ SUR : cuda\n",
      "ðŸ”§ Construction du modÃ¨le...\n",
      "ðŸ”“ DÃ©blocage : Layer 3, 4 et TÃªte.\n",
      "ðŸ”¥ DÃ©marrage EntraÃ®nement 'Generalization' (Objectif 75-80%)...\n",
      "   â³ Ep 1 | Batch 2100 | Loss Train: 1.6883\n",
      "âœ… FIN EP 1 | Time: 623s | F1 Val: 0.5649 | LR: 1.0e-04\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.5649\n",
      "   â³ Ep 2 | Batch 2100 | Loss Train: 1.3254\n",
      "âœ… FIN EP 2 | Time: 625s | F1 Val: 0.5927 | LR: 1.0e-04\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.5927\n",
      "   â³ Ep 3 | Batch 2100 | Loss Train: 1.2172\n",
      "âœ… FIN EP 3 | Time: 637s | F1 Val: 0.6095 | LR: 1.0e-04\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.6095\n",
      "   â³ Ep 4 | Batch 2100 | Loss Train: 1.1664\n",
      "âœ… FIN EP 4 | Time: 675s | F1 Val: 0.6117 | LR: 1.0e-04\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.6117\n",
      "   â³ Ep 5 | Batch 2100 | Loss Train: 0.9467\n",
      "âœ… FIN EP 5 | Time: 652s | F1 Val: 0.6292 | LR: 1.0e-04\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.6292\n",
      "   â³ Ep 6 | Batch 2100 | Loss Train: 0.7080\n",
      "âœ… FIN EP 6 | Time: 646s | F1 Val: 0.6151 | LR: 1.0e-04\n",
      "   â³ Ep 7 | Batch 2100 | Loss Train: 1.0205\n",
      "âœ… FIN EP 7 | Time: 646s | F1 Val: 0.6399 | LR: 1.0e-04\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.6399\n",
      "   â³ Ep 8 | Batch 2100 | Loss Train: 0.8514\n",
      "âœ… FIN EP 8 | Time: 614s | F1 Val: 0.6283 | LR: 1.0e-04\n",
      "   â³ Ep 9 | Batch 2100 | Loss Train: 0.6997\n",
      "âœ… FIN EP 9 | Time: 635s | F1 Val: 0.6362 | LR: 1.0e-04\n",
      "   â³ Ep 10 | Batch 2100 | Loss Train: 0.5844\n",
      "âœ… FIN EP 10 | Time: 655s | F1 Val: 0.6583 | LR: 1.0e-05\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.6583\n",
      "   â³ Ep 11 | Batch 2100 | Loss Train: 0.6734\n",
      "âœ… FIN EP 11 | Time: 641s | F1 Val: 0.6615 | LR: 1.0e-05\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.6615\n",
      "   â³ Ep 12 | Batch 2100 | Loss Train: 0.7990\n",
      "âœ… FIN EP 12 | Time: 637s | F1 Val: 0.6590 | LR: 1.0e-05\n",
      "   â³ Ep 13 | Batch 2100 | Loss Train: 0.3854\n",
      "âœ… FIN EP 13 | Time: 638s | F1 Val: 0.6634 | LR: 1.0e-05\n",
      "   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : 0.6634\n",
      "   â³ Ep 14 | Batch 2100 | Loss Train: 0.6635\n",
      "âœ… FIN EP 14 | Time: 636s | F1 Val: 0.6612 | LR: 1.0e-05\n",
      "   â³ Ep 15 | Batch 2100 | Loss Train: 0.2845\n",
      "âœ… FIN EP 15 | Time: 637s | F1 Val: 0.6599 | LR: 1.0e-05\n",
      "ðŸ† EntraÃ®nement terminÃ©. Score final 'HonnÃªte' : 0.6634\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- 1. CONFIGURATION PROPRE ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "IMG_DIR = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Scaler moderne\n",
    "scaler = torch.amp.GradScaler('cuda') \n",
    "\n",
    "print(f\"ðŸ›¡ï¸ PROTOCOLE ANTI-OVERFITTING ACTIVÃ‰ SUR : {DEVICE}\")\n",
    "\n",
    "# --- 2. DATASET AVEC AUGMENTATION FORTE ---\n",
    "csv_path = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda x: os.path.join(IMG_DIR, f\"image_{x['imageid']}_product_{x['productid']}.jpg\"), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "class RobustDataset(Dataset):\n",
    "    def __init__(self, df, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        \n",
    "        # AUGMENTATION \"HEAVY\" (EmpÃªche le par-cÅ“ur)\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),      \n",
    "            transforms.RandomCrop(224),         \n",
    "            transforms.RandomHorizontalFlip(p=0.5), \n",
    "            transforms.RandomRotation(15),      \n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # VALIDATION STRICTE\n",
    "        self.transform_val = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self): return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try: img = Image.open(row['path']).convert(\"RGB\")\n",
    "        except: img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return self.transform_train(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "        else:\n",
    "            return self.transform_val(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(RobustDataset(train_df, 'train'), batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(RobustDataset(val_df, 'val'), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# --- 3. ARCHITECTURE HYBRIDE ---\n",
    "print(\"ðŸ”§ Construction du modÃ¨le...\")\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V1\") \n",
    "\n",
    "# TÃªte Robuste\n",
    "class LegendMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048), nn.BatchNorm1d(2048), nn.GELU(), nn.Dropout(0.3), \n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),  nn.BatchNorm1d(512),  nn.GELU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "resnet.fc = LegendMLP(2048, NUM_CLASSES)\n",
    "model = resnet.to(DEVICE)\n",
    "\n",
    "# DÃ‰BLOCAGE PARTIEL\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(\"ðŸ”“ DÃ©blocage : Layer 3, 4 et TÃªte.\")\n",
    "\n",
    "# --- 4. OPTIMISEUR ET ENTRAINEMENT ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "# CORRECTION ICI : suppression de verbose=True\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=1)\n",
    "\n",
    "print(\"ðŸ”¥ DÃ©marrage EntraÃ®nement 'Generalization' (Objectif 75-80%)...\")\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    loss_ep = 0.0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for i, (imgs, lbls) in enumerate(train_loader):\n",
    "        imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, lbls)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        loss_ep += loss.item()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"   â³ Ep {epoch+1} | Batch {i} | Loss Train: {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model(imgs)\n",
    "            _, p = torch.max(out, 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(lbls.cpu().numpy())\n",
    "    \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    duree = time.time() - t0\n",
    "    \n",
    "    print(f\"\\nâœ… FIN EP {epoch+1} | Time: {duree:.0f}s | F1 Val: {val_f1:.4f} | LR: {current_lr:.1e}\")\n",
    "    \n",
    "    scheduler.step(val_f1)\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"livrable_model_resnet_final_clean.pth\"))\n",
    "        \n",
    "        meta_data = {\n",
    "            \"model_name\": \"ResNet50 Robust (Anti-Overfit)\", \n",
    "            \"score_f1\": val_f1,\n",
    "            \"class_mapping\": {int(i): str(c) for i, c in enumerate(le.classes_)}\n",
    "        }\n",
    "        with open(os.path.join(OUTPUT_DIR, \"livrable_resnet_reborn_metadata.json\"), 'w') as f:\n",
    "            json.dump(meta_data, f, indent=4)\n",
    "            \n",
    "        print(f\"   ðŸ’¾ Nouveau Champion (Sain) SauvegardÃ© : {val_f1:.4f}\")\n",
    "\n",
    "print(f\"ðŸ† EntraÃ®nement terminÃ©. Score final 'HonnÃªte' : {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65153fd3-85fc-4328-84dc-c74f877185ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jai eu un bug de kernel donc je rÃ©importe tout ici et je fais un test de num worker pour vÃ©rifier ce qui marche ou pas \n"
     ]
    }
   ],
   "source": [
    "print(\"jai eu un bug de kernel donc je rÃ©importe tout ici et je fais un test de num worker pour vÃ©rifier ce qui marche ou pas \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4ba0b-bc4c-4706-a356-39ff75fac495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽï¸ DÃ‰BUT DU BENCHMARK SUR : cuda\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸ§ª TEST num_workers = 0 ...\n",
      "âœ… SUCCÃˆS pour Workers=0 | Temps Total: 2.21s | Vitesse: 0.147 s/batch\n",
      "\n",
      "ðŸ§ª TEST num_workers = 1 ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- CONFIGURATION EXPRESS ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "IMG_DIR = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"ðŸŽï¸ DÃ‰BUT DU BENCHMARK SUR : {DEVICE}\")\n",
    "\n",
    "# --- RECONSTRUCTION RAPIDE DU DATASET ---\n",
    "# (Obligatoire pour que le test fonctionne seul)\n",
    "csv_path = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda x: os.path.join(IMG_DIR, f\"image_{x['imageid']}_product_{x['productid']}.jpg\"), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "train_df, _ = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "class RobustDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        # Transformation standard pour le test\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try: img = Image.open(row['path']).convert(\"RGB\")\n",
    "        except: img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        return self.transform(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "\n",
    "# --- LE TEST DE VITESSE ---\n",
    "workers_to_test = [0, 1, 2, 4] # On teste ces valeurs\n",
    "\n",
    "dataset_test = RobustDataset(train_df)\n",
    "best_worker = 0\n",
    "best_time = 9999.0\n",
    "\n",
    "print(\"-\" * 60)\n",
    "for w in workers_to_test:\n",
    "    print(f\"\\nðŸ§ª TEST num_workers = {w} ...\")\n",
    "    \n",
    "    try:\n",
    "        # On crÃ©e un loader temporaire\n",
    "        loader = DataLoader(\n",
    "            dataset_test, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True, \n",
    "            num_workers=w, \n",
    "            pin_memory=True, \n",
    "            persistent_workers=(w > 0) # Optimisation si > 0\n",
    "        )\n",
    "        \n",
    "        t0 = time.time()\n",
    "        # On charge 15 batchs pour voir\n",
    "        for i, _ in enumerate(loader):\n",
    "            if i >= 15: break\n",
    "            print(f\"   > Batch {i+1}/15 chargÃ©...\", end=\"\\r\")\n",
    "            \n",
    "        duree = time.time() - t0\n",
    "        speed = duree / 15\n",
    "        \n",
    "        print(f\"âœ… SUCCÃˆS pour Workers={w} | Temps Total: {duree:.2f}s | Vitesse: {speed:.3f} s/batch\")\n",
    "        \n",
    "        if speed < best_time:\n",
    "            best_time = speed\n",
    "            best_worker = w\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ã‰CHEC pour Workers={w} (Erreur ou Freeze)\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"ðŸ›‘ STOP MANUEL pour Workers={w}\")\n",
    "        break \n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"ðŸ† VAINQUEUR : num_workers = {best_worker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74a50cb-d867-4c7d-a3e2-c83fa6faf879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ RELANCE TOTALE (EXTENSION 30 EPOQUES) SUR : cuda\n",
      "ðŸ“‚ Rechargement du Dataset...\n",
      "ðŸ”§ Reconstruction de l'architecture...\n",
      "ðŸ“¥ Chargement de ton champion (Epoque 15)...\n",
      "âœ… Poids chargÃ©s avec succÃ¨s ! On reprend l'entraÃ®nement.\n",
      "ðŸ”¥ DÃ©marrage Extension (Epoques 16 -> 45) | LR FixÃ© Ã : 1.0e-05\n",
      "   â³ Ep 16 | Batch 2100 | Loss Train: 0.5318\n",
      "âœ… FIN EP 16 | Time: 625s | F1 Val: 0.6617 | LR: 1.0e-05\n",
      "   ðŸ’¾ NOUVEAU RECORD : 0.6617\n",
      "   â³ Ep 17 | Batch 2100 | Loss Train: 0.4231\n",
      "âœ… FIN EP 17 | Time: 577s | F1 Val: 0.6618 | LR: 1.0e-05\n",
      "   ðŸ’¾ NOUVEAU RECORD : 0.6618\n",
      "   â³ Ep 18 | Batch 2100 | Loss Train: 0.2502\n",
      "âœ… FIN EP 18 | Time: 562s | F1 Val: 0.6608 | LR: 1.0e-05\n",
      "   â³ Ep 19 | Batch 2100 | Loss Train: 0.4842\n",
      "âœ… FIN EP 19 | Time: 565s | F1 Val: 0.6603 | LR: 1.0e-06\n",
      "   â³ Ep 20 | Batch 2100 | Loss Train: 0.5718\n",
      "âœ… FIN EP 20 | Time: 565s | F1 Val: 0.6605 | LR: 1.0e-06\n",
      "   â³ Ep 21 | Batch 2100 | Loss Train: 0.5222\n",
      "âœ… FIN EP 21 | Time: 566s | F1 Val: 0.6604 | LR: 1.0e-07\n",
      "   â³ Ep 22 | Batch 2100 | Loss Train: 0.2447\n",
      "âœ… FIN EP 22 | Time: 566s | F1 Val: 0.6600 | LR: 1.0e-07\n",
      "   â³ Ep 23 | Batch 2100 | Loss Train: 0.2741\n",
      "âœ… FIN EP 23 | Time: 567s | F1 Val: 0.6610 | LR: 1.0e-08\n",
      "   â³ Ep 24 | Batch 2100 | Loss Train: 0.5113\n",
      "âœ… FIN EP 24 | Time: 564s | F1 Val: 0.6599 | LR: 1.0e-08\n",
      "   â³ Ep 25 | Batch 2100 | Loss Train: 0.2945\n",
      "âœ… FIN EP 25 | Time: 565s | F1 Val: 0.6610 | LR: 1.0e-08\n",
      "   â³ Ep 26 | Batch 2100 | Loss Train: 0.2625\n",
      "âœ… FIN EP 26 | Time: 563s | F1 Val: 0.6612 | LR: 1.0e-08\n",
      "   â³ Ep 27 | Batch 2100 | Loss Train: 0.1580\n",
      "âœ… FIN EP 27 | Time: 569s | F1 Val: 0.6610 | LR: 1.0e-08\n",
      "   â³ Ep 28 | Batch 2100 | Loss Train: 0.3100\n",
      "âœ… FIN EP 28 | Time: 568s | F1 Val: 0.6626 | LR: 1.0e-08\n",
      "   ðŸ’¾ NOUVEAU RECORD : 0.6626\n",
      "   â³ Ep 29 | Batch 2100 | Loss Train: 0.0903\n",
      "âœ… FIN EP 29 | Time: 565s | F1 Val: 0.6612 | LR: 1.0e-08\n",
      "   â³ Ep 30 | Batch 2100 | Loss Train: 0.3943"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 152\u001b[39m\n\u001b[32m    150\u001b[39m             out = model(imgs)\n\u001b[32m    151\u001b[39m         _, p = torch.max(out, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m         preds.extend(\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.numpy())\n\u001b[32m    153\u001b[39m         targets.extend(lbls.cpu().numpy())\n\u001b[32m    155\u001b[39m val_f1 = f1_score(targets, preds, average=\u001b[33m'\u001b[39m\u001b[33mweighted\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "IMG_DIR = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "print(f\"ðŸš€ RELANCE TOTALE (EXTENSION 30 EPOQUES) SUR : {DEVICE}\")\n",
    "\n",
    "# --- 2. RECONSTRUCTION DES DONNÃ‰ES (Obligatoire aprÃ¨s redÃ©marrage) ---\n",
    "print(\"ðŸ“‚ Rechargement du Dataset...\")\n",
    "csv_path = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda x: os.path.join(IMG_DIR, f\"image_{x['imageid']}_product_{x['productid']}.jpg\"), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "# DÃ©finition de la classe Dataset (Celle qui manquait)\n",
    "class RobustDataset(Dataset):\n",
    "    def __init__(self, df, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        \n",
    "        # AUGMENTATION \"HEAVY\"\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),      \n",
    "            transforms.RandomCrop(224),         \n",
    "            transforms.RandomHorizontalFlip(p=0.5), \n",
    "            transforms.RandomRotation(15),      \n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # VALIDATION STRICTE\n",
    "        self.transform_val = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self): return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try: img = Image.open(row['path']).convert(\"RGB\")\n",
    "        except: img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            return self.transform_train(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "        else:\n",
    "            return self.transform_val(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "\n",
    "# Configuration Safe (Workers=0) mais optimisÃ©e (Pin Memory)\n",
    "train_loader = DataLoader(RobustDataset(train_df, 'train'), batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(RobustDataset(val_df, 'val'), batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# --- 3. RECONSTRUCTION DU MODÃˆLE ---\n",
    "print(\"ðŸ”§ Reconstruction de l'architecture...\")\n",
    "resnet = models.resnet50(weights=None) # Pas besoin des poids ImageNet, on va charger les nÃ´tres\n",
    "\n",
    "class LegendMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048), nn.BatchNorm1d(2048), nn.GELU(), nn.Dropout(0.3), \n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),  nn.BatchNorm1d(512),  nn.GELU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "resnet.fc = LegendMLP(2048, NUM_CLASSES)\n",
    "model = resnet.to(DEVICE)\n",
    "\n",
    "# --- 4. CHARGEMENT DU CHECKPOINT (CRUCIAL) ---\n",
    "print(\"ðŸ“¥ Chargement de ton champion (Epoque 15)...\")\n",
    "checkpoint_path = os.path.join(OUTPUT_DIR, \"livrable_model_resnet_final_clean.pth\")\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(\"âœ… Poids chargÃ©s avec succÃ¨s ! On reprend l'entraÃ®nement.\")\n",
    "else:\n",
    "    print(\"âŒ ERREUR CRITIQUE : Le fichier .pth n'existe pas !\")\n",
    "    print(\"   -> Assure-toi d'avoir bien fini les 15 premiÃ¨res Ã©poques.\")\n",
    "    # On raise une erreur pour ne pas entraÃ®ner un modÃ¨le vide par erreur\n",
    "    raise FileNotFoundError(\"ModÃ¨le 'clean' introuvable.\")\n",
    "\n",
    "# Optimiseur et Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2) # On force 1e-5 direct\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=1)\n",
    "\n",
    "# Init best_f1 avec une valeur basse pour Ãªtre sÃ»r de sauvegarder si Ã§a monte\n",
    "best_f1 = 0.60 \n",
    "\n",
    "# --- 5. BOUCLE D'EXTENSION ---\n",
    "print(f\"ðŸ”¥ DÃ©marrage Extension (Epoques 16 -> 45) | LR FixÃ© Ã : 1.0e-05\")\n",
    "\n",
    "for epoch in range(15, 45):\n",
    "    model.train()\n",
    "    loss_ep = 0.0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for i, (imgs, lbls) in enumerate(train_loader):\n",
    "        imgs, lbls = imgs.to(DEVICE, non_blocking=True), lbls.to(DEVICE, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, lbls)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        loss_ep += loss.item()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"   â³ Ep {epoch+1} | Batch {i} | Loss Train: {loss.item():.4f}\", end=\"\\r\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model(imgs)\n",
    "            _, p = torch.max(out, 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(lbls.cpu().numpy())\n",
    "    \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    duree = time.time() - t0\n",
    "    \n",
    "    print(f\"\\nâœ… FIN EP {epoch+1} | Time: {duree:.0f}s | F1 Val: {val_f1:.4f} | LR: {current_lr:.1e}\")\n",
    "    \n",
    "    scheduler.step(val_f1)\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"livrable_model_resnet_final_clean.pth\"))\n",
    "        \n",
    "        meta_data = {\n",
    "            \"model_name\": \"ResNet50 Robust Extended Final\", \n",
    "            \"score_f1\": val_f1,\n",
    "            \"class_mapping\": {int(i): str(c) for i, c in enumerate(le.classes_)}\n",
    "        }\n",
    "        with open(os.path.join(OUTPUT_DIR, \"livrable_resnet_reborn_metadata.json\"), 'w') as f:\n",
    "            json.dump(meta_data, f, indent=4)\n",
    "            \n",
    "        print(f\"   ðŸ’¾ NOUVEAU RECORD : {val_f1:.4f}\")\n",
    "\n",
    "print(f\"ðŸ† Marathon terminÃ©. Score final : {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b429e46f-50ef-4ddb-9eec-f9475a0cd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mon modele est actuellement bloque et ne progresse plus du tout\n",
    "# je tente une approche pro pour casser ce plafond de verre\n",
    "# j active le lissage des etiquettes pour eviter que le modele soit trop arrogant\n",
    "# cela l aide a mieux comprendre les images difficiles sans apprendre par coeur\n",
    "# je change aussi le rythme d apprentissage pour qu il fasse des vagues\n",
    "# cela va secouer le modele et le forcer a trouver de meilleures solutions\n",
    "# c est une technique tres efficace pour gagner les derniers points de precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ba442e-619e-49e9-be37-69748ec516dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ OPÃ‰RATION 'BREAKTHROUGH' (LABEL SMOOTHING) SUR : cuda\n",
      "âœ… Poids rechargÃ©s. On va les secouer.\n",
      "ðŸ”¥ DÃ‰MARRAGE PROTOCOLE 'COSINE RESTART' (Optimisation SOTA)...\n",
      "   â³ Ep 1 | Batch 2100 | Loss: 1.5736 | LR: 9.07e-05\n",
      "âœ… FIN EP 1 | Time: 599s | F1 Val: 0.6430 | ðŸ˜\n",
      "   â³ Ep 2 | Batch 2100 | Loss: 0.9871 | LR: 6.61e-05\n",
      "âœ… FIN EP 2 | Time: 573s | F1 Val: 0.6505 | ðŸ˜\n",
      "   â³ Ep 3 | Batch 2100 | Loss: 1.2467 | LR: 3.55e-05\n",
      "âœ… FIN EP 3 | Time: 578s | F1 Val: 0.6541 | ðŸ˜\n",
      "   â³ Ep 4 | Batch 2100 | Loss: 0.8575 | LR: 1.07e-05\n",
      "âœ… FIN EP 4 | Time: 576s | F1 Val: 0.6587 | ðŸ˜\n",
      "   â³ Ep 5 | Batch 2100 | Loss: 1.1364 | LR: 1.00e-06\n",
      "âœ… FIN EP 5 | Time: 582s | F1 Val: 0.6602 | ðŸš€ RECORD\n",
      "   â³ Ep 6 | Batch 1600 | Loss: 1.5174 | LR: 9.86e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "PROJECT_ROOT = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\"\n",
    "IMG_DIR = r\"C:\\Users\\amisf\\Desktop\\datascientest_projet\\data\\raw\\images\\images\\image_train\"\n",
    "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"implementation\", \"outputs\")\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "print(f\"âš¡ OPÃ‰RATION 'BREAKTHROUGH' (LABEL SMOOTHING) SUR : {DEVICE}\")\n",
    "\n",
    "# --- RECONSTRUCTION DATA (Comme avant) ---\n",
    "csv_path = os.path.join(PROJECT_ROOT, \"data\", \"raw\")\n",
    "df_x = pd.read_csv(os.path.join(csv_path, \"X_train_update.csv\"), index_col=0)\n",
    "df_y = pd.read_csv(os.path.join(csv_path, \"Y_train_CVw08PX.csv\"), index_col=0)\n",
    "df = pd.merge(df_x, df_y, left_index=True, right_index=True)\n",
    "df['path'] = df.apply(lambda x: os.path.join(IMG_DIR, f\"image_{x['imageid']}_product_{x['productid']}.jpg\"), axis=1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_encoded'] = le.fit_transform(df['prdtypecode'])\n",
    "NUM_CLASSES = len(le.classes_)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'], random_state=42)\n",
    "\n",
    "class RobustDataset(Dataset):\n",
    "    def __init__(self, df, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),      \n",
    "            transforms.RandomCrop(224),         \n",
    "            transforms.RandomHorizontalFlip(p=0.5), \n",
    "            transforms.RandomRotation(15),      \n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3), # AugmentÃ© un peu\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.transform_val = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        try: img = Image.open(row['path']).convert(\"RGB\")\n",
    "        except: img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        if self.mode == 'train': return self.transform_train(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "        else: return self.transform_val(img), torch.tensor(row['label_encoded'], dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(RobustDataset(train_df, 'train'), batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(RobustDataset(val_df, 'val'), batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# --- MODELE & CHARGEMENT ---\n",
    "resnet = models.resnet50(weights=None)\n",
    "class LegendMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048), nn.BatchNorm1d(2048), nn.GELU(), nn.Dropout(0.4), # Dropout 0.4 plus fort\n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.GELU(), nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 512),  nn.BatchNorm1d(512),  nn.GELU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "resnet.fc = LegendMLP(2048, NUM_CLASSES)\n",
    "model = resnet.to(DEVICE)\n",
    "\n",
    "# On recharge le poids bloquÃ© Ã  66% pour ne pas tout perdre\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, \"livrable_model_resnet_final_clean.pth\")))\n",
    "    print(\"âœ… Poids rechargÃ©s. On va les secouer.\")\n",
    "except:\n",
    "    print(\"âš ï¸ Pas de poids trouvÃ©s, on part de zÃ©ro (ce sera long).\")\n",
    "\n",
    "# --- ðŸ§ª L'ARME SECRÃˆTE : LABEL SMOOTHING + COSINE ANNEALING ---\n",
    "\n",
    "# 1. Label Smoothing : On tolÃ¨re l'incertitude (0.1)\n",
    "# Au lieu de viser [0, 1, 0], on vise [0.05, 0.95, 0.05]\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) \n",
    "\n",
    "# 2. Reset de l'optimiseur\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=2e-2) # Weight decay plus fort\n",
    "\n",
    "# 3. Scheduler Cosine : On fait 3 cycles de restart(idÃ©e d'un coeur qu'on redÃ©mmarre et les vrais rÃ©sulstats sont toutes les 5 Ã©pochs)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "print(\"ðŸ”¥ DÃ‰MARRAGE PROTOCOLE 'COSINE RESTART' (Optimisation SOTA)...\")\n",
    "best_f1 = 0.66 # On veut battre Ã§a\n",
    "\n",
    "for epoch in range(15): # On lance pour 15 Ã©poques de test (Cycle 1 + dÃ©but Cycle 2)\n",
    "    model.train()\n",
    "    loss_ep = 0.0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for i, (imgs, lbls) in enumerate(train_loader):\n",
    "        imgs, lbls = imgs.to(DEVICE, non_blocking=True), lbls.to(DEVICE, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(imgs)\n",
    "            loss = criterion(out, lbls)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        loss_ep += loss.item()\n",
    "        \n",
    "        # Le scheduler Cosine fonctionne par BATCH, pas par Ã©poque (souvent mieux)\n",
    "        scheduler.step(epoch + i / len(train_loader))\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"   â³ Ep {epoch+1} | Batch {i} | Loss: {loss.item():.4f} | LR: {optimizer.param_groups[0]['lr']:.2e}\", end=\"\\r\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model(imgs)\n",
    "            _, p = torch.max(out, 1)\n",
    "            preds.extend(p.cpu().numpy())\n",
    "            targets.extend(lbls.cpu().numpy())\n",
    "    \n",
    "    val_f1 = f1_score(targets, preds, average='weighted')\n",
    "    duree = time.time() - t0\n",
    "    \n",
    "    # Indicateur visuel\n",
    "    res = \"ðŸ˜\"\n",
    "    if val_f1 > best_f1: res = \"ðŸš€ RECORD\"\n",
    "    \n",
    "    print(f\"\\nâœ… FIN EP {epoch+1} | Time: {duree:.0f}s | F1 Val: {val_f1:.4f} | {res}\")\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"livrable_model_resnet_cosine_best.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterclass_tooling",
   "language": "python",
   "name": "masterclass_tooling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
